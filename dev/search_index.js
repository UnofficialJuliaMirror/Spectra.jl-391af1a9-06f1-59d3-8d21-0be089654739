var documenterSearchIndex = {"docs":
[{"location":"GeneralFunctions.html#General-Functions-1","page":"General Functions","title":"General Functions","text":"","category":"section"},{"location":"GeneralFunctions.html#Peak-shapes-1","page":"General Functions","title":"Peak shapes","text":"","category":"section"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"The following functions are useful when generating peaks with various shapes. See the examples for using them during peak fitting for instance.","category":"page"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"gaussiennes\nlorentziennes\npearson7\npseudovoigts","category":"page"},{"location":"GeneralFunctions.html#Spectra.gaussiennes","page":"General Functions","title":"Spectra.gaussiennes","text":"gaussiennes(amplitude::Array{Float64},centre::Array{Float64},hwhm::Array{Float64},x::Array{Float64};style::String = \"None\")\n\ngaussiennes, written in the plural french form there, is a function that allows to build gaussian peaks. The gaussian function used there is:\n\ny = amplitude x exp(-ln(2) x [(x-centre)/hwhm]^2 )\n\nYou can enter the amplitude, centre and half-width at half-maximum (hwhm) values as arrays of float 64 (even containing one float value), without specifying style. hwhm is proportional to the standard deviation sigma:\n\nhwhm= sqrt(2xln(2)) x sigma\n\nthat is used in a normal distribution (see function normal_dist).\n\nInputs\n\namplitude: Array{Float64}\n\tpeaks amplitudes\ncentre: Array{Float64}\n\tpeaks centres\nhwhm: Array{Float64}\n\tpeaks half-width at middle heights (hwhm);\nx: Array{Float64}\n\tx axis values;\n\nOptions\n\nstyle: ASCIIString = \"None\"\n\tsee examples below.\n\nOutputs\n\ny_calc: Array{Float64}\n\tcalculated y values\ny_peaks: Array{Float64}\n\tcalculated y values of the different peaks.\n\n\n\nExamples\n\nTo have four gaussian peaks centered at 800, 900, 1000 and 1100 cm-1 with hwhm of 50 cm-1 on a Raman spectrum, you will enter:\n\n```julia-repl\njulia> y_calc, y_peaks = gaussiennes([1.0,1.0,1.0,1.0], [800.0,900.0,1000.0,1100.0], [50.0,50.0,50.0,50.0], x)\n```\n\nand ypeaks will contain in 4 columns the 4 different y values of the peaks, and ycalc their sum (the total model). Now, if you want to calculate more complex models, such as for instance contructing how the Raman peaks of water vary with pressure, you might like to parametrize the variations of the peak parameters rather than just fitting each spectrum. This will provide more robust fits of the spectra, as you will fit them together, and will also force you to find the correct underlying mathematical assumption.\n\nThe gaussiennes function allows you to do that. If you specify style = \"poly\", you can enter arrays for the amplitudes, centres and half-widths at half-maximum (hwhm) of the peaks, with in each column the coefficients for the polynomial variations of this parameters. The second column of x will need to contain the second variable for those polynomial functions.\n\nLet's say for instance that we have one peak at 900 cm-1 in a pure material. It's frequency seems to linearly shift with increasing the amount of hydrogen in this material, but it's intensity is non-linearly increasing, following a quadratic variation. It's width seems constant.\n\nHow to write that with gaussiennes? Well, first you need to construct a relevant x axis: first column contains the frequency, and the second one contains the chemical variable value. In our case, we want to model the peak between 800 and 1000 cm-1, for 1 wt% H. So we have an x array build like:\n\n```julia-repl\njulia> frequency = collect(800:1:1000)\njulia> x = ones(length(frequency),2)\njulia> x[:,1] = frequency[:]\njulia> x[:,2] = 1.0\n```\n\nOk, now lets build our y peaks:\n\n```julia-repl\njulia> amplitudes = [1.0 0.1 0.1]\njulia> frequencies = [900.0 2.0]\njulia> hwhm = 20.0\njulia> y_calc, y_peaks = gaussiennes(amplitudes, frequencies, hwhm, x)\n```\n\nThis should provide you how the shape of the peak is as a function of both the frequency and the chemical composition there. If you want to go further, you might just want to stick gaussiennes in a loop, and play with creating various peaks with changing the chemical parameter in the x[:,2] column!\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Spectra.lorentziennes","page":"General Functions","title":"Spectra.lorentziennes","text":"lorentziennes(amplitude::Array{Float64},centre::Array{Float64},hwhm::Array{Float64},x::Array{Float64};style::String = \"None\")\n\nInputs\n\namplitude: Array{Float64}\n\tpeaks amplitudes\ncentre: Array{Float64}\n\tpeaks centres\nhwhm: Array{Float64}\n\tpeaks half-width at middle heights (hwhm)\nx: Array{Float64}\n\tx axis values\n\nOptions\n\nstyle: ASCIIString = \"None\", see examples in the gaussiennes documentation.\n\nOutputs\n\ny_calc: Array{Float64}\n\tcalculated y values\ny_peaks: Array{Float64}\n\tcalculated y values of the different peaks.\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Spectra.pearson7","page":"General Functions","title":"Spectra.pearson7","text":"pearson7(a1::Array{Float64},a2::Array{Float64},a3::Array{Float64},a4::Array{Float64},x::Array{Float64};style::String = \"None\")\n\na Pearson 7 peak with formula a1 ./ (1 + ((x-a2)./a3).^2 .* (2.0.^(1./a4) - 1.0))\n\nInputs\n\na1: Array{Float64}\n\tparameter a1\na2: Array{Float64}\n\tparameter a2\na3: Array{Float64}\n\tparameter a3\na4: Array{Float64}\n\tparameter a4\nx: Array{Float64}\n\tx axis values\n\nOptions\n\nstyle: ASCIIString = \"None\", see examples in the gaussiennes documentation.\n\nOutputs\n\ny_calc: Array{Float64}\n\tcalculated y values\ny_peaks: Array{Float64}\n\ty values of the different peaks.\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Spectra.pseudovoigts","page":"General Functions","title":"Spectra.pseudovoigts","text":"pseudovoigts(amplitude::Array{Float64},centre::Array{Float64},hwhm::Array{Float64},lorentzian_fraction::Array{Float64},x::Array{Float64};style::String = \"None\")\n\nA mixture of gaussian and lorentzian peaks.\n\nInputs\n\namplitude: Array{Float64}\n\tpeaks amplitudes\ncentre: Array{Float64}\n\tpeaks centres\nhwhm: Array{Float64}\n\tpeaks half-width at middle heights (hwhm)\nlorentzian_fraction: Array{Float64}\n\tlorentzian fraction of the pseudovoigt function. Should be comprised between 0 and 1;\nx: Array{Float64}\n\tx axis values\n\nOptions\n\nstyle: ASCIIString = \"None\", see examples in the gaussiennes documentation.\n\nOutputs\n\ny_calc: Array{Float64}\n\tcalculated y values\ny_peaks: Array{Float64}\n\ty values of the different peaks\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Peak-measurement-1","page":"General Functions","title":"Peak measurement","text":"","category":"section"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"peakmeas","category":"page"},{"location":"GeneralFunctions.html#Spectra.peakmeas","page":"General Functions","title":"Spectra.peakmeas","text":"peakmeas(x::Array{Float64,1}, y::Array{Float64,1}; smoothing = \"yes\", method = \"savgol\", window_length=5, polyorder=2, ese_y=1., y_smo_out=false)\n\nThe peakmeas function allows performing measurements of the position, width, intensity and centroïd of a dominant peak in a provided x-y signal.\n\nIt smooths the signal with a Savitzky-Golay filter prior to measuring the peak position, width and intensity. It is advised to check that the M and N values of the Savitzky-Golay filter are adequate for your problem before trusting the results from peakmeas. For that, just use the ysmoout option.\n\nhalf-width at half-maximum are calculated as the width of the peak at half its maximum intensity. This calculation is not affected by any asumption of peak symmetry (no fitting is done).\n\nCentroïd is calculated as sum(y./sum(y).*x).\n\nInputs\n\nx: Array{Float64}\n\tx values\ny: Array{Float64}\n\ty values\n\nOptions\n\nsmoothing, String\n\ttriggers the smoothing of the spectrum if set to yes (default value);\nfilter, Symbol\n\tthe filter that will be used. See the smooth function documentation;\nM=5, Int\n\tM parameter for smoothing y with a Savitzky-Golay filter. See smooth function documentation;\nN=2, Int\n\tM parameter for smoothing y with a Savitzky-Golay filter. See smooth function documentation;\ny_smo_out=false\n\tOutputs the smoothed signal.\n\nOutputs\n\nintensity: Float64\n\tpeak intensity\nposition: Float64\n\tpeak position\nhwhm: Float64\n \tpeak half-width at half-maximum\ncentroïd: Float64\n \tpeak centroid\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Integration-1","page":"General Functions","title":"Integration","text":"","category":"section"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"Spectra.jl provides functions that allow one to integrate the area under a region of a spectrum, or to calculate the area under Gaussian, Lorentzian or other bands.","category":"page"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"trapz\nbandarea","category":"page"},{"location":"GeneralFunctions.html#Spectra.trapz","page":"General Functions","title":"Spectra.trapz","text":"trapz(x::Vector{Tx}, y::Vector{Ty}) where {Tx <: Number, Ty <: Number}\n\nTrapezoidal integration. This function is particularly helpful to calculate the area under a portion of a spectrum, and can be used for various purposes (normalisation, area comparison, etc.).\n\nInputs\n\nx: Vector{Float64}\n\tx values\ny: Vector{Float64}\n\ty values.\n\nOutputs\n\narea: Vector{Float64}\n\ttrapezoidal integration value.\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Spectra.bandarea","page":"General Functions","title":"Spectra.bandarea","text":"bandarea(Amplitude::Array{Float64},HWHM::Array{Float64}; peak_shape = \"Gaussian\", error_switch = \"no\", eseAmplitude::Array{Float64} = [0.0], eseHWHM::Array{Float64} = [0.0])\n\nThis function allows calculating the area under a specific band, with different shapes. For now, only Gaussian bands are supported, but other band shapes will be added soon.\n\nInputs\n\nAmplitude: Array{Float64}\n\tpeak amplitude\nHWHM: Array{Float64}\n\tpeak half width at half maximum\n\nOptions\n\npeak_shape: String\n\tshape of the peak. Only \"Gaussian\" is supported for now\nerror_switch: String\n\tshould be \"yes\" or \"no\". If \"yes\", the arrays containing the errors affecting the band amplitude and widhts should be provided in eseAmplitude and eseHWHM (see below);\neseAmplitude: Array{Float64}\n\tarray containing the errors affecting Amplitude\neseHWHM: Array{Float64}\n\tarray containing the errors affecting HWHM;\n\nOutputs\n\narea: Array{Float64}\n\tarray containing peak areas\n\nif error_switch is set to \"yes\", then a second output is provided:\n\nesearea: Array{Float64}\n\tarray that contains the propagated errors affecting the areas calculations.\n\n\n\n\n\n","category":"function"},{"location":"GeneralFunctions.html#Polynomial-1","page":"General Functions","title":"Polynomial","text":"","category":"section"},{"location":"GeneralFunctions.html#","page":"General Functions","title":"General Functions","text":"poly","category":"page"},{"location":"GeneralFunctions.html#Spectra.poly","page":"General Functions","title":"Spectra.poly","text":"poly(p::Vector{Float64},x::Array{Float64})\n\nThis function just allows to build a polynomial curve.\n\nInputs\n\np: Vector{Float64}\n\tpolynomial parameters. For a linear curve, p = [1.0,1.0], for a second order polynomial, p = [1.0,1.0,1.0], etc.;\nx: Array{Float64}\n\tx values for calculation.\n\nOutputs\n\ny: Array{Float64}, containing the result of calculation.\n\n\n\n\n\n","category":"function"},{"location":"Installation.html#Installation-1","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"Installation.html#General-Instructions-1","page":"Installation","title":"General Instructions","text":"","category":"section"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"Two ways of using Spectra: [1] with using a cloud-computing approach and [2] with installing everything on your computer.","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"[1] JuliaBox (https://www.juliabox.org/) allows you to run Julia in your browser. You still need to add Spectra. To do so, run a notebook, and in the first instance, type","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"\t```\n\tUsing Pkg\nPkg.add(\"Spectra\")\n\t```","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"Everything should install without trouble. Requirements in Spectra are extensive and will provide you all the packages needed by Spectra's functions and examples.","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"[2] You can download the current version of Julia and follow the installation instruction here: http://julialang.org/downloads/ . Then, type ] in the Julia REPL shell and do","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"```julia-repl\njulia> add Spectra\n\t```","category":"page"},{"location":"Installation.html#Notes-on-gcvspline-for-v0.4.1-and-higher-1","page":"Installation","title":"Notes on gcvspline for v0.4.1 and higher","text":"","category":"section"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"Installing the gcvspline Python library is optional but gives access to the GCV algorithms in the smooth() and baseline() functions. Install as","category":"page"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"\t```julia-repl\n\t julia> using PyCall\n\t julia> pyimport_conda(\"pip\", \"pip\")\n\t julia> run(`$(PyCall.python) -m pip install $(PACKAGES)`)\n\t ```","category":"page"},{"location":"Installation.html#Prior-to-v0.4.1:-1","page":"Installation","title":"Prior to v0.4.1:","text":"","category":"section"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"Please update to version v0.4.1 :)","category":"page"},{"location":"Installation.html#Error-messages?-1","page":"Installation","title":"Error messages?","text":"","category":"section"},{"location":"Installation.html#","page":"Installation","title":"Installation","text":"If you see various errors messages when trying to install Spectra or after a Pkg.update() command, please see the Tips section!","category":"page"},{"location":"MachineLearning.html#Machine-Learning-1","page":"Machine Learning","title":"Machine Learning","text":"","category":"section"},{"location":"MachineLearning.html#","page":"Machine Learning","title":"Machine Learning","text":"Spectra calls the rampy.mlregressor and rampy.mlexplorer functions to provide easy-to-use access to some machine learning algorithms from the SciKit Learn python library.","category":"page"},{"location":"MachineLearning.html#","page":"Machine Learning","title":"Machine Learning","text":"More advanced ML treatments can be done within the Julia ecosystem (e.g. using Flux, MXNet, Tensorflow etc.), but this is outsite Spectra.","category":"page"},{"location":"MachineLearning.html#","page":"Machine Learning","title":"Machine Learning","text":"mlregressor\nmlexplorer","category":"page"},{"location":"MachineLearning.html#Spectra.mlregressor","page":"Machine Learning","title":"Spectra.mlregressor","text":"mlregressor(x::Array{Float64},y::Array{Float64};X_test::Array{Float64}=[0.0],y_test::Array{Float64}=[0.0],test_sz=0.3,scaler=\"MinMaxScaler\",rand_state=42)\n\nUses machine learning algorithms from scikit learn to perform regression between spectra and an observed variable. This calls the rampy.mlregressor function and creates a Python object. Any algorithm parameter can be modified in the model object.\n\nExample\n\n```julia-repl\njulia> using Spectra\njulia> model = mlregressor(X,y)\njulia> model.algorithm = \"SVM\"\njulia> model.user_kernel = \"poly\"\njulia> model.fit()\njulia> y_new = model.predict(X_new)\n```\n\nDocstring from rampy.mlexporer\n\nAttributes\n\nx : {array-like, sparse matrix}, shape = (nsamples, nfeatures) \tSpectra; nfeatures = nfrequencies. y : array, shape = (nsamples,) \tReturns predicted values. Xtest : {array-like, sparse matrix}, shape = (nsamples, nfeatures) \tspectra organised in rows (1 row = one spectrum) that you want to use as a testing dataset. THose spectra should not be present in the x (training) dataset. The spectra should share a common X axis. ytest : array, shape = (nsamples,) \tthe target that you want to use as a testing dataset. Those targets should not be present in the y (training) dataset. algorithm : String, \t\"KernelRidge\", \"SVM\", \"LinearRegression\", \"Lasso\", \"ElasticNet\", \"NeuralNet\", \"BaggingNeuralNet\", default = \"SVM\" scaling : Bool \tTrue or False. If True, data will be scaled during fitting and prediction with the requested scaler (see below), scaler : String \tthe type of scaling performed. Choose between MinMaxScaler or StandardScaler, see http://scikit-learn.org/stable/modules/preprocessing.html for details. Default = \"MinMaxScaler\". testsize : float \tthe fraction of the dataset to use as a testing dataset; only used if Xtest and ytest are not provided. randstate : Float64 \tthe random seed that is used for reproductibility of the results. Default = 42. paramkr : Dictionary \tcontain the values of the hyperparameters that should be provided to KernelRidge and GridSearch for the Kernel Ridge regression algorithm. paramsvm : Dictionary \tcontaing the values of the hyperparameters that should be provided to SVM and GridSearch for the Support Vector regression algorithm. paramneurons : Dictionary \tcontains the parameters for the Neural Network (MLPregressor model in sklearn). \tDefault= dict(hiddenlayersizes=(3,),solver = 'lbfgs',activation='relu',earlystopping=True) parambagging : Dictionary \tcontains the parameters for the BaggingRegressor sklearn function that uses a MLPregressor base method. \tDefault= dict(nestimators=100, maxsamples=1.0, maxfeatures=1.0, bootstrap=True, \t\t\t\t\tbootstrapfeatures=False, oobscore=False, warmstart=False, njobs=1, randomstate=randstate, verbose=0) predictiontrain : Array{Float64} \tthe predicted target values for the training y dataset. predictiontest : Array{Float64} \tthe predicted target values for the testing ytest dataset. model : Scikit learn model \tA Scikit Learn object model, see scikit learn library documentation. Xscaler : \tA Scikit Learn scaler object for the x values. Y_scaler : \tA Scikit Learn scaler object for the y values.\n\nRemarks\n\nFor details on hyperparameters of each algorithms, please directly consult the documentation of SciKit Learn at:\n\nhttp://scikit-learn.org/stable/\n\nFor Support Vector and Kernel Ridge regressions, mlregressor performs a cross_validation search with using 5 KFold cross validators.\n\nIf the results are poor with Support Vector and Kernel Ridge regressions, you will have to tune the paramgridkr or paramgridsvm dictionnary that records the hyperparameter space to investigate during the cross validation.\n\nResults for machine learning algorithms can vary from run to run. A way to solve that is to fix the random_state. For neural nets, results from multiple neural nets (bagging technique) may also generalise better, such that it may be better to use the BaggingNeuralNet function.\n\n\n\n\n\n","category":"function"},{"location":"MachineLearning.html#Spectra.mlexplorer","page":"Machine Learning","title":"Spectra.mlexplorer","text":"mlexplorer(x::Array{Float64})\n\nUse machine learning algorithms from scikit learn to explore spectroscopic datasets. Performs automatic scaling and train/test split before NMF or PCA fit.\n\nExample\n\n```julia-repl\njulia> explo = mlexplorer(X) # X is an array of signals built by mixing two partial components\njulia> explo.algorithm = \"NMF\" # using Non-Negative Matrix factorization\njulia> explo.nb_compo = 2 # number of components to use\njulia> explo.test_size = 0.3 # size of test set\njulia> explo.scaler = \"MinMax\" # scaler\njulia> explo.fit() # fitting!\njulia> W = explo.model.transform(explo.X_train_sc) # getting the mixture array\njulia> H = explo.X_scaler.inverse_transform(explo.model.components_) # components in the original space\njulia> plot(X,H.T) # plot the two components\n```\n\nDocstring from rampy.mlexporer\n\nAttributes\n\nx : {array-like, sparse matrix}, shape = (nsamples, nfeatures) \tSpectra; nfeatures = nfrequencies. Xtest : {array-like, sparse matrix}, shape = (nsamples, nfeatures) \tspectra organised in rows (1 row = one spectrum) that you want to use as a testing dataset. THose spectra should not be present in the x (training) dataset. The spectra should share a common X axis. algorithm : String, \t\"PCA\", \"NMF\", default = \"PCA\" scaling : Bool \tTrue or False. If True, data will be scaled prior to fitting (see below), scaler : String \tthe type of scaling performed. Choose between MinMaxScaler or StandardScaler, see http://scikit-learn.org/stable/modules/preprocessing.html for details. Default = \"MinMaxScaler\". testsize : float \tthe fraction of the dataset to use as a testing dataset; only used if Xtest and ytest are not provided. rand_state : Float64 \tthe random seed that is used for reproductibility of the results. Default = 42. model : Scikit learn model \tA Scikit Learn object model, see scikit learn library documentation.\n\nRemarks\n\nFor details on hyperparameters of each algorithms, please directly consult the documentation of SciKit Learn at:\n\nhttp://scikit-learn.org/stable/\n\nResults for machine learning algorithms can vary from run to run. A way to solve that is to fix the random_state.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Peak-fitting-1","page":"Peak fitting","title":"Peak fitting","text":"","category":"section"},{"location":"PeakFitting.html#Model-adjustment-1","page":"Peak fitting","title":"Model adjustment","text":"","category":"section"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"Peak fitting is done with the JuMP framework (https://jump.readthedocs.org/en/latest/). Spectra actually does not provide any peak fitting capacities by itself, but the combination of its functionality with JuMP helps making fitting procedure quite easy. An example is visible in the example section of Spectra.","category":"page"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"One goal of Spectra is to promote the use of global optimisation models, where peak parameters are actually calculated from variation in other parameters (chemistry, temperature, etc.), or are shared between several spectra. I will provide very soon an example of such an approach. It can be implemented in a few lines of code with combining Spectra and JuMP, and has the advantage of greatly reducing the errors of the fits.","category":"page"},{"location":"PeakFitting.html#error-calculation-with-bootstrapping-1","page":"Peak fitting","title":"error calculation with bootstrapping","text":"","category":"section"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"Error calculation can be done with using bootstrapping. Spectra provides a function that allows generating K new datasetes, by resampling the existing dataset in a non-parametric or parametric way.","category":"page"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"bootsample\nbootperf","category":"page"},{"location":"PeakFitting.html#Spectra.bootsample","page":"Peak fitting","title":"Spectra.bootsample","text":"bootsample(x::Array{Float64}, y::Array{Float64}; boottype::String = \"np\", ese::Array{Float64} = [0.0])\n\nInputs\n\nx: Array{Float64}, the x axis. It can have multiple columns.\n\ny: Array{Float64}, the y axis. It can have multiple columns.\n\nOptions\n\nboottype: ASCIIString, either \"np\" or \"p\", this is the type of bootstrapping performed. \"np\" performes a non-parametric resampling fo the dataset with replacement. \"p\" performs a parametric resampling. The data are resample from a gaussian distribution centered on the y values with errors that should be provided in the ese variable.\n\nese: Array{Float64}, containing the errors affecting the y values that are used during parametric bootstrapping.\n\nOutputs\n\nb_x_f: Array{Float64}, the bootstrapped x values\n\nb_y_f: Array{Float64}, the bootstrapped y values\n\nThe bootstrap function can be embedded in a for loop, and will each time produce a different dataset. Performing K times the bootstrapping and fitting each time the model will allow to estimate the error distribution on the peak parameters. This technic has the advantage of making no prior assumption on the probability distribution functions of parameters errors. However, it is  much more time consuming that using the covariance matrix.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.bootperf","page":"Peak fitting","title":"Spectra.bootperf","text":"bootperf(params_boot::Array{Float64}; plotting::String = \"True\", parameter::Int64 = 1, feature::Int64 = 1, histogram_step::Int64 = 100, savefigures::String = \"False\", save_bootrecord::String = \"Boot_record.pdf\", save_histogram::String = \"Boot_histogram.pdf\")\n\nInputs\n\nparams_boot[i,j] or [i,j,k]\n\tarray with i the bootstrrap experiment, j the parameter and k the feature being calculated (e.g., a peak during peak fitting)\nplotting: String\n\tswitch to plotting mode (\"True\") or not (\"False\"). If true, parameter and feature must be provided, otherwise an error message is returned.\n\nhistogram_step\n\tinteger value to control the histogram X axis division.\nsavefigures: \"True\" or \"False\"\n\texplicit, save in the current working directory.\nsave_bootrecord:\n\tName for the graphic showing the bootstrap mean and std evolutions, with extension.\nsave_histogram:\n\tName for the graphic showing the histogram for the parameter and feature of interest, with extension.\n\nOutputs\n\nstd_record, mean_record, the arrays recording how the standard deviation and mean of the parameters as a function of the bootstrap advance.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"For further details, see the following references","category":"page"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"Efron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics 7 (1): 1–26.","category":"page"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"Efron, Bradley. 1981. “Nonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.” Biometrika 68 (3): 589–99. doi:10.1093/biomet/68.3.589.","category":"page"},{"location":"PeakFitting.html#","page":"Peak fitting","title":"Peak fitting","text":"Efron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.","category":"page"},{"location":"PreProcessing.html#Pre-Processing-1","page":"Pre-Processing","title":"Pre-Processing","text":"","category":"section"},{"location":"PreProcessing.html#Temperature-and-frequency-corrections-for-Raman-spectra-1","page":"Pre-Processing","title":"Temperature and frequency corrections for Raman spectra","text":"","category":"section"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"Raman spectra can be corrected from temperature and excitation line effects using this function.","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"tlcorrection","category":"page"},{"location":"PreProcessing.html#Spectra.tlcorrection","page":"Pre-Processing","title":"Spectra.tlcorrection","text":"tlcorrection(data::Array{Float64},temp::Float64,wave::Float64;correction=\"long\",normalisation=\"area\",density=2210.0)\n\nInputs\n\ndata: Array{Float64}\n\tinput spectrum with x and y in first and second columns respectively\ntemp: Float64\n\ttemperature in °C\nwave: Float64\n\twavenumber at which the spectrum was acquirred in nm\n\nOptions\n\ncorrection: String\n\tequation used for the correction. Choose between \"long\", \"galeener\", or \"hehlen\". Default = \"long\".\nnormalisation: String\n\tindicate if you want to normalise your signal or not. Choose between \"intensity\", \"area\", or \"no\". Default = \"area\".\ndensity: Float64\n\tdensity of the studied material in kg m-3, to be used with the \"hehlen\" equation. Default = 2210.0 (density of silica).\n\nOutputs\n\n(are combined in one array if only one output name is given) \tx: Array{Float64} \t\tx values \tlong: Array{Float64} \t\tcorrected y values \teselong: Array{Float64} \t\terrors calculated as sqrt(y) on raw data and propagated after the correction.\n\nNotes\n\nThis correction uses the formula reported in Galeener and Sen (1978), Mysen et al. (1982), Brooker et al. (1988) and Hehlen et al. (2010).\n\nThe \"galeener\" equation is the exact one reported in Galeener and Sen (1978), which is a modification from Shuker and Gammon (1970) for accounting of (vo - v)^4 dependence of the Raman intensity. See also Brooker et al. (1988) for further discussion.\n\nThe \"long\" equation is that of Galeener and Sen (1978) corrected by a vo^3 coefficient for removing the cubic meter dimension of the equation of \"galeener\". This equation has been used in Mysen et al. (1982), Neuville and Mysen (1996) and Le Losq et al. (2012).\n\nThe \"hehlen\" equation is that reported in Hehlen et al. (2010). It actually originates before this publication (Brooker et al. 1988). It uses a different correction that avoid crushing the signal below 500 cm-1. THerefore, it has the advantage of keeping intact the Boson peak signal in glasses.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Smoothing-signals-1","page":"Pre-Processing","title":"Smoothing signals","text":"","category":"section"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"Smoothing the signal is achieved with the smooth function.","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"smooth","category":"page"},{"location":"PreProcessing.html#Spectra.smooth","page":"Pre-Processing","title":"Spectra.smooth","text":"smooth(x,y;method=\"whittaker\", window_length=5, polyorder = 2, Lambda = 10.0.^5, d=2, ese_y=1.0)\n\nsmooth the provided y signal (sampled on x)\n\nInputs\n\nx: vector\n\tNx1 array of x values (equally spaced).\ny: vector\n\tNx1 array of y values (equally spaced).\nmethod: str\n\tMethod for smoothing the signal;\n\tchoose between savgol (Savitzky-Golay), GCVSmoothedNSpline, MSESmoothedNSpline, DOFSmoothedNSpline, whittaker, 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'.\n\nOptions\n\nwindowlength: int \tThe length of the filter window (i.e. the number of coefficients). windowlength must be a positive odd integer. polyorder: int \tThe order of the polynomial used to fit the samples. polyorder must be less than windowlength. Lambda: float \tsmoothing parameter of the Whittaker filter described in Eilers (2003). The higher the smoother the fit. d: int \td parameter in Whittaker filter, see Eilers (2003). esey: ndarray \terrors associated with y (for the gcvspline algorithms)\n\nOutputs\n\ny_smo: ndarray \tsmoothed signal sampled on x.\n\nNote\n\nUse of GCVSmoothedNSpline, MSESmoothedNSpline, DOFSmoothedNSpline requires installation of gcvspline. See gcvspline documentation. See also documentation for details on GCVSmoothedNSpline, MSESmoothedNSpline, DOFSmoothedNSpline.\n\nsavgol uses the scipy.signal.savgol_filter() function.\n\nReferences\n\nEilers, P.H.C., 2003. A Perfect Smoother. Anal. Chem. 75, 3631–3636. https://doi.org/10.1021/ac034173t\n\nScipy Cookbook: https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html?highlight=smooth\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Baseline-subtraction-1","page":"Pre-Processing","title":"Baseline subtraction","text":"","category":"section"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"Baseline subtraction can be made with using the baseline function:","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"baseline","category":"page"},{"location":"PreProcessing.html#Spectra.baseline","page":"Pre-Processing","title":"Spectra.baseline","text":"baseline(x::Array{Float64},y::Array{Float64},roi::Array{Float64},basetype::AbstractString;polynomial_order=1, s = 1.0, lam = 10^5, p = 0.01, ratio = 0.01, niter = 10, p0_exp = [1.,1.,1.],p0_log =[1.,1.,1.])\n\nAllows subtracting a baseline under a x y spectrum; uses the baseline function from the rampy Python package.\n\nParameters\n\nxinput : ndarray \tx values. yinput : ndarray \ty values. bir : ndarray \tContain the regions of interest, organised per line. \tFor instance, roi = np.array([[100., 200.],[500.,600.]]) will \tdefine roi between 100 and 200 as well as between 500 and 600. \tNote: This is NOT used by the \"als\" and \"arPLS\" algorithms, but still is a requirement when calling the function. \tbir and method probably will become args in a futur iteration of rampy to solve this. methods : str \t\"poly\": polynomial fitting, with splinesmooth the degree of the polynomial. \t\"unispline\": spline with the UnivariateSpline function of Scipy, splinesmooth is \t\t\t\t the spline smoothing factor (assume equal weight in the present case); \t\"gcvspline\": spline with the gcvspl.f algorythm, really robust. \t\t\t\t Spectra must have x, y, ese in it, and splinesmooth is the smoothing factor; \t\t\t\t For gcvspline, if ese are not provided we assume ese = sqrt(y). \t\t\t\t WARNING: Requires the installation of the gcvspline Python package prior to use in the Python ENV used by Julia. \t\t\t\t See website for install instructions \t\"exp\": exponential background; \t\"log\": logarythmic background; \t\"rubberband\": rubberband baseline fitting; \t\"als\": automatic least square fitting following Eilers and Boelens 2005; \t\"arPLS\": automatic baseline fit using the algorithm from Baek et al. 2015 \t\t\t Baseline correction using asymmetrically reweighted penalized least squares smoothing, Analyst 140: 250-257.\n\nOptions\n\npolynomialorder : Int \tThe degree of the polynomial (0 for a constant), default = 1. s : Float \tspline smoothing coefficient for the unispline and gcvspline algorithms. lam : Float \tfloat, the lambda smoothness parameter for the ALS and ArPLS algorithms. Typical values are between 102 to 109, default = 10**5. p : Float \tfloat, for the ALS algorithm, advised value between 0.001 to 0.1, default = 0.01. ratio : float \tratio parameter of the arPLS algorithm. default = 0.01. niter : Int \tnumber of iteration of the ALS algorithm, default = 10. p0exp : List \tcontaing the starting parameter for the exp baseline fit with curvefit. Default = [1.,1.,1.]. p0log : List \tcontaing the starting parameter for the log baseline fit with curve_fit. Default = [1.,1.,1.,1.].\n\nReturns\n\nout1 : ndarray \tContain the corrected signal. out2 : ndarray \tContain the baseline.\n\nExample\n\nConsider a Y signal sampled at X. We want to fit a polynomial baseline (2nd order) in the regions of interest comprised between x1 and x2, as well as x3 and x4.\n\njulia> Y_corr, Y_baseline = baseline(X,Y,[x1 x2; x3 x4],\"poly\",polynomial_order=2)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Frequency-shifts-correction-1","page":"Pre-Processing","title":"Frequency shifts correction","text":"","category":"section"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"In case your spectra are shifted from a reference value, Spectra offers several functions that allows you to correct it from this shift.","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"To correct a spectrum from a shift of P wavenumbers, you can simply call:","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"xshift_direct","category":"page"},{"location":"PreProcessing.html#Spectra.xshift_direct","page":"Pre-Processing","title":"Spectra.xshift_direct","text":"xshift_direct(original_x::Array{Float64}, original_y::Array{Float64}, p::Float64)\n\nTo correct a spectrum for a p shift in X.\n\nUsed in xshift_correction.\n\nInputs\n\noriginal_x: Array{Float64}\n\tx values\noriginal_y: Array{Float64}\n\ty values associated with x\np: Array{Float64}\n\tvalue of how much x should be shifted\n\nOutputs\n\noriginal_x: Array{Float64}\n\tsame as input\ncorrected_y: Array{Float64}\n\tthe y values corrected from the p shift in original_x\np: Array{Float64}\n\tsame as input.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"Sometime, two signals from the same mineral show a shift in the X axis, while they share a common X axis. To correct from such thing, you can use the function:","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"xshift_correction","category":"page"},{"location":"PreProcessing.html#Spectra.xshift_correction","page":"Pre-Processing","title":"Spectra.xshift_correction","text":"xshift_correction(full_x::Array{Float64}, full_shifted_y::Array{Float64}, ref_x::Array{Float64}, ref_y::Array{Float64},shifted_y::Array{Float64})\n\nTo correct a shift between two spectra using a reference peak.\n\nInputs\n\nfull_x: Array{Float64}\n\tx values that are not good\nfull_shifted_y: Array{Float64}\n\ty values associated with full_x\nref_x: Array{Float64}\n\tx values that are good\nref_y: Array{Float64}\n\ty values associated with ref_x\nshifted_y: Array{Float64}\n\ty values associated with a selected range of full_x that corresponds to ref_x (for instance, a specific peak that you want to use to correct the shift).\n\nOutputs\n\nfull_x: Array{Float64}\n\tsame as input\ncorrected_y: Array{Float64}\n\tthe full_shifted_y values corrected from the shift\np: Array{Float64}\n\tsame as input.\n\nrefx is the common X axis of two particular refy and shiftedy signals, that should be for instance an intense and well defined peak in your spectra. If refy and shifted_y do not share the same X axis, you can use first the Dierckx spline to re-sample one of them and have both sharing a common X axis. See the examples for further details.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#array-manipulation-1","page":"Pre-Processing","title":"array manipulation","text":"","category":"section"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"For spectra recorded with decreasing frequencies, use the flipsp() function to put them back with increasing frequencies (necessary for some algo)","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"flipsp","category":"page"},{"location":"PreProcessing.html#Spectra.flipsp","page":"Pre-Processing","title":"Spectra.flipsp","text":"flipsp(spectra::Array{Float64})\n\nFlip an array along the row dimension (dim = 1) if the first column values are in decreasing order.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"You can also resample a signal at wanted x_new values with resample()","category":"page"},{"location":"PreProcessing.html#","page":"Pre-Processing","title":"Pre-Processing","text":"resample","category":"page"},{"location":"PreProcessing.html#Spectra.resample","page":"Pre-Processing","title":"Spectra.resample","text":"resample(x::Array{Float64},y::Array{Float64},x_new::Array{Float64})\n\nResample a y signal associated with x, along the x_new values.\n\nUses the Dierckx spline library.\n\n\n\n\n\n","category":"function"},{"location":"References.html#References-1","page":"References","title":"References","text":"","category":"section"},{"location":"References.html#","page":"References","title":"References","text":"Baek, S.-J., A. Park, Y.-J. Ahn, and J. Choo 2015. Baseline correction using asymmetrically reweighted penalized least squares smoothing, Analyst, 140(1), 250–257, doi:10.1039/C4AN01061B.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Brooker et al. 1988 Assessment of correction procedures for reduction of Raman spectra. Journal of Raman Spectroscopy 19(2), 71-78.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Efron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics 7 (1): 1–26.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Efron, Bradley. 1981. “Nonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.” Biometrika 68 (3): 589–99. doi:10.1093/biomet/68.3.589.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Efron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Eilers, P. H. C. 2003. A Perfect Smoother, Anal. Chem., 75(14), 3631–3636, doi:10.1021/ac034173t.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Eilers, P. H. C. and Boelens H. F. M., 2005. Baseline Correction with Asymmetric Least Squares Smoothing.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Galeener, F. L., and Sen, P. N. 1978. “Theory of the First-Order Vibrational Spectra of Disordered Solids.” Physical Review B 17 (4): 1928–33.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Hehlen, B. 2010. “Inter-Tetrahedra Bond Angle of Permanently Densified Silicas Extracted from Their Raman Spectra.” Journal of Physics: Condensed Matter 22 (2): 025401.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Le Losq C., Neuville D. R., Florian P., Henderson G. S. and Massiot D., 2014, The role of Al3+ on rheology and structural changes in sodium silicate and aluminosilicate glasses and melts. Geochimica et Cosmochimica Acta 126, 495-517.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Neuville, D. R., and B. O. Mysen. 1996. “Role of Aluminium in the Silicate Network: In Situ, High-Temperature Study of Glasses and Melts on the Join SiO₂-NaAl0₂.” Geochimica et Cosmochimica Acta 60: 1727–37.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Mysen, B. O., L. W. Finger, D. Virgo, and F. A. Seifert. 1982. “Curve-Fitting of Raman Spectra of Silicate Glasses.” American Mineralogist 67: 686–95.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Shuker, Reuben, and Robert Gammon. 1970. “Raman-Scattering Selection-Rule Breaking and the Density of States in Amorphous Materials.” Physical Review Letters 25 (4): 222–25.","category":"page"},{"location":"References.html#","page":"References","title":"References","text":"Woltring, 1986, A FORTRAN package for generalized, cross-validatory spline smoothing and differentiation. Adv. Eng. Softw. 8, 104-113.","category":"page"},{"location":"Tips.html#Tips-1","page":"Tips","title":"Tips","text":"","category":"section"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"In this section are listed various tips for the use of Julia and Spectra:","category":"page"},{"location":"Tips.html#Installation-1","page":"Tips","title":"Installation","text":"","category":"section"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"If you see errors messages linked to PyCall, you may have a problem with your environment variable. To solve it, tyope the following commands in the Julia prompt:","category":"page"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"```julia-repl\njulia> ENV[\"PYTHON\"]=\"\"\njulia> Using Pkg\njulia> Pkg.build(\"PyCall\")\n```","category":"page"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"At this point it should work. If yes, you now can type ']' in the Julia repl and then enter: \tjulia-repl \tpkg> add Spectra","category":"page"},{"location":"Tips.html#Maintenance-1","page":"Tips","title":"Maintenance","text":"","category":"section"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"The Julia package ecosystem is frequently evolving. Because of that, it is recommended to update frequently. Type ']' in the Julia repl and then enter: \tjulia-repl \tpkg> update","category":"page"},{"location":"Tips.html#Running-Spectra-1","page":"Tips","title":"Running Spectra","text":"","category":"section"},{"location":"Tips.html#","page":"Tips","title":"Tips","text":"Always be careful to variable types. Functions will return an error message if you do not enter the good type.","category":"page"},{"location":"index.html#Welcome-to-Spectra's-documentation!-1","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"","category":"section"},{"location":"index.html#Introduction-1","page":"Welcome to Spectra's documentation!","title":"Introduction","text":"","category":"section"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Spectra is a package aimed at helping spectroscopic (Raman, Infrared, Nuclear Magnetic Resonance, XAS...) data treatment written with the Julia programming language. It's aim is to provide the simplest way to perform actions like baseline fitting and removal or peak fitting for instance, while respecting the freedom offered by data treatment through coding. Therefore, Spectra is aimed to be used explicitly with other packages like JuMP for building models. The key is to provide functions for simplifying the life of the spectroscopist, while still leaving him all the freedom offered by treating data with a performant computer language.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Spectra is particularly focused on large datasets because of the high speed of Julia's, e.g. for performing peak fitting along Infrared diffusion profiles. For peak fitting for instance, the JuMP interface offers a very flexible yet clear way to build models, that can be solve with solvers such as Ipopt or NLopt.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Please consult this documentation to learn using Spectra, do not forget to check the Tips_ section if you have issues, and please report anything you want!","category":"page"},{"location":"index.html#Starting-Notes-1","page":"Welcome to Spectra's documentation!","title":"Starting Notes","text":"","category":"section"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Using Julia and Spectra for processing your data is quite similar to Matlab, with the flexibility offered by the open-source and free character of Julia. Reading the docs is strongly recommended. A good start will be to read the docs of Julia itself.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Programming can be done locally using your browser and the IJulia notebooks, very similar to the IPython ones. For a Matlab-like interface, you can use Atom with Juno.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"For maintaining your packages up-to-date, something critical with the fast evolution of Julia packages, I suggest running each day of Julia use the update command:","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Pkg.update()","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Installation of Spectra is easy:","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Pkg.add(\"Spectra\")","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"See the Installation section for further details, in particular for Windows users.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Any help developing and maintaining this Spectra package is welcome. You can fork the project on GitHub, modify it and commit your modifications. You can also add requests and everything on Github. Please do not hesitate to do so! The functionalities available in Spectra are not exhaustive, and a little help to add new ones will be more that welcome.","category":"page"},{"location":"index.html#Examples-1","page":"Welcome to Spectra's documentation!","title":"Examples","text":"","category":"section"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Examples are available in the examples folder of Spectra (https://github.com/charlesll/Spectra/tree/master/examples).","category":"page"},{"location":"index.html#Citing-Spectra-1","page":"Welcome to Spectra's documentation!","title":"Citing Spectra","text":"","category":"section"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"You can cite Spectra as","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"LE LOSQ, C. (2016) Spectra: a Julia package for processing spectroscopic data. Zenodo. 10.5281/zenodo.53940","category":"page"},{"location":"index.html#Index-1","page":"Welcome to Spectra's documentation!","title":"Index","text":"","category":"section"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"The functions that are in Spectra are listed below. See the other part of the documentation for further information.","category":"page"},{"location":"index.html#","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"","category":"page"}]
}
