{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Spectra.jl's documentation!\n\n\n\n\nIntroduction\n\n\nSpectra.jl is a package aimed at helping spectroscopic (Raman, Infrared, Nuclear Magnetic Resonance, XAS...) data treatment written with the \nJulia programming language\n. It's aim is to provide the simplest way to perform actions like baseline fitting and removal or peak fitting for instance, while respecting the freedom offered by data treatment through coding. Therefore, Spectra.jl is aimed to be used explicitly with other packages like \nJuMP\n for building models. The key is to provide functions for simplifying the life of the spectroscopist, while still leaving him all the freedom offered by treating data with a performant computer language.\n\n\nSpectra.jl is particularly focused on large datasets because of the high speed of Julia's, e.g. for performing peak fitting along Infrared diffusion profiles. For peak fitting for instance, the JuMP interface offers a very flexible yet clear way to build models, that can be solve with solvers such as Ipopt or NLopt.\n\n\nPlease consult this documentation to learn using Spectra, do not forget to check the Tips_ section if you have issues, and please report anything you want!\n\n\n\n\nStarting Notes\n\n\nUsing Julia and Spectra.jl for processing your data is quite similar to Matlab, with the flexibility offered by the open-source and free character of Julia. Reading the docs is strongly recommended. A good start will be to read the \ndocs of Julia itself\n.\n\n\nProgramming can be done locally using your browser and the \nIJulia notebooks\n, very similar to the IPython ones. For a Matlab-like interface, you can use \nAtom with Juno\n.\n\n\nFor maintaining your packages up-to-date, something critical with the fast evolution of Julia packages, I suggest running each day of Julia use the update command:\n\n\nPkg.update()\n\n\n\n\n\nInstallation of Spectra is easy:\n\n\nPkg.add(\nSpectra\n)\n\n\n\n\n\nSee the Installation section for further details, in particular for Windows users.\n\n\nAny help developing and maintaining this Spectra.jl package is welcome. You can fork the project on GitHub, modify it and commit your modifications. You can also add requests and everything on Github. Please do not hesitate to do so! The functionalities available in Spectra.jl are not exhaustive, and a little help to add new ones will be more that welcome.\n\n\n\n\nCiting Spectra\n\n\nYou can cite Spectra as \n\n\nLE LOSQ, C. (2016) Spectra.jl: a Julia package for processing spectroscopic data. Zenodo. 10.5281/zenodo.53940\n\n\n\n\n\n\n\nIndex\n\n\nThe functions that are in Spectra.jl are listed below. See the other part of the documentation for further information.\n\n\n\n\nSpectra.SavitzkyGolayFilter\n\n\nSpectra.bandarea\n\n\nSpectra.baseline\n\n\nSpectra.bootperf\n\n\nSpectra.bootsample\n\n\nSpectra.ctxremoval\n\n\nSpectra.gaussiennes\n\n\nSpectra.gcvspl_julia\n\n\nSpectra.lorentziennes\n\n\nSpectra.mlregressor\n\n\nSpectra.normal_dist\n\n\nSpectra.peakhw\n\n\nSpectra.pearson7\n\n\nSpectra.poly\n\n\nSpectra.polyfit\n\n\nSpectra.pseudovoigts\n\n\nSpectra.rameau\n\n\nSpectra.splderivative_julia\n\n\nSpectra.tlcorrection\n\n\nSpectra.trapz\n\n\nSpectra.xshift_correction\n\n\nSpectra.xshift_direct", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-spectrajls-documentation", 
            "text": "", 
            "title": "Welcome to Spectra.jl's documentation!"
        }, 
        {
            "location": "/#introduction", 
            "text": "Spectra.jl is a package aimed at helping spectroscopic (Raman, Infrared, Nuclear Magnetic Resonance, XAS...) data treatment written with the  Julia programming language . It's aim is to provide the simplest way to perform actions like baseline fitting and removal or peak fitting for instance, while respecting the freedom offered by data treatment through coding. Therefore, Spectra.jl is aimed to be used explicitly with other packages like  JuMP  for building models. The key is to provide functions for simplifying the life of the spectroscopist, while still leaving him all the freedom offered by treating data with a performant computer language.  Spectra.jl is particularly focused on large datasets because of the high speed of Julia's, e.g. for performing peak fitting along Infrared diffusion profiles. For peak fitting for instance, the JuMP interface offers a very flexible yet clear way to build models, that can be solve with solvers such as Ipopt or NLopt.  Please consult this documentation to learn using Spectra, do not forget to check the Tips_ section if you have issues, and please report anything you want!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#starting-notes", 
            "text": "Using Julia and Spectra.jl for processing your data is quite similar to Matlab, with the flexibility offered by the open-source and free character of Julia. Reading the docs is strongly recommended. A good start will be to read the  docs of Julia itself .  Programming can be done locally using your browser and the  IJulia notebooks , very similar to the IPython ones. For a Matlab-like interface, you can use  Atom with Juno .  For maintaining your packages up-to-date, something critical with the fast evolution of Julia packages, I suggest running each day of Julia use the update command:  Pkg.update()  Installation of Spectra is easy:  Pkg.add( Spectra )  See the Installation section for further details, in particular for Windows users.  Any help developing and maintaining this Spectra.jl package is welcome. You can fork the project on GitHub, modify it and commit your modifications. You can also add requests and everything on Github. Please do not hesitate to do so! The functionalities available in Spectra.jl are not exhaustive, and a little help to add new ones will be more that welcome.", 
            "title": "Starting Notes"
        }, 
        {
            "location": "/#citing-spectra", 
            "text": "You can cite Spectra as   LE LOSQ, C. (2016) Spectra.jl: a Julia package for processing spectroscopic data. Zenodo. 10.5281/zenodo.53940", 
            "title": "Citing Spectra"
        }, 
        {
            "location": "/#index", 
            "text": "The functions that are in Spectra.jl are listed below. See the other part of the documentation for further information.   Spectra.SavitzkyGolayFilter  Spectra.bandarea  Spectra.baseline  Spectra.bootperf  Spectra.bootsample  Spectra.ctxremoval  Spectra.gaussiennes  Spectra.gcvspl_julia  Spectra.lorentziennes  Spectra.mlregressor  Spectra.normal_dist  Spectra.peakhw  Spectra.pearson7  Spectra.poly  Spectra.polyfit  Spectra.pseudovoigts  Spectra.rameau  Spectra.splderivative_julia  Spectra.tlcorrection  Spectra.trapz  Spectra.xshift_correction  Spectra.xshift_direct", 
            "title": "Index"
        }, 
        {
            "location": "/Installation/", 
            "text": "Installation\n\n\n\n\nGeneral Instructions\n\n\nTwo ways of using Spectra.jl: [1] with using a cloud-computing approach and [2] with installing everything on your computer.\n\n\n[1] JuliaBox (https://www.juliabox.org/) allows you to run Julia in your browser. You still need to add Spectra.jl. To do so, run a notebook, and in the first instance, type\n\n\nPkg.add(\nSpectra\n)\n\n\n\n\n\nEverything shoul install without trouble. Requirements in Spectra.jl are extensive and will provide you all the packages needed by Spectra.jl's functions and examples.\n\n\n[2] You can download the current version of Julia and follow the installation instruction here: http://julialang.org/downloads/ . Then, run\n\n\nPkg.add(\nSpectra\n)\n\n\n\n\n\nIn the Julia shell. Please note that before installing Spectra.jl, the installation of the MatPlotLib library for Python is strongly recommended. Furthermore, some baseline codes call the SciKit learn library, again belonging to the Python ecosystem. If not already present in your system, those library should be automatically installed when trying to call for the first time Spectra. However, another good option is to install a Python scientific distribution before installing Julia. I recommend Anaconda Python that provides an easy-to-install and nice, fully-featured Python distribution with MatplotLib, SciPy, Numpy and SciKit learn. Follow installation instructions here:\n\n\nhttps://www.continuum.io/downloads\n\n\n\n\nWindows users\n\n\nFor Windows users, Spectra.jl will issue a WARNING message saying that GCVSPL.F is not compiled automatically upon installation, and will point to this page. You will need to compile GCVSPL.F by yourself for now. If you want to avoid this step, I recommand using JuliaBox.org where everything can run smoothly, or using Julia inside a free virtualbox Linux installation (https://www.virtualbox.org/). This makes things pretty easy. If you want to run Julia directly on your Windows system, you can try the following steps to compile GCVSPL.F with cygwin:\n\n\n1) create bin32 and bin64 folders in the /deps forlder;\n\n2) compile GCVSPL.F as a shared libgcvspl.dll library in ./bin32 or ./bin64. Using cygwin, this can be done as:\n\ni686-w64-mingw32-gfortran -o bin32/libgcvspl.dll -O3 -shared -static-libgfortran -static-libgcc src/gcvspline/*.f\n\nx86_64-w64-mingw32-gfortran -o bin64/libgcvspl.dll -O3 -shared -static-libgfortran -static-libgcc src/gcvspline/*.f\n\n3) if this is not working, you may want to also change the winpath in Spectra.jl,  see /Spectra/src/Spectra.jl line 38.\n\n\n\n\n\nI never tested those steps because I do not have a Windows system available, so I am not sure if they fully work. You might have to tweak things a little bit. This will be corrected soon. If anybody would like to help me with that, please submit a pull request of a working Windows installation procedure.\n\n\nAnother solution: at the moment, we are working on a port to Python of GCVspline, this will solve the problem for Windows users as we will simply PyCall the GCVspline library.\n\n\n\n\nError messages?\n\n\nIf you see various errors messages when trying to install Spectra or after a Pkg.update() command, please see the Tips section!", 
            "title": "Installation"
        }, 
        {
            "location": "/Installation/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/Installation/#general-instructions", 
            "text": "Two ways of using Spectra.jl: [1] with using a cloud-computing approach and [2] with installing everything on your computer.  [1] JuliaBox (https://www.juliabox.org/) allows you to run Julia in your browser. You still need to add Spectra.jl. To do so, run a notebook, and in the first instance, type  Pkg.add( Spectra )  Everything shoul install without trouble. Requirements in Spectra.jl are extensive and will provide you all the packages needed by Spectra.jl's functions and examples.  [2] You can download the current version of Julia and follow the installation instruction here: http://julialang.org/downloads/ . Then, run  Pkg.add( Spectra )  In the Julia shell. Please note that before installing Spectra.jl, the installation of the MatPlotLib library for Python is strongly recommended. Furthermore, some baseline codes call the SciKit learn library, again belonging to the Python ecosystem. If not already present in your system, those library should be automatically installed when trying to call for the first time Spectra. However, another good option is to install a Python scientific distribution before installing Julia. I recommend Anaconda Python that provides an easy-to-install and nice, fully-featured Python distribution with MatplotLib, SciPy, Numpy and SciKit learn. Follow installation instructions here:  https://www.continuum.io/downloads", 
            "title": "General Instructions"
        }, 
        {
            "location": "/Installation/#windows-users", 
            "text": "For Windows users, Spectra.jl will issue a WARNING message saying that GCVSPL.F is not compiled automatically upon installation, and will point to this page. You will need to compile GCVSPL.F by yourself for now. If you want to avoid this step, I recommand using JuliaBox.org where everything can run smoothly, or using Julia inside a free virtualbox Linux installation (https://www.virtualbox.org/). This makes things pretty easy. If you want to run Julia directly on your Windows system, you can try the following steps to compile GCVSPL.F with cygwin:  1) create bin32 and bin64 folders in the /deps forlder;\n\n2) compile GCVSPL.F as a shared libgcvspl.dll library in ./bin32 or ./bin64. Using cygwin, this can be done as:\n\ni686-w64-mingw32-gfortran -o bin32/libgcvspl.dll -O3 -shared -static-libgfortran -static-libgcc src/gcvspline/*.f\n\nx86_64-w64-mingw32-gfortran -o bin64/libgcvspl.dll -O3 -shared -static-libgfortran -static-libgcc src/gcvspline/*.f\n\n3) if this is not working, you may want to also change the winpath in Spectra.jl,  see /Spectra/src/Spectra.jl line 38.  I never tested those steps because I do not have a Windows system available, so I am not sure if they fully work. You might have to tweak things a little bit. This will be corrected soon. If anybody would like to help me with that, please submit a pull request of a working Windows installation procedure.  Another solution: at the moment, we are working on a port to Python of GCVspline, this will solve the problem for Windows users as we will simply PyCall the GCVspline library.", 
            "title": "Windows users"
        }, 
        {
            "location": "/Installation/#error-messages", 
            "text": "If you see various errors messages when trying to install Spectra or after a Pkg.update() command, please see the Tips section!", 
            "title": "Error messages?"
        }, 
        {
            "location": "/PreProcessing/", 
            "text": "Pre-Processing\n\n\n\n\nTemperature and frequency corrections for Raman spectra\n\n\nRaman spectra can be corrected from temperature and excitation line effects using this function.\n\n\n#\n\n\nSpectra.tlcorrection\n \n \nMethod\n.\n\n\ntlcorrection\n(\ndata\n::\nArray\n{\nFloat64\n}\n,\ntemp\n::\nFloat64\n,\nwave\n::\nFloat64\n;\ncorrection\n=\nlong\n,\nnormalisation\n=\narea\n,\ndensity\n=\n2210\n.\n0\n)\n\n\n\n\n\n\nINPUTS:\n\n\ndata\n:\n \nArray\n{\nFloat64\n},\n \ninput\n \nspectrum\n \nwith\n \nx\n \nand\n \ny\n \nin\n \nfirst\n \nand\n \nsecond\n \ncolumns\n \nrespectively\n;\n\n\n\ntemp\n:\n \nFloat64\n,\n \nthe\n \ntemperature\n \nin\n \n\u00b0\nC\n;\n\n\n\nwave\n:\n \nFloat64\n,\n \nthe\n \nwavenumber\n \nat\n \nwhich\n \nthe\n \nspectrum\n \nwas\n \nacquirred\n \nin\n \nnm\n.\n\n\n\n\n\n\nOPTIONS:\n\n\ncorrection\n:\n \nString\n,\n \nthe\n \nequation\n \nused\n \nfor\n \nthe\n \ncorrection\n.\n \nChoose\n \nbetween\n \nlong\n,\n \ngaleener\n,\n \nor\n \nhehlen\n.\n \nDefault\n \n=\n \nlong\n.\n\n\n\nnormalisation\n:\n \nString\n,\n \nindicate\n \nif\n \nyou\n \nwant\n \nto\n \nnormalise\n \nyour\n \nsignal\n \nor\n \nnot\n.\n \nChoose\n \nbetween\n \nintensity\n,\n \narea\n,\n \nor\n \nno\n.\n \nDefault\n \n=\n \narea\n.\n\n\n\ndensity\n:\n \nFloat64\n,\n \nthe\n \ndensity\n \nof\n \nthe\n \nstudied\n \nmaterial\n \nin\n \nkg\n \nm\n-\n3\n,\n \nto\n \nbe\n \nused\n \nwith\n \nthe\n \nhehlen\n \nequation\n.\n \nDefault\n \n=\n \n2210.0\n \n(\ndensity\n \nof\n \nsilica\n).\n\n\n\n\n\n\nOUTPUTS:\n\n\n(are combined in one array if only one output name is given)\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nx\n \nvalues\n;\n\n\n\nlong\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \ncorrected\n \ny\n \nvalues\n;\n\n\n\neselong\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nerrors\n \ncalculated\n \nas\n \nsqrt\n(\ny\n)\n \non\n \nraw\n \ndata\n \nand\n \npropagated\n \nafter\n \nthe\n \ncorrection\n.\n\n\n\n\n\n\nNOTES:\n\n\nThis correction uses the formula reported in Galeener and Sen (1978), Mysen et al. (1982), Brooker et al. (1988) and Hehlen et al. (2010).\n\n\nThe \"galeener\" equation is the exact one reported in Galeener and Sen (1978), which is a modification from Shuker and Gammon (1970) for accounting of (vo - v)^4 dependence of the Raman intensity. See also Brooker et al. (1988) for further discussion.\n\n\nThe \"long\" equation is that of Galeener and Sen (1978) corrected by a vo^3 coefficient for removing the cubic meter dimension of the equation of \"galeener\". This equation has been used in Mysen et al. (1982), Neuville and Mysen (1996) and Le Losq et al. (2012).\n\n\nThe \"hehlen\" equation is that reported in Hehlen et al. (2010). It actually originates before this publication (Brooker et al. 1988). It uses a different correction that avoid crushing the signal below 500 cm-1. THerefore, it has the advantage of keeping intact the Boson peak signal in glasses.\n\n\nsource\n\n\n\n\nRemoving cristal or epoxy signals\n\n\nSpectra.jl contains a function that helps removing the signal from crystals in the Raman spectra of glasses. Two spectra are needed: that of the mixed crystal+glass signals, and that of the pure cristal signals. Please note that it also can be used to remove signal from epoxy.\n\n\nThis function is still under test and experimental. Further details on the code will be provided soon. For now, only a short description is provided.\n\n\n#\n\n\nSpectra.ctxremoval\n \n \nMethod\n.\n\n\nctxremoval(liste,in_path,out_path,roi_all;input_properties=(\n   \n,0),algorithm=\nFastICA\n,plot_intermediate_show = \nno\n,plot_mixing_show = \nyes\n,plot_final_show = \nno\n,save_fig_switch = \nyes\n, shutdown = 1300.,scaling=100.)\n\n\n\n\n\nINPUTS\n\n\nliste\n:\n \nArray\n{\nFloat64\n},\n \nan\n \narray\n \ncontaning\n \nthe\n \ninformation\n \nfor\n \ngetting\n \nthe\n \nspectra\n.\n \n\n    \nColumn\n \n1\n:\n \nthe\n \nname\n \nand\n \nrelative\n \npath\n \nfor\n \nthe\n \ncrystal\n \nspectra\n;\n \n\n    \nColumn\n \n2\n:\n \nthe\n \nname\n \nand\n \nrelative\n \npath\n \nfor\n \nthe\n \n(\nmixed\n)\n \nglass\n \nspectra\n;\n\n\n    \nColumn\n \n3\n:\n \nsmo_water\n,\n \nthe\n \ncoefficient\n \nof\n \nsmothing\n \nfor\n \nthe\n \nspline\n \nthat\n \nfits\n \nthe\n \nbackgrous\n \nbelow\n \nthe\n \nsignal\n \nof\n \nwater\n \n(\nif\n \nany\n)\n \nin\n \nthe\n \nglass\n \nspectra\n\n\n    \nColumn\n \n4\n:\n \nnumber\n \nof\n \niteration\n \nfor\n \nthe\n \ngeneration\n \nof\n \nnew\n \nmixed\n \nspectra\n\n\n    \nColumn\n \n5\n:\n \nthe\n \nK_Start\n \nparameter\n,\n \nset\n \nat\n \n0.0\n\n\n    \nColumn\n \n6\n:\n \nthe\n \nK_increament\n \nparameter\n,\n \nfor\n \nmixing\n \nthe\n \nsignals\n\n\n\nin_path\n:\n \nString\n,\n \nthe\n \nrelative\n \nlocation\n \nof\n \nthe\n \ndata\n,\n \ne\n.\ng\n.\n \n./raw/\n\n\n\nout_path\n:\n \nString\n,\n \nthe\n \nrelative\n \nlocation\n \nwhere\n \nyou\n \nwant\n \nto\n \nsave\n \nthe\n \ncorrected\n \nspectra\n,\n \ne\n.\ng\n.\n \n./treated/\n \n\n\nroi_all\n:\n \nTuple\n,\n \ncontains\n \n2\n \narrays\n \nand\n \n2\n \nFloat64\n \nnumbers\n.\n \nThe\n \n2\n \narrays\n \nindicate\n \nthe\n \nregions\n \nof\n \ninterest\n \nwhere\n \nthe\n \nbackground\n \ncorrection\n \nis\n \napplied\n,\n \nfor\n \nthe\n \ncristal\n \nand\n \nthe\n \nglass\n.\n \nThe\n  \n2\n \nfloat\n \nnumbers\n \nindicate\n \nthe\n \nstarting\n \nand\n \nending\n \nfrequency\n \nof\n \nthe\n \npeak\n \nused\n \nto\n \ncorrect\n \nthe\n \nspectra\n \nfrom\n \nany\n \nshift\n \nin\n \nfrequency\n.\n \nFor\n \ninstance\n:\n\n\n    \nThose\n \nare\n \nthe\n \nroi\n \nfor\n \nfitting\n \nthe\n \nbaseline\n \non\n \nthe\n \ncrystal\n \n(\nroi_ctx\n)\n \nand\n \nglass\n \n(\nroi_glass\n)\n \nsignals\n:\n\n\n    \nroi_ctx\n \n=\n \n[\n1260\n.\n \n2000\n.;\n2000\n.\n \n4000\n.]\n\n\n    \nroi_glass\n \n=\n \n[\n1260\n.\n \n2000\n.;\n2000\n.\n \n3000\n.;\n3750\n.\n \n4000\n.]\n\n\n    \nWe\n \nhave\n \na\n \nstrong\n \npeak\n \nfrom\n \nthe\n \ncrystal\n \nat\n \n~\n650\n \ncm\n-\n1\n \nthat\n \nwe\n \ncan\n \nuse\n \nto\n \ncorrect\n \nthe\n \nspectra\n \nfrom\n \nany\n \nshift\n \nin\n \nfrequency\n.\n \nSo\n \nwe\n \nindicate\n \nthe\n \nvalues\n \nhere\n:\n\n\n    \nroi_xshift_low\n \n=\n \n655\n.\n\n\n    \nroi_xshift_high\n \n=\n \n670\n.\n\n\n    \nThen\n \nwe\n \nconstruct\n \nthe\n \nfinal\n \ntuple\n \nas\n:\n\n\n    \nroi_all\n \n=\n \n(\nroi_ctx\n,\nroi_glass\n,\nroi_xshift_low\n,\nroi_xshift_high\n)\n\n\n\n\n\n\nOPTIONS\n\n\ninput_properties\n:\n \nTuple\n,\n \nthis\n \ntuple\n \ncontains\n \nthe\n \ndelimiter\n \nand\n \nthe\n \nnumber\n \nof\n \nlines\n \nto\n \nskip\n \nin\n \nthe\n \nraw\n \ndata\n \nfiles\n.\n \nDefault\n \n=\n \n(\n  \n,\n0\n);\n\n\n\nalgorithm\n:\n \nString\n,\n \nThis\n \nindicates\n \nif\n \nthe\n \nFastICA\n \nor\n \nthe\n \nNon\n-\nnegative\n \nMatrix\n \nFactorisation\n \n(\nNMF\n)\n \nalgorithms\n \nfrom\n \nSciKit\n \nLearn\n \nwill\n \nbe\n \nused\n.\n \nDefault\n \n=\n \nFastICA\n;\n\n\n\nplot_intermediate_show\n:\n \nString\n,\n \nThis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nIt\n \ndisplays\n \nthe\n \nintermediate\n \nfigures\n.\n \nDefault\n \n=\n \nno\n;\n\n\n\nplot_mixing_show\n:\n \nString\n,\n \nThis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nIt\n \ndisplays\n \nthe\n \nfigures\n \nshowing\n \nthe\n \nmixing\n \nstep\n.\n \nDefault\n \n=\n \nyes\n;\n\n\n\nplot_final_show\n:\n \nString\n,\n \nThis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nIt\n \ndisplays\n \nthe\n \nfinal\n \nfigures\n,\n \nshowing\n \nthe\n \nbackground\n \nsubtraction\n \nand\n \nthe\n \nretrieved\n \nsignals\n.\n \nDefault\n \n=\n \nyes\n;\n\n\n\nsave_fig_switch\n:\n \nString\n,\n \nThis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nIt\n \nindicates\n \nif\n \nyou\n \nwant\n \nto\n \nsave\n \nthe\n \nfinal\n \nfigures\n \nin\n \nthe\n \nlocation\n \nindicated\n \nby\n \nout_path\n;\n\n\n\nshutdown\n:\n \nFloat64\n,\n \nindicates\n \nwhere\n \nyou\n \nconsider\n \nthe\n \nsignals\n \nfrom\n \nsilicate\n \nunits\n \nto\n \nstop\n.\n \nDefault\n \n=\n \n1300.0\n;\n\n\n\nscaling\n:\n \nFloat64\n,\n \nthe\n \nretrieved\n \nspectra\n \nare\n \nscaled\n \nto\n \nthe\n \noriginal\n \nspectra\n \nusing\n \nthe\n \nBoson\n \npeak\n,\n \nlocated\n \n~\n \n60\n-\n80\n \ncm\n-\n1\n.\n \nThis\n \nparameters\n \nindicates\n \nwhere\n \nyou\n \nconsider\n \nthe\n \nBoson\n \npeak\n \nto\n \nstop\n \nfor\n \nthe\n \nscaling\n \nprocedure\n.\n \nNo\n \nneed\n \nto\n \nput\n \na\n \ntoo\n \nhigh\n \nvalue\n,\n \nas\n \nyou\n \nmight\n \nget\n \nstrong\n \ncrystal\n \nsignals\n \nat\n \nfrequencies\n \n \n100\n-\n150\n \ncm\n-\n1\n.\n\n\n\n\n\n\nOUTPUTS\n\n\nAll the corrected spectra and figures are saved in the location indicated in out_path. No direct outputs in Julia.\n\n\n\n\n\nsource\n\n\n\n\nBaseline subtraction\n\n\nBaseline subtraction can be made with using the baseline function:\n\n\n#\n\n\nSpectra.baseline\n \n \nMethod\n.\n\n\nbaseline\n(\nx\n::\nArray\n{\nFloat64\n}\n,\ny\n::\nArray\n{\nFloat64\n}\n,\nroi\n::\nArray\n{\nFloat64\n}\n,\nbasetype\n::\nAbstractString\n;\np\n=\n1\n.\n0\n,\nSplOrder\n=\n3\n,\nroi_out\n=\nno\n)\n\n\n\n\n\n\nBaseline subtraction can be made with using the baseline function:\n\n\nINPUTS:\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nx\n \nvalues\n;\n\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \ny\n \nvalues\n;\n\n\n\nroi\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nregion of interest\n,\n \ni\n.\ne\n.\n \nthe\n \nplaces\n \nwhere\n \nyou\n \nwant\n \nto\n \nfit\n \nthe\n \nbaseline\n.\n \nFor\n \ninstance\n,\n \nif\n \nthe\n \nbaseline\n \nshould\n \nfit\n \nthe\n \nregions\n \ncomprised\n \nbetween\n \n750\n \nand\n \n800\n \ncm\n^{-\n1\n},\n \nand\n \n1250\n \nand\n \n1300\n \ncm\n^{-\n1\n}:\n \nroi\n \n=\n \n[\n750\n.\n \n800\n.;\n \n1250\n.\n \n1300\n.];\n\n\n\nbasetype\n:\n \nAbstractString\n,\n \nthe\n \ntype\n \nof\n \nbaseline\n \nthat\n \nyou\n \nwant\n \nto\n \nuse\n.\n \nFor\n \nnow\n,\n \npolynomial\n \nand\n \ncubic\n \nspline\n \nbaselines\n \nare\n \navailable\n.\n \nIndicate\n \nthe\n \ntype\n \nyou\n \nwant\n \nas\n:\n\n\n    \nPolynomial\n \nbaseline\n:\n \nenter\n \npoly\n \nfor\n \nbasetype\n,\n \nthen\n \nthe\n \npolynomial\n \ndegree\n \nas\n \np\n.\n\n\n    \nDierckx\n \ncubic\n \nspline\n \nbaseline\n:\n \nenter\n \nDspline\n \nfor\n \nbasetype\n,\n \nthen\n \nthe\n \nsmoothing\n \ndegree\n \nas\n \np\n.\n\n\n    \nGeneralised\n \nCross\n-\nValidated\n \nbaseline\n:\n \nenter\n \ngsvspline\n \nfor\n \nbasetype\n,\n \nthen\n \nthe\n \nsmoothing\n \ndegree\n \nas\n \np\n.\n \n\n    \nKernel\n \nRidge\n \nRegression\n:\n \nenter\n \nKRregression\n \nfor\n \nbasetype\n,\n \nno\n \nneed\n \nto\n \nprovide\n \np\n.\n\n\n    \nSupport\n \nVector\n \nMachines\n \nregression\n:\n \nenter\n \nSVMregression\n \nfor\n \nbasetype\n,\n \nno\n \nneed\n \nto\n \nprovide\n \np\n.\n\n\n\n\n\n\nOPTIONS:\n\n\np:: Float64, if using gcvspline or Dspline, this number indicates the spline smoothing coefficient. If using \npoly\n, it is the degree of the polynomial function to be fitted. Please enter a float number (1.0, 2.0 or 3.0 for splines of order 1, 2 or 3), and it is automatically converted to an Integer for the polyfit function. Default = 1.0.\n\nSplOrder: Integer, the spline coefficient to be used with the Dspline or gcvspline options. Default = 3.\n\nroi_out: String, \nno\n or \nyes\n. This will result in an additional output matrix containing the y signal in the roi regions of interest, which can then be used to plot and to evaluate the roi provided to the baseline function.\n\n\n\n\n\nOUTPUTS:\n\n\n(are combined in a tuple in one array if only one output variable is provided)\n\n\ny_corr\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nspectrum\n \ncorrected\n \nfrom\n \nits\n \nbaseline\n;\n\n\n\nbass\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nbaseline\n.\n\n\n\n\n\n\nOPTIONAL OUTPUT:\n\n\ny_roi_out\n:\n \nArray\n{\nFloat64\n},\n \nan\n \n2\n \ncolumn\n \narray\n \ncontaining\n \nthe\n \ninitial\n \nx\n-\ny\n \npairs\n \nof\n \nthe\n \nsignal\n \nin\n \nthe\n \nroi\n \nregions\n \nof\n \ninterest\n.\n\n\n\n\n\n\nNOTES:\n\n\nErrors on measurenements are automatically provided as sqrt(y) in gcvspline. For further options, please use the gcvspl and splderivative functions that directly call the GCVSPL and SPLDER function of the gcvspl.f program (Holtring, 1986). Further informations for the use of splines are given in the Splines section, see :ref:\nSplines\n.\n\n\nThe Kernel Ridge and Support Vector Machines regression algorithms call the Scikit Learn library, available in Python. This library thus SHOULD be installed. They are machine learning algorithms that will try to automatically fit the baseline in the provided regions of interest. They are slower that splines, but have the advantage of avoiding the (sometimes painful) tuning of the spline coefficients.\n\n\nThe Kernel Ridge and Support Vector Machines regression algorithms used a Cross-Validated approach to increase the generalisation and avoid overfitting. The GridSearchCV function of SciKit Learn is called, with 5 fold cross-validation and the following gridsearch parameters:\n\n\n-\n \nFor\n \nKRregression\n:\n \nparam_grid\n=\nDict\n(\nalpha\n=\n \n[\n1\ne0\n,\n \n0.1\n,\n \n1\ne\n-\n2\n,\n \n1\ne\n-\n3\n]\n,\ngamma\n=\n \nlogspace\n(\n-4\n,\n \n4\n,\n \n9\n));\n\n\n-\n \nFor\n \nSVMregression\n:\n \nparam_grid\n=\nDict\n(\nC\n=\n \n[\n1\ne0\n,\n \n1\ne1\n,\n \n1\ne2\n,\n \n1\ne3\n]\n,\ngamma\n=\n \nlogspace\n(\n-4\n,\n \n4\n,\n \n9\n)).\n\n\n\n\n\n\nPlease see the SciKit Learn documentation at http://scikit-learn.org/stable/index.html for further details on the implementation of those technics, together with the source code of Spectra.jl.\n\n\nEXAMPLES:\n\n\nFor instance, for subtracting a constant baseline between 1250 and 1300 cm^{-1}:\n\n\nroi = [1250. 1300.]\n\nbasetype = \npoly\n\n\ny_corr, bas = baseline(x,y,roi,\npoly\n,p=0.0)\n\n\n\n\n\nFor a linear baseline,\n\n\nbas = baseline(x,y,roi,\npoly\n,p=1.0)\n\n\n\n\n\nFor a second order polynomial baseline,\n\n\nbas = baseline(x,y,roi,\npoly\n,p=2.0)\n\n\n\n\n\nwith the last coefficient will be the one in front of x^2. This can continue as you want by adding more 1.0 values to p.\n\n\nFor a cubic spline baseline fitting the basis of a peak centered at 1100 cm^{-1} and with basis at 900 and 1250 cm^{-1}:\n\n\nroi = [890. 910.; 1250. 1300.]\n\nbasetype = \nDspline\n\n\nbas = baseline(x,y,roi,basetype,p=0.01)\n\n\n\n\n\np there is the smoothing parameter used. The cubic spline uses the Dierckx package initially written in Fortran and used in Julia: https://github.com/kbarbary/Dierckx.jl\n\n\nsource\n\n\n\n\nFrequency shifts correction\n\n\nIn case your spectra are shifted from a reference value, Spectra offers several functions that allows you to correct it from this shift.\n\n\nTo correct a spectrum from a shift of P wavenumbers, you can simply call:\n\n\n#\n\n\nSpectra.xshift_direct\n \n \nMethod\n.\n\n\nxshift_direct(original_x::Array{Float64}, original_y::Array{Float64}, p::Float64)\n\n\n\n\n\nTo correct a spectrum for a p shift in X.\n\n\nUsed in xshift_correction.\n\n\nINPUTS:\n\n\noriginal_x\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nx\n \nvalues\n;\n\n\n\noriginal_y\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \ny\n \nvalues\n \nassociated\n \nwith\n \nx\n;\n\n\n\np\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nvalue\n \nof\n \nhow\n \nmuch\n \nx\n \nshould\n \nbe\n \nshifted\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\noriginal_x\n:\n \nArray\n{\nFloat64\n},\n \nsame\n \nas\n \ninput\n;\n\n\n\ncorrected_y\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \ny\n \nvalues\n \ncorrected\n \nfrom\n \nthe\n \np\n \nshift\n \nin\n \noriginal_x\n;\n \n\n\np\n:\n \nArray\n{\nFloat64\n},\n \nsame\n \nas\n \ninput\n.\n\n\n\n\n\n\nsource\n\n\nSometime, two signals from the same mineral show a shift in the X axis, while they share a common X axis. To correct from such thing, you can use the function:\n\n\n#\n\n\nSpectra.xshift_correction\n \n \nMethod\n.\n\n\nxshift_correction(full_x::Array{Float64}, full_shifted_y::Array{Float64}, ref_x::Array{Float64}, ref_y::Array{Float64},shifted_y::Array{Float64})\n\n\n\n\n\nTo correct a shift between two spectra using a reference peak.\n\n\nINPUTS:\n\n\nfull_x\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nx\n \nvalues\n \nthat\n \nare\n \nnot\n \ngood\n;\n\n\n\nfull_shifted_y\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \ny\n \nvalues\n \nassociated\n \nwith\n \nfull_x\n;\n\n\n\nref_x\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nx\n \nvalues\n \nthat\n \nare\n \ngood\n;\n\n\n\nref_y\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \ny\n \nvalues\n \nassociated\n \nwith\n \nref_x\n.\n\n\n\nshifted_y\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \ny\n \nvalues\n \nassociated\n \nwith\n \na\n \nselected\n \nrange\n \nof\n \nfull_x\n \nthat\n \ncorresponds\n \nto\n \nref_x\n \n(\nfor\n \ninstance\n,\n \na\n \nspecific\n \npeak\n \nthat\n \nyou\n \nwant\n \nto\n \nuse\n \nto\n \ncorrect\n \nthe\n \nshift\n).\n\n\n\n\n\n\nOUTPUTS:\n\n\nfull_x\n:\n \nArray\n{\nFloat64\n},\n \nsame\n \nas\n \ninput\n;\n\n\n\ncorrected_y\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nfull_shifted_y\n \nvalues\n \ncorrected\n \nfrom\n \nthe\n \nshift\n;\n \n\n\np\n:\n \nArray\n{\nFloat64\n},\n \nsame\n \nas\n \ninput\n.\n\n\n\n\n\n\nref_x is the common X axis of two particular ref_y and shifted_y signals, that should be for instance an intense and well defined peak in your spectra. If ref_y and shifted_y do not share the same X axis, you can use first the Dierckx spline to re-sample one of them and have both sharing a common X axis. See the examples for further details.\n\n\nsource\n\n\n\n\nSmoothing\n\n\n#\n\n\nSpectra.SavitzkyGolayFilter\n \n \nType\n.\n\n\nSavitzkyGolayFilter{M,N}(data)\n\n\n\n\n\nSavitzky-Golay filter of window half-width M and degree N M is the number of points before and after to interpolate, i.e. the full width of the window is 2M+1 Code from https://medium.com/@acidflask/smoothing-data-with-julia-s-generated-functions-c80e240e05f3#.45v03x6it\n\n\nsource", 
            "title": "Pre-Processing"
        }, 
        {
            "location": "/PreProcessing/#pre-processing", 
            "text": "", 
            "title": "Pre-Processing"
        }, 
        {
            "location": "/PreProcessing/#temperature-and-frequency-corrections-for-raman-spectra", 
            "text": "Raman spectra can be corrected from temperature and excitation line effects using this function.  #  Spectra.tlcorrection     Method .  tlcorrection ( data :: Array { Float64 } , temp :: Float64 , wave :: Float64 ; correction = long , normalisation = area , density = 2210 . 0 )   INPUTS:  data :   Array { Float64 },   input   spectrum   with   x   and   y   in   first   and   second   columns   respectively ;  temp :   Float64 ,   the   temperature   in   \u00b0 C ;  wave :   Float64 ,   the   wavenumber   at   which   the   spectrum   was   acquirred   in   nm .   OPTIONS:  correction :   String ,   the   equation   used   for   the   correction .   Choose   between   long ,   galeener ,   or   hehlen .   Default   =   long .  normalisation :   String ,   indicate   if   you   want   to   normalise   your   signal   or   not .   Choose   between   intensity ,   area ,   or   no .   Default   =   area .  density :   Float64 ,   the   density   of   the   studied   material   in   kg   m - 3 ,   to   be   used   with   the   hehlen   equation .   Default   =   2210.0   ( density   of   silica ).   OUTPUTS:  (are combined in one array if only one output name is given)  x :   Array { Float64 },   containing   the   x   values ;  long :   Array { Float64 },   containing   the   corrected   y   values ;  eselong :   Array { Float64 },   containing   the   errors   calculated   as   sqrt ( y )   on   raw   data   and   propagated   after   the   correction .   NOTES:  This correction uses the formula reported in Galeener and Sen (1978), Mysen et al. (1982), Brooker et al. (1988) and Hehlen et al. (2010).  The \"galeener\" equation is the exact one reported in Galeener and Sen (1978), which is a modification from Shuker and Gammon (1970) for accounting of (vo - v)^4 dependence of the Raman intensity. See also Brooker et al. (1988) for further discussion.  The \"long\" equation is that of Galeener and Sen (1978) corrected by a vo^3 coefficient for removing the cubic meter dimension of the equation of \"galeener\". This equation has been used in Mysen et al. (1982), Neuville and Mysen (1996) and Le Losq et al. (2012).  The \"hehlen\" equation is that reported in Hehlen et al. (2010). It actually originates before this publication (Brooker et al. 1988). It uses a different correction that avoid crushing the signal below 500 cm-1. THerefore, it has the advantage of keeping intact the Boson peak signal in glasses.  source", 
            "title": "Temperature and frequency corrections for Raman spectra"
        }, 
        {
            "location": "/PreProcessing/#removing-cristal-or-epoxy-signals", 
            "text": "Spectra.jl contains a function that helps removing the signal from crystals in the Raman spectra of glasses. Two spectra are needed: that of the mixed crystal+glass signals, and that of the pure cristal signals. Please note that it also can be used to remove signal from epoxy.  This function is still under test and experimental. Further details on the code will be provided soon. For now, only a short description is provided.  #  Spectra.ctxremoval     Method .  ctxremoval(liste,in_path,out_path,roi_all;input_properties=(     ,0),algorithm= FastICA ,plot_intermediate_show =  no ,plot_mixing_show =  yes ,plot_final_show =  no ,save_fig_switch =  yes , shutdown = 1300.,scaling=100.)  INPUTS  liste :   Array { Float64 },   an   array   contaning   the   information   for   getting   the   spectra .  \n\n     Column   1 :   the   name   and   relative   path   for   the   crystal   spectra ;  \n\n     Column   2 :   the   name   and   relative   path   for   the   ( mixed )   glass   spectra ; \n\n     Column   3 :   smo_water ,   the   coefficient   of   smothing   for   the   spline   that   fits   the   backgrous   below   the   signal   of   water   ( if   any )   in   the   glass   spectra \n\n     Column   4 :   number   of   iteration   for   the   generation   of   new   mixed   spectra \n\n     Column   5 :   the   K_Start   parameter ,   set   at   0.0 \n\n     Column   6 :   the   K_increament   parameter ,   for   mixing   the   signals  in_path :   String ,   the   relative   location   of   the   data ,   e . g .   ./raw/  out_path :   String ,   the   relative   location   where   you   want   to   save   the   corrected   spectra ,   e . g .   ./treated/   roi_all :   Tuple ,   contains   2   arrays   and   2   Float64   numbers .   The   2   arrays   indicate   the   regions   of   interest   where   the   background   correction   is   applied ,   for   the   cristal   and   the   glass .   The    2   float   numbers   indicate   the   starting   and   ending   frequency   of   the   peak   used   to   correct   the   spectra   from   any   shift   in   frequency .   For   instance : \n\n     Those   are   the   roi   for   fitting   the   baseline   on   the   crystal   ( roi_ctx )   and   glass   ( roi_glass )   signals : \n\n     roi_ctx   =   [ 1260 .   2000 .; 2000 .   4000 .] \n\n     roi_glass   =   [ 1260 .   2000 .; 2000 .   3000 .; 3750 .   4000 .] \n\n     We   have   a   strong   peak   from   the   crystal   at   ~ 650   cm - 1   that   we   can   use   to   correct   the   spectra   from   any   shift   in   frequency .   So   we   indicate   the   values   here : \n\n     roi_xshift_low   =   655 . \n\n     roi_xshift_high   =   670 . \n\n     Then   we   construct   the   final   tuple   as : \n\n     roi_all   =   ( roi_ctx , roi_glass , roi_xshift_low , roi_xshift_high )   OPTIONS  input_properties :   Tuple ,   this   tuple   contains   the   delimiter   and   the   number   of   lines   to   skip   in   the   raw   data   files .   Default   =   (    , 0 );  algorithm :   String ,   This   indicates   if   the   FastICA   or   the   Non - negative   Matrix   Factorisation   ( NMF )   algorithms   from   SciKit   Learn   will   be   used .   Default   =   FastICA ;  plot_intermediate_show :   String ,   This   should   be   equal   to   yes   or   no .   It   displays   the   intermediate   figures .   Default   =   no ;  plot_mixing_show :   String ,   This   should   be   equal   to   yes   or   no .   It   displays   the   figures   showing   the   mixing   step .   Default   =   yes ;  plot_final_show :   String ,   This   should   be   equal   to   yes   or   no .   It   displays   the   final   figures ,   showing   the   background   subtraction   and   the   retrieved   signals .   Default   =   yes ;  save_fig_switch :   String ,   This   should   be   equal   to   yes   or   no .   It   indicates   if   you   want   to   save   the   final   figures   in   the   location   indicated   by   out_path ;  shutdown :   Float64 ,   indicates   where   you   consider   the   signals   from   silicate   units   to   stop .   Default   =   1300.0 ;  scaling :   Float64 ,   the   retrieved   spectra   are   scaled   to   the   original   spectra   using   the   Boson   peak ,   located   ~   60 - 80   cm - 1 .   This   parameters   indicates   where   you   consider   the   Boson   peak   to   stop   for   the   scaling   procedure .   No   need   to   put   a   too   high   value ,   as   you   might   get   strong   crystal   signals   at   frequencies     100 - 150   cm - 1 .   OUTPUTS  All the corrected spectra and figures are saved in the location indicated in out_path. No direct outputs in Julia.  source", 
            "title": "Removing cristal or epoxy signals"
        }, 
        {
            "location": "/PreProcessing/#baseline-subtraction", 
            "text": "Baseline subtraction can be made with using the baseline function:  #  Spectra.baseline     Method .  baseline ( x :: Array { Float64 } , y :: Array { Float64 } , roi :: Array { Float64 } , basetype :: AbstractString ; p = 1 . 0 , SplOrder = 3 , roi_out = no )   Baseline subtraction can be made with using the baseline function:  INPUTS:  x :   Array { Float64 },   containing   the   x   values ;  y :   Array { Float64 },   containing   the   y   values ;  roi :   Array { Float64 },   containing   the   region of interest ,   i . e .   the   places   where   you   want   to   fit   the   baseline .   For   instance ,   if   the   baseline   should   fit   the   regions   comprised   between   750   and   800   cm ^{- 1 },   and   1250   and   1300   cm ^{- 1 }:   roi   =   [ 750 .   800 .;   1250 .   1300 .];  basetype :   AbstractString ,   the   type   of   baseline   that   you   want   to   use .   For   now ,   polynomial   and   cubic   spline   baselines   are   available .   Indicate   the   type   you   want   as : \n\n     Polynomial   baseline :   enter   poly   for   basetype ,   then   the   polynomial   degree   as   p . \n\n     Dierckx   cubic   spline   baseline :   enter   Dspline   for   basetype ,   then   the   smoothing   degree   as   p . \n\n     Generalised   Cross - Validated   baseline :   enter   gsvspline   for   basetype ,   then   the   smoothing   degree   as   p .  \n\n     Kernel   Ridge   Regression :   enter   KRregression   for   basetype ,   no   need   to   provide   p . \n\n     Support   Vector   Machines   regression :   enter   SVMregression   for   basetype ,   no   need   to   provide   p .   OPTIONS:  p:: Float64, if using gcvspline or Dspline, this number indicates the spline smoothing coefficient. If using  poly , it is the degree of the polynomial function to be fitted. Please enter a float number (1.0, 2.0 or 3.0 for splines of order 1, 2 or 3), and it is automatically converted to an Integer for the polyfit function. Default = 1.0.\n\nSplOrder: Integer, the spline coefficient to be used with the Dspline or gcvspline options. Default = 3.\n\nroi_out: String,  no  or  yes . This will result in an additional output matrix containing the y signal in the roi regions of interest, which can then be used to plot and to evaluate the roi provided to the baseline function.  OUTPUTS:  (are combined in a tuple in one array if only one output variable is provided)  y_corr :   Array { Float64 },   the   spectrum   corrected   from   its   baseline ;  bass :   Array { Float64 },   the   baseline .   OPTIONAL OUTPUT:  y_roi_out :   Array { Float64 },   an   2   column   array   containing   the   initial   x - y   pairs   of   the   signal   in   the   roi   regions   of   interest .   NOTES:  Errors on measurenements are automatically provided as sqrt(y) in gcvspline. For further options, please use the gcvspl and splderivative functions that directly call the GCVSPL and SPLDER function of the gcvspl.f program (Holtring, 1986). Further informations for the use of splines are given in the Splines section, see :ref: Splines .  The Kernel Ridge and Support Vector Machines regression algorithms call the Scikit Learn library, available in Python. This library thus SHOULD be installed. They are machine learning algorithms that will try to automatically fit the baseline in the provided regions of interest. They are slower that splines, but have the advantage of avoiding the (sometimes painful) tuning of the spline coefficients.  The Kernel Ridge and Support Vector Machines regression algorithms used a Cross-Validated approach to increase the generalisation and avoid overfitting. The GridSearchCV function of SciKit Learn is called, with 5 fold cross-validation and the following gridsearch parameters:  -   For   KRregression :   param_grid = Dict ( alpha =   [ 1 e0 ,   0.1 ,   1 e - 2 ,   1 e - 3 ] , gamma =   logspace ( -4 ,   4 ,   9 ));  -   For   SVMregression :   param_grid = Dict ( C =   [ 1 e0 ,   1 e1 ,   1 e2 ,   1 e3 ] , gamma =   logspace ( -4 ,   4 ,   9 )).   Please see the SciKit Learn documentation at http://scikit-learn.org/stable/index.html for further details on the implementation of those technics, together with the source code of Spectra.jl.  EXAMPLES:  For instance, for subtracting a constant baseline between 1250 and 1300 cm^{-1}:  roi = [1250. 1300.]\n\nbasetype =  poly \n\ny_corr, bas = baseline(x,y,roi, poly ,p=0.0)  For a linear baseline,  bas = baseline(x,y,roi, poly ,p=1.0)  For a second order polynomial baseline,  bas = baseline(x,y,roi, poly ,p=2.0)  with the last coefficient will be the one in front of x^2. This can continue as you want by adding more 1.0 values to p.  For a cubic spline baseline fitting the basis of a peak centered at 1100 cm^{-1} and with basis at 900 and 1250 cm^{-1}:  roi = [890. 910.; 1250. 1300.]\n\nbasetype =  Dspline \n\nbas = baseline(x,y,roi,basetype,p=0.01)  p there is the smoothing parameter used. The cubic spline uses the Dierckx package initially written in Fortran and used in Julia: https://github.com/kbarbary/Dierckx.jl  source", 
            "title": "Baseline subtraction"
        }, 
        {
            "location": "/PreProcessing/#frequency-shifts-correction", 
            "text": "In case your spectra are shifted from a reference value, Spectra offers several functions that allows you to correct it from this shift.  To correct a spectrum from a shift of P wavenumbers, you can simply call:  #  Spectra.xshift_direct     Method .  xshift_direct(original_x::Array{Float64}, original_y::Array{Float64}, p::Float64)  To correct a spectrum for a p shift in X.  Used in xshift_correction.  INPUTS:  original_x :   Array { Float64 },   containing   x   values ;  original_y :   Array { Float64 },   containing   y   values   associated   with   x ;  p :   Array { Float64 },   containing   the   value   of   how   much   x   should   be   shifted .   OUTPUTS:  original_x :   Array { Float64 },   same   as   input ;  corrected_y :   Array { Float64 },   the   y   values   corrected   from   the   p   shift   in   original_x ;   p :   Array { Float64 },   same   as   input .   source  Sometime, two signals from the same mineral show a shift in the X axis, while they share a common X axis. To correct from such thing, you can use the function:  #  Spectra.xshift_correction     Method .  xshift_correction(full_x::Array{Float64}, full_shifted_y::Array{Float64}, ref_x::Array{Float64}, ref_y::Array{Float64},shifted_y::Array{Float64})  To correct a shift between two spectra using a reference peak.  INPUTS:  full_x :   Array { Float64 },   containing   x   values   that   are   not   good ;  full_shifted_y :   Array { Float64 },   containing   y   values   associated   with   full_x ;  ref_x :   Array { Float64 },   containing   x   values   that   are   good ;  ref_y :   Array { Float64 },   containing   y   values   associated   with   ref_x .  shifted_y :   Array { Float64 },   containing   y   values   associated   with   a   selected   range   of   full_x   that   corresponds   to   ref_x   ( for   instance ,   a   specific   peak   that   you   want   to   use   to   correct   the   shift ).   OUTPUTS:  full_x :   Array { Float64 },   same   as   input ;  corrected_y :   Array { Float64 },   the   full_shifted_y   values   corrected   from   the   shift ;   p :   Array { Float64 },   same   as   input .   ref_x is the common X axis of two particular ref_y and shifted_y signals, that should be for instance an intense and well defined peak in your spectra. If ref_y and shifted_y do not share the same X axis, you can use first the Dierckx spline to re-sample one of them and have both sharing a common X axis. See the examples for further details.  source", 
            "title": "Frequency shifts correction"
        }, 
        {
            "location": "/PreProcessing/#smoothing", 
            "text": "#  Spectra.SavitzkyGolayFilter     Type .  SavitzkyGolayFilter{M,N}(data)  Savitzky-Golay filter of window half-width M and degree N M is the number of points before and after to interpolate, i.e. the full width of the window is 2M+1 Code from https://medium.com/@acidflask/smoothing-data-with-julia-s-generated-functions-c80e240e05f3#.45v03x6it  source", 
            "title": "Smoothing"
        }, 
        {
            "location": "/GeneralFunctions/", 
            "text": "General Functions\n\n\n\n\nPeak shapes\n\n\nThe following functions are useful when generating peaks with various shapes. See the examples for using them during peak fitting for instance.\n\n\n#\n\n\nSpectra.gaussiennes\n \n \nMethod\n.\n\n\ngaussiennes(amplitude::Array{Float64},centre::Array{Float64},hwhm::Array{Float64},x::Array{Float64},style::String = \nNone\n)\n\n\n\n\n\ngaussiennes, written in the plural french form there, is a function that allows to build gaussian peaks. The gaussian function used there is:\n\n\ny = amplitude x exp(-ln(2) x [(x-centre)/hwhm]^2 )\n\n\n\n\n\nINPUTS:\n\n\namplitude\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \namplitudes\n;\n\n\n\ncentre\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \ncentres\n;\n\n\n\nhwhm\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \nhalf\n-\nwidth\n \nat\n \nmiddle\n \nheights\n \n(\nhwhm\n);\n\n\n\nx\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \naxis\n \nvalues\n;\n\n\n\n\n\n\nOPTIONS:\n\n\nstyle\n:\n \nASCIIString\n \n=\n \nNone\n,\n \nsee\n \nexamples\n \nbelow\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ny\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ncalculated\n \ny\n \nvalues\n.\n\n\n\n\n\n\nYou can enter the amplitude, centre and half-width at half-maximum (hwhm) values as arrays of float 64 (even containing one float value), without specifying style. hwhm is proportional to the standard deviation sigma:\n\n\nhwhm= sqrt(2xln(2)) x sigma\n\n\n\n\n\nthat is used in a normal distribution (see function normal_dist).\n\n\n\n\nExamples\n\n\nTo have four gaussian peaks centered at 800, 900, 1000 and 1100 cm-1 with hwhm of 50 cm-1 on a Raman spectrum, you will enter:\n\n\ny_calc, y_peaks = gaussiennes([1.0,1.0,1.0,1.0], [800.0,900.0,1000.0,1100.0], [50.0,50.0,50.0,50.0], x)\n\n\nand y_peaks will contain in 4 columns the 4 different y values of the peaks, and y_calc their sum (the total model). Now, if you want to calculate more complex models, such as for instance contructing how the Raman peaks of water vary with pressure, you might like to parametrize the variations of the peak parameters rather than just fitting each spectrum. This will provide more robust fits of the spectra, as you will fit them together, and will also force you to find the correct underlying mathematical assumption.\n\n\nThe gaussiennes function allows you to do that. If you specify style = \"poly\", you can enter arrays for the amplitudes, centres and half-widths at half-maximum (hwhm) of the peaks, with in each column the coefficients for the polynomial variations of this parameters. The second column of x will need to contain the second variable for those polynomial functions.\n\n\nLet's say for instance that we have one peak at 900 cm-1 in a pure material. It's frequency seems to linearly shift with increasing the amount of hydrogen in this material, but it's intensity is non-linearly increasing, following a quadratic variation. It's width seems constant.\n\n\nHow to write that with gaussiennes? Well, first you need to construct a relevant x axis: first column contains the frequency, and the second one contains the chemical variable value. In our case, we want to model the peak between 800 and 1000 cm-1, for 1 wt% H. So we have an x array build like:\n\n\nfrequency = collect(800:1:1000)\n\nx = ones(length(frequency),2)\n\nx[:,1] = frequency[:]\n\nx[:,2] = 1.0\n\n\n\n\n\nOk, now lets build our y peaks:\n\n\namplitudes = [1.0 0.1 0.1]\n\nfrequencies = [900.0 2.0]\n\nhwhm = 20.0\n\ny_calc, y_peaks = gaussiennes(amplitudes, frequencies, hwhm, x)\n\n\n\n\n\nThis should provide you how the shape of the peak is as a function of both the frequency and the chemical composition there. If you want to go further, you might just want to stick gaussiennes in a loop, and play with creating various peaks with changing the chemical parameter in the x[:,2] column!\n\n\nsource\n\n\n#\n\n\nSpectra.lorentziennes\n \n \nMethod\n.\n\n\nlorentziennes\n(\namplitude\n::\nArray\n{\nFloat64\n}\n,\ncentre\n::\nArray\n{\nFloat64\n}\n,\nhwhm\n::\nArray\n{\nFloat64\n}\n,\nx\n::\nArray\n{\nFloat64\n}\n;\nstyle\n::\nString\n \n=\n \nNone\n)\n\n\n\n\n\n\nINPUTS:\n\n\namplitude\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \namplitudes\n;\n\n\n\ncentre\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \ncentres\n;\n\n\n\nhwhm\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \nhalf\n-\nwidth\n \nat\n \nmiddle\n \nheights\n \n(\nhwhm\n);\n\n\n\nx\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \naxis\n \nvalues\n;\n\n\n\n\n\n\nOPTIONS:\n\n\nstyle\n:\n \nASCIIString\n \n=\n \nNone\n,\n \nsee\n \nexamples\n \nin\n \nthe\n \ngaussiennes\n \ndocumentation\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ny\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ncalculated\n \ny\n \nvalues\n.\n\n\n\n\n\n\nsource\n\n\n#\n\n\nSpectra.pearson7\n \n \nMethod\n.\n\n\npearson7\n(\na1\n::\nArray\n{\nFloat64\n}\n,\na2\n::\nArray\n{\nFloat64\n}\n,\na3\n::\nArray\n{\nFloat64\n}\n,\na4\n::\nArray\n{\nFloat64\n}\n,\nx\n::\nArray\n{\nFloat64\n}\n;\nstyle\n::\nString\n \n=\n \nNone\n)\n\n\n\n\n\n\na Pearson 7 peak with formula a1 ./ (1 + ((x-a2)./a3).^2 .* (2.0.^(1./a4) - 1.0))\n\n\nINPUTS:\n\n\na1\n:\n \nArray\n{\nFloat64\n}\n \n;\n\n\n\na2\n:\n \nArray\n{\nFloat64\n}\n \n;\n\n\n\na3\n:\n \nArray\n{\nFloat64\n}\n \n;\n\n\n\na4\n:\n \nArray\n{\nFloat64\n}\n \n;\n\n\n\nx\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \naxis\n \nvalues\n;\n\n\n\n\n\n\nOPTIONS:\n\n\nstyle\n:\n \nASCIIString\n \n=\n \nNone\n,\n \nsee\n \nexamples\n \nin\n \nthe\n \ngaussiennes\n \ndocumentation\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ny\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ncalculated\n \ny\n \nvalues\n.\n\n\n\n\n\n\nsource\n\n\n#\n\n\nSpectra.pseudovoigts\n \n \nMethod\n.\n\n\npseudovoigts\n(\namplitude\n::\nArray\n{\nFloat64\n}\n,\ncentre\n::\nArray\n{\nFloat64\n}\n,\nhwhm\n::\nArray\n{\nFloat64\n}\n,\nlorentzian_fraction\n::\nArray\n{\nFloat64\n}\n,\nx\n::\nArray\n{\nFloat64\n}\n;\nstyle\n::\nString\n \n=\n \nNone\n)\n\n\n\n\n\n\nA mixture of gaussian and lorentzian peaks.\n\n\nINPUTS:\n\n\namplitude\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \namplitudes\n;\n\n\n\ncentre\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \ncentres\n;\n\n\n\nhwhm\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \nhalf\n-\nwidth\n \nat\n \nmiddle\n \nheights\n \n(\nhwhm\n);\n\n\n\nlorentzian_fraction\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nlorentzian\n \nfraction\n \nof\n \nthe\n \npseudovoigt\n \nfunction\n.\n \nShould\n \nbe\n \ncomprised\n \nbetween\n \n0\n \nand\n \n1\n;\n \n\n\nx\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \naxis\n \nvalues\n;\n\n\n\n\n\n\nOPTIONS:\n\n\nstyle\n:\n \nASCIIString\n \n=\n \nNone\n,\n \nsee\n \nexamples\n \nin\n \nthe\n \ngaussiennes\n \ndocumentation\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ny\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ncalculated\n \ny\n \nvalues\n.\n\n\n\n\n\n\nsource\n\n\n#\n\n\nSpectra.normal_dist\n \n \nMethod\n.\n\n\nnormal_dist(nd_amplitudes::Array{Float64},nd_centres::Array{Float64},nd_sigmas::Array{Float64},x::Array{Float64})\n\n\n\n\n\nThe real normal distribution / gaussian function\n\n\nINPUTS:\n\n\namplitude\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \namplitudes\n;\n\n\n\ncentre\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \ncentres\n;\n\n\n\nhwhm\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \npeaks\n \nhalf\n-\nwidth\n \nat\n \nmiddle\n \nheights\n \n(\nhwhm\n);\n\n\n\nlorentzian_fraction\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nlorentzian\n \nfraction\n \nof\n \nthe\n \npseudovoigt\n \nfunction\n.\n \nShould\n \nbe\n \ncomprised\n \nbetween\n \n0\n \nand\n \n1\n;\n \n\n\nx\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \naxis\n \nvalues\n;\n\n\n\n\n\n\nOPTIONS:\n\n\nstyle\n:\n \nASCIIString\n \n=\n \nNone\n,\n \nsee\n \nexamples\n \nin\n \nthe\n \ngaussiennes\n \ndocumentation\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ny\n:\n \nArray\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ncalculated\n \ny\n \nvalues\n.\n\n\n\n\n\n\nsource\n\n\n\n\nPeak measurement\n\n\n#\n\n\nSpectra.peakhw\n \n \nMethod\n.\n\n\npeakhw\n(\nx\n::\nArray\n{\nFloat64\n}\n,\ny\n::\nArray\n{\nFloat64\n}\n;\nM\n=\n5\n,\nN\n=\n2\n,\ny_smo_out\n=\nfalse\n)\n\n\n\n\n\n\nThe peakhw function allows performing measurements of the position, width and intensity of a peak.\n\n\nIt also allows smoothing the signal with a Savitzky-Golay filter prior to measuring the peak position, width and intensity, see the options.\n\n\nINPUTS:\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nx\n \nvalues\n;\n\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \ny\n \nvalues\n.\n\n\n\n\n\n\nOPTIONS:\n\n\nM=5, the M parameter for smoothing y with a Savitzky-Golay filter. See SavitzkyGolayFilter documentation;\n\nN=2, the M parameter for smoothing y with a Savitzky-Golay filter. See SavitzkyGolayFilter documentation;\n\ny_smo_out=false, the smoothed signal. Signal will be smoothed if set to true, using the SavitzkyGolayFilter function with the M and N values. y_smo output will also be provided.\n\n\n\n\n\nOUTPUTS:\n\n\nx_maximum\n:\n \nthe\n \nposition\n \nof\n \nthe\n \npeak\n;\n\n\n\nhwhm\n:\n \nthe\n \nhalf\n-\nwidth\n \nat\n \nhalf\n-\nmaximum\n \nof\n \nthe\n \npeak\n;\n\n\n\nif\n \ny_smo_out\n \nis\n \nset\n \nto\n \ntrue\n,\n \nthen\n \nanother\n \noutput\n \nis\n \nprovided\n:\n\n\n\ny_smo\n:\n \nthe\n \nsmoothed\n \ny\n \nsignal\n.\n\n\n\n\n\n\nsource\n\n\n\n\nIntegration\n\n\nSpectra.jl provides functions that allow one to integrate the area under a region of a spectrum, or to calculate the area under Gaussian, Lorentzian or other bands.\n\n\n#\n\n\nSpectra.trapz\n \n \nMethod\n.\n\n\ntrapz{Tx\n:Number, Ty\n:Number}(x::Vector{Tx}, y::Vector{Ty})\n\n\n\n\n\nTrapezoidal integration.\n\n\nINPUTS:\n\n\nx\n:\n \nVector\n{\nFloat64\n}\n \ncontaining\n \nthe\n \nx\n \nvalues\n;\n\n\n\ny\n:\n \nVector\n{\nFloat64\n}\n \ncontaining\n \nthe\n \ny\n \nvalues\n.\n\n\n\n\n\n\nOUTPUTS: \n\n\narea\n:\n \nVector\n{\nFloat64\n},\n \nthe\n \ntrapezoidal\n \nintegration\n \nvalue\n.\n\n\n\n\n\n\nThis function is particularly helpful to calculate the area under a portion of a spectrum, and can be used for various purposes (normalisation, area comparison, etc.).\n\n\nsource\n\n\n#\n\n\nSpectra.bandarea\n \n \nMethod\n.\n\n\nbandarea\n(\nAmplitude\n::\nArray\n{\nFloat64\n}\n,\nHWHM\n::\nArray\n{\nFloat64\n}\n;\n \npeak_shape\n \n=\n \nGaussian\n,\n \nerror_switch\n \n=\n \nno\n,\n \neseAmplitude\n::\nArray\n{\nFloat64\n}\n \n=\n \n[\n0.0\n]\n,\n \neseHWHM\n::\nArray\n{\nFloat64\n}\n \n=\n \n[\n0.0\n]\n)\n\n\n\n\n\n\nThis function replaces the function gaussianarea in the version \n0.1.9 of Spectra.jl. It allows to calculate the area under a specific band, with different shapes. For now, only Gaussian bands are supported, but other band shapes will be added soon. (This explains why gaussianarea is deprecated in favor of a more generic function)\n\n\ngaussianarea allows to calculate the area under a gaussian peak from its half-width at half maximum (hwhm) and its amplitude, with the possibility of calculating the error based on the inputs of the errors on hwhm and amplitude. Call it as:\n\n\narea, esearea = band(Amplitude,HWHM; peak_shape = \nGaussian\n, error_switch = \nno\n, eseAmplitude = [0.0], eseHWHM = [0.0])\n\n\n\n\n\nINPUTS:\n\n\nAmplitude\n:\n \nArray\n{\nFloat64\n},\n \ncontains\n \nthe\n \namplitudes\n \n(\nintensity\n)\n \nof\n \nthe\n \nband\n(\ns\n);\n\n\n\nHWHM\n:\n \nArray\n{\nFloat64\n},\n \ncontains\n \nthe\n \nhalf\n \nwidth\n \nat\n \nhalf\n \nmaximum\n \nof\n \nthe\n \npeaks\n;\n\n\n\n\n\n\nOPTIONS\n\n\npeak_shape\n:\n \nString\n,\n \nindicates\n \nthe\n \nshape\n \nof\n \nthe\n \ncomponent\n.\n \nOnly\n \nGaussian\n \nis\n \nsupported\n \nfor\n \nnow\n;\n\n\n\nerror_switch\n:\n \nString\n,\n \nshould\n \nbe\n \nyes\n \nor\n \nno\n.\n \nIf\n \nyes\n,\n \nthe\n \narrays\n \ncontaining\n \nthe\n \nerrors\n \naffecting\n \nthe\n \nband\n \namplitude\n \nand\n \nwidhts\n \nshould\n \nbe\n \nprovided\n \nin\n \neseAmplitude\n \nand\n \neseHWHM\n \n(\nsee\n \nbelow\n);\n\n\n\neseAmplitude\n:\n \nArray\n{\nFloat64\n},\n \nan\n \narray\n \nthat\n \ncontains\n \nthe\n \nerrors\n \naffecting\n \nAmplitude\n;\n\n\n\neseHWHM\n:\n \nArray\n{\nFloat64\n},\n \nan\n \narray\n \nthat\n \ncontains\n \nthe\n \nerrors\n \naffecting\n \nHWHM\n;\n\n\n\n\n\n\nOUTPUTS: \n\n\narea\n:\n \nArray\n{\nFloat64\n},\n \nan\n \narray\n \nthat\n \ncontains\n \nthe\n \nareas\n;\n\n\n\nif\n \nerror_switch\n \nis\n \nset\n \nto\n \nyes\n,\n \nthen\n \na\n \nsecond\n \noutput\n \nis\n \nprovided\n:\n\n\n\nesearea\n:\n \nArray\n{\nFloat64\n},\n \nan\n \narray\n \nthat\n \ncontains\n \nthe\n \npropagated\n \nerrors\n \naffecting\n \nthe\n \nareas\n \ncalculations\n.\n\n\n\n\n\n\nsource\n\n\n\n\nPolynomials\n\n\n#\n\n\nSpectra.poly\n \n \nMethod\n.\n\n\npoly(p::Vector{Float64},x::Array{Float64})\n\n\n\n\n\nThis function just allows to build a polynomial curve.\n\n\nINPUTS:\n\n\np\n:\n \nVector\n{\nFloat64\n},\n \ncontaining\n \nthe\n \npolynomial\n \nparameters\n.\n \nFor\n \na\n \nlinear\n \ncurve\n,\n \np\n \n=\n \n[\n1.0\n,\n1.0\n],\n \nfor\n \na\n \nsecond\n \norder\n \npolynomial\n,\n \np\n \n=\n \n[\n1.0\n,\n1.0\n,\n1.0\n],\n \netc\n.;\n\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nx\n \nvalues\n \nfor\n \ncalculation\n.\n\n\n\n\n\n\nOutput:\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nresult\n \nof\n \ncalculation\n.\n\n\n\n\n\n\nsource\n\n\n#\n\n\nSpectra.polyfit\n \n \nMethod\n.\n\n\npolyfit(x::Array{Float64}, y::Array{Float64}, n::Int64)\n\n\n\n\n\nFit a polynom of degree n to x-y data. Code from https://rosettacode.org/wiki/Polynomial_regression#Julia\n\n\nINPUTS:\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nx\n \nvalues\n;\n\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \ny\n \nvalues\n;\n\n\n\nn\n:\n \nInt64\n,\n \nthe\n \npolynomial\n \ndegree\n:\n \n0\n \nfor\n \na\n \nconstant\n \nup\n \nto\n \nas\n \nhigh\n \nas\n \nwanted\n.\n\n\n\n\n\n\nOUTPUTS:\n\n\ncoefs\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \npolynomial\n \ncoefficients\n.\n\n\n\n\n\n\nsource\n\n\n\n\nSplines\n\n\nNot all the splines packages provide the same performances for data smoothing and interpolation. By experience, the Dierckx spline package (\"Dspline\" option in the baseline() function) provides a good starting point, but is not as usefull as other spline packages.\n\n\nThe csaps function of Matlab uses the SMOOTH Fortran library, and provides better smoothing capabilities for noisy data. Similarly, the GCVSPL Fortran package from Woltring (1986) also provides a very robust way to smooth and interpolate noisy data.\n\n\nThis GCVSPL spline package is called directly by Julia (through a ccall()) in the baseline function, with the options of a cubic spline with least-square data fitting. The smoothing is done with scaling the variances of the data points (VAR variable in the GCVSPL.f package) that is provided to the GCVSPL.f program.\n\n\nNow, while baseline() should be well suited for most users needs, it uses cubic splines that are not always the best answers to some problems. For instance, quadratic splines may be more robust in some cases. You can change that by providing the spline order to baseline() as SplOrder = 2 for instance.\n\n\nIn case you want to have even more control on GCVSPL.f, and use its internal tricks and tweeks, the following lines will provide you the documentation of the two functions allowing you to calculate the spline coefficients and to evaluate the spline values at specific x entries.\n\n\n#\n\n\nSpectra.gcvspl_julia\n \n \nMethod\n.\n\n\ngcvspl_julia(x,y,ese,SmoothSpline;SplineOrder = Int32(2),SplineMode = Int32(3))\n\n\n\n\n\nThis function allows you to calculate the spline coefficients. It calls gcvspline subroutine of the program GCVSPL.f.\n\n\nINPUTS:\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nindependent\n \nvariables\n;\n\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nobservations\n \n(\nwe\n \nassume\n \nhere\n \nthat\n \nyou\n \nwant\n \nto\n \nuse\n \nthis\n \nspline\n \nonly\n \non\n \n1\n \ndataset\n...\n \nsee\n \ngcvspl\n.\nf\n \nif\n \nnot\n);\n\n\n\nese\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nerrors\n \non\n \ny\n;\n\n\n\nSplineSmooth\n:\n \nFloat64\n,\n \nthe\n \nsmoothing\n \nfactor\n;\n\n\n\nSplineOrder\n \n(\nM\n \nparameter\n \nin\n \ngcvspl\n.\nf\n):\n \nInt32\n,\n \nthe\n \nhalf\n \norder\n \nof\n \nthe\n \nrequired\n \nB\n-\nsplines\n.\n \ndefault\n:\n \nsplorder\n \n=\n \n2\n \n(\ncubic\n).\n \nSplineOrder\n \n=\n \n1\n,\n2\n,\n3\n,\n4\n \ncorrespond\n \nto\n \nlinear\n,\n \ncubic\n,\n \nquintic\n,\n \nand\n \nheptic\n \nsplines\n,\n \nrespectively\n.\n \n\n\nSplineMode\n \n(\nInt32\n,\n \nMD\n \nparameter\n \nin\n \ngcvspl\n.\nf\n)\n \nis\n \nthe\n \nOptimization\n \nmode\n \nswitch\n:\n\n    \ndefault\n:\n   \nSplineMode\n \n=\n \n2\n \n(\nGeneral\n \nCross\n \nValidated\n)\n\n\n               \nSplineMode\n \n=\n \n1\n:\n \nPrior\n \ngiven\n \nvalue\n \nfor\n \np\n \nin\n \nVAL\n\n                         \n(\nVAL\n.\nge\n.\nZERO\n).\n \nThis\n \nis\n \nthe\n \nfastest\n\n                         \nuse\n \nof\n \nGCVSPL\n,\n \nsince\n \nno\n \niteration\n\n                         \nis\n \nperformed\n \nin\n \np\n.\n\n\n               \nSplineMode\n \n=\n \n2\n:\n \nGeneralized\n \ncross\n \nvalidation\n.\n\n\n               \nSplineMode\n \n=\n \n3\n:\n \nTrue\n \npredicted\n \nmean\n-\nsquared\n \nerror\n,\n\n                         \nwith\n \nprior\n \ngiven\n \nvariance\n \nin\n \nVAL\n.\n\n\n               \nSplineMode\n \n=\n \n4\n:\n \nPrior\n \ngiven\n \nnumber\n \nof\n \ndegrees\n \nof\n\n                         \nfreedom\n \nin\n \nVAL\n \n(\nZERO\n.\nle\n.\nVAL\n.\nle\n.\nN\n-\nM\n).\n\n\n               \nSplineMode\n  \n \n0\n:\n \nIt\n \nis\n \nassumed\n \nthat\n \nthe\n \ncontents\n \nof\n\n                         \nX\n,\n \nW\n,\n \nM\n,\n \nN\n,\n \nand\n \nWK\n \nhave\n \nnot\n \nbeen\n\n                         \nmodified\n \nsince\n \nthe\n \nprevious\n \ninvoca\n-\n\n                         \ntion\n \nof\n \nGCVSPL\n.\n \nIf\n \nMD\n \n \n-\n1\n,\n \nWK\n(\n4\n)\n\n                         \nis\n \nused\n \nas\n \nan\n \ninitial\n \nestimate\n \nfor\n\n                         \nthe\n \nsmoothing\n \nparameter\n \np\n.\n  \nAt\n \nthe\n\n                         \nfirst\n \ncall\n \nto\n \nGCVSPL\n,\n \nMD\n \nmust\n \nbe\n \n \n0\n.\n\n\n               \nOther\n \nvalues\n \nfor\n \nSplineMode\n,\n \nand\n \ninappropriate\n \nvalues\n\n               \nfor\n \nVAL\n \nwill\n \nresult\n \nin\n \nan\n \nerror\n \ncondition\n,\n \nor\n\n               \ncause\n \na\n \ndefault\n \nvalue\n \nfor\n \nVAL\n \nto\n \nbe\n \nselected\n.\n\n               \nAfter\n \nreturn\n \nfrom\n \nMD\n.\nne\n.\n1\n,\n \nthe\n \nsame\n \nnumber\n \nof\n\n               \ndegrees\n \nof\n \nfreedom\n \ncan\n \nbe\n \nobtained\n,\n \nfor\n \nidentical\n\n               \nweight\n \nfactors\n \nand\n \nknot\n \npositions\n,\n \nby\n \nselecting\n\n               \nSplineMode\n=\n1\n,\n \nand\n \nby\n \ncopying\n \nthe\n \nvalue\n \nof\n \np\n \nfrom\n \nWK\n(\n4\n)\n\n               \ninto\n \nVAL\n.\n \nIn\n \nthis\n \nway\n,\n \nno\n \niterative\n \noptimization\n\n               \nis\n \nrequired\n \nwhen\n \nprocessing\n \nother\n \ndata\n \nin\n \nY\n.\n\n\n\n\n\n\nOUPUTS:\n\n\nc\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nspline\n \ncoefficients\n;\n\n\n\nWK\n:\n \nArray\n{\nFloat64\n},\n \nworking\n \nvector\n,\n \nsee\n \ngcvspl\n.\nf\n;\n\n\n\nIER\n:\n \nerror\n \nparameter\n\n\n    \nIER\n \n=\n \n0\n:\n \nNormal\n \nexit\n \n\n    \nIER\n \n=\n \n1\n:\n \nM\n.\nle\n.\n0\n \n.\nor\n.\n \nN\n.\nlt\n.\n2\n*\nM\n\n\n    \nIER\n \n=\n \n2\n:\n \nKnot\n \nsequence\n \nis\n \nnot\n \nstrictly\n \nincreasing\n,\n \nor\n \nsome\n \nweight\n \nfactor\n \nis\n \nnot\n \npositive\n.\n\n\n    \nIER\n \n=\n \n3\n:\n \nWrong\n \nmode\n \nparameter\n \nor\n \nvalue\n.\n\n\n\n\n\n\nSEE GCVSPL.f and Woltring (1986) for even more information.\n\n\nsource\n\n\n#\n\n\nSpectra.splderivative_julia\n \n \nMethod\n.\n\n\nsplderivative_julia\n(\nxfull\n::\nArray\n{\nFloat64\n}\n,\nxparse\n::\nArray\n{\nFloat64\n}\n,\ncparse\n::\nArray\n{\nFloat64\n}\n;\nSplineOrder\n::\nInt32\n \n=\n \nInt32\n(\n2\n),\n \nL\n::\nInt32\n \n=\n \nInt32\n(\n1\n),\n \nIDER\n::\nInt32\n \n=\n \nInt32\n(\n0\n))\n\n\n\n\n\n\nWrapper to the SPLDER function of gcvspl.f, for interpolation purpose\n\n\nINPUTS:\n\n\nxfull\n:\n \nFloat64\n \nArray\n,\n \ncontains\n \nthe\n \nentire\n \nx\n \nrange\n \nwhere\n \nthe\n \nspline\n \nhas\n \nto\n \nbe\n \nevaluated\n\n\n\nxparse\n:\n \nFloat64\n \nArray\n,\n \ncontains\n \nthe\n \nx\n \nvalues\n \nof\n \ninterpolation\n \nregions\n   \n\n\nWARNING\n!!!\n \n=\n \nxparse\n[\n0\n]\n \n=\n \nxfull\n[\n0\n]\n \n=\n \nxparse\n[\nn\n]\n \n\n\ncparse\n:\n \nFloat64\n \nArray\n,\n \nis\n \nthe\n \nevaluated\n \nspline\n \ncoefficients\n \nreturned\n \nby\n \ngcvspl\n \nfor\n \nxparse\n\n\n\n\n\n\nOPTIONS:    \n\n\nsplineorder\n \n(\ninteger\n):\n \nis\n \nthe\n \nspline\n \norder\n,\n \ndefault\n:\n \nsplineorder\n \n=\n \n2\n \n(\ncubic\n);\n\n\n\nL\n \n(\ninteger\n):\n \nsee\n \ngcvspl\n.\nf\n \nfor\n \ndetails\n,\n \ndefault\n:\n \nL\n \n=\n \n1\n;\n\n\n\nIDER\n:\n \nthe\n \nDerivative\n \norder\n \nrequired\n,\n \nwith\n \n0\n.\nle\n.\nIDER\n \nand\n \nIDER\n.\nle\n.\n2\n*\nM\n.\n \nIf\n \nIDER\n.\neq\n.\n0\n,\n \nthe\n \nfunction\n \nvalue\n \nis\n \nreturned\n;\n \notherwise\n,\n \nthe\n \nIDER-th\n \nderivative\n \nof\n \nthe\n \nspline\n \nis\n \nreturned\n.\n\n\n\n\n\n\nSEE gcvspl.f FOR MORE INFORMATION\n\n\nsource", 
            "title": "General Functions"
        }, 
        {
            "location": "/GeneralFunctions/#general-functions", 
            "text": "", 
            "title": "General Functions"
        }, 
        {
            "location": "/GeneralFunctions/#peak-shapes", 
            "text": "The following functions are useful when generating peaks with various shapes. See the examples for using them during peak fitting for instance.  #  Spectra.gaussiennes     Method .  gaussiennes(amplitude::Array{Float64},centre::Array{Float64},hwhm::Array{Float64},x::Array{Float64},style::String =  None )  gaussiennes, written in the plural french form there, is a function that allows to build gaussian peaks. The gaussian function used there is:  y = amplitude x exp(-ln(2) x [(x-centre)/hwhm]^2 )  INPUTS:  amplitude :   Array { Float64 }   containing   the   peaks   amplitudes ;  centre :   Array { Float64 }   containing   the   peaks   centres ;  hwhm :   Array { Float64 }   containing   the   peaks   half - width   at   middle   heights   ( hwhm );  x :   Array { Float64 }   containing   the   x   axis   values ;   OPTIONS:  style :   ASCIIString   =   None ,   see   examples   below .   OUTPUTS:  y :   Array { Float64 }   containing   the   calculated   y   values .   You can enter the amplitude, centre and half-width at half-maximum (hwhm) values as arrays of float 64 (even containing one float value), without specifying style. hwhm is proportional to the standard deviation sigma:  hwhm= sqrt(2xln(2)) x sigma  that is used in a normal distribution (see function normal_dist).   Examples  To have four gaussian peaks centered at 800, 900, 1000 and 1100 cm-1 with hwhm of 50 cm-1 on a Raman spectrum, you will enter:  y_calc, y_peaks = gaussiennes([1.0,1.0,1.0,1.0], [800.0,900.0,1000.0,1100.0], [50.0,50.0,50.0,50.0], x)  and y_peaks will contain in 4 columns the 4 different y values of the peaks, and y_calc their sum (the total model). Now, if you want to calculate more complex models, such as for instance contructing how the Raman peaks of water vary with pressure, you might like to parametrize the variations of the peak parameters rather than just fitting each spectrum. This will provide more robust fits of the spectra, as you will fit them together, and will also force you to find the correct underlying mathematical assumption.  The gaussiennes function allows you to do that. If you specify style = \"poly\", you can enter arrays for the amplitudes, centres and half-widths at half-maximum (hwhm) of the peaks, with in each column the coefficients for the polynomial variations of this parameters. The second column of x will need to contain the second variable for those polynomial functions.  Let's say for instance that we have one peak at 900 cm-1 in a pure material. It's frequency seems to linearly shift with increasing the amount of hydrogen in this material, but it's intensity is non-linearly increasing, following a quadratic variation. It's width seems constant.  How to write that with gaussiennes? Well, first you need to construct a relevant x axis: first column contains the frequency, and the second one contains the chemical variable value. In our case, we want to model the peak between 800 and 1000 cm-1, for 1 wt% H. So we have an x array build like:  frequency = collect(800:1:1000)\n\nx = ones(length(frequency),2)\n\nx[:,1] = frequency[:]\n\nx[:,2] = 1.0  Ok, now lets build our y peaks:  amplitudes = [1.0 0.1 0.1]\n\nfrequencies = [900.0 2.0]\n\nhwhm = 20.0\n\ny_calc, y_peaks = gaussiennes(amplitudes, frequencies, hwhm, x)  This should provide you how the shape of the peak is as a function of both the frequency and the chemical composition there. If you want to go further, you might just want to stick gaussiennes in a loop, and play with creating various peaks with changing the chemical parameter in the x[:,2] column!  source  #  Spectra.lorentziennes     Method .  lorentziennes ( amplitude :: Array { Float64 } , centre :: Array { Float64 } , hwhm :: Array { Float64 } , x :: Array { Float64 } ; style :: String   =   None )   INPUTS:  amplitude :   Array { Float64 }   containing   the   peaks   amplitudes ;  centre :   Array { Float64 }   containing   the   peaks   centres ;  hwhm :   Array { Float64 }   containing   the   peaks   half - width   at   middle   heights   ( hwhm );  x :   Array { Float64 }   containing   the   x   axis   values ;   OPTIONS:  style :   ASCIIString   =   None ,   see   examples   in   the   gaussiennes   documentation .   OUTPUTS:  y :   Array { Float64 }   containing   the   calculated   y   values .   source  #  Spectra.pearson7     Method .  pearson7 ( a1 :: Array { Float64 } , a2 :: Array { Float64 } , a3 :: Array { Float64 } , a4 :: Array { Float64 } , x :: Array { Float64 } ; style :: String   =   None )   a Pearson 7 peak with formula a1 ./ (1 + ((x-a2)./a3).^2 .* (2.0.^(1./a4) - 1.0))  INPUTS:  a1 :   Array { Float64 }   ;  a2 :   Array { Float64 }   ;  a3 :   Array { Float64 }   ;  a4 :   Array { Float64 }   ;  x :   Array { Float64 }   containing   the   x   axis   values ;   OPTIONS:  style :   ASCIIString   =   None ,   see   examples   in   the   gaussiennes   documentation .   OUTPUTS:  y :   Array { Float64 }   containing   the   calculated   y   values .   source  #  Spectra.pseudovoigts     Method .  pseudovoigts ( amplitude :: Array { Float64 } , centre :: Array { Float64 } , hwhm :: Array { Float64 } , lorentzian_fraction :: Array { Float64 } , x :: Array { Float64 } ; style :: String   =   None )   A mixture of gaussian and lorentzian peaks.  INPUTS:  amplitude :   Array { Float64 }   containing   the   peaks   amplitudes ;  centre :   Array { Float64 }   containing   the   peaks   centres ;  hwhm :   Array { Float64 }   containing   the   peaks   half - width   at   middle   heights   ( hwhm );  lorentzian_fraction :   Array { Float64 },   containing   the   lorentzian   fraction   of   the   pseudovoigt   function .   Should   be   comprised   between   0   and   1 ;   x :   Array { Float64 }   containing   the   x   axis   values ;   OPTIONS:  style :   ASCIIString   =   None ,   see   examples   in   the   gaussiennes   documentation .   OUTPUTS:  y :   Array { Float64 }   containing   the   calculated   y   values .   source  #  Spectra.normal_dist     Method .  normal_dist(nd_amplitudes::Array{Float64},nd_centres::Array{Float64},nd_sigmas::Array{Float64},x::Array{Float64})  The real normal distribution / gaussian function  INPUTS:  amplitude :   Array { Float64 }   containing   the   peaks   amplitudes ;  centre :   Array { Float64 }   containing   the   peaks   centres ;  hwhm :   Array { Float64 }   containing   the   peaks   half - width   at   middle   heights   ( hwhm );  lorentzian_fraction :   Array { Float64 },   containing   the   lorentzian   fraction   of   the   pseudovoigt   function .   Should   be   comprised   between   0   and   1 ;   x :   Array { Float64 }   containing   the   x   axis   values ;   OPTIONS:  style :   ASCIIString   =   None ,   see   examples   in   the   gaussiennes   documentation .   OUTPUTS:  y :   Array { Float64 }   containing   the   calculated   y   values .   source", 
            "title": "Peak shapes"
        }, 
        {
            "location": "/GeneralFunctions/#peak-measurement", 
            "text": "#  Spectra.peakhw     Method .  peakhw ( x :: Array { Float64 } , y :: Array { Float64 } ; M = 5 , N = 2 , y_smo_out = false )   The peakhw function allows performing measurements of the position, width and intensity of a peak.  It also allows smoothing the signal with a Savitzky-Golay filter prior to measuring the peak position, width and intensity, see the options.  INPUTS:  x :   Array { Float64 },   the   x   values ;  y :   Array { Float64 },   the   y   values .   OPTIONS:  M=5, the M parameter for smoothing y with a Savitzky-Golay filter. See SavitzkyGolayFilter documentation;\n\nN=2, the M parameter for smoothing y with a Savitzky-Golay filter. See SavitzkyGolayFilter documentation;\n\ny_smo_out=false, the smoothed signal. Signal will be smoothed if set to true, using the SavitzkyGolayFilter function with the M and N values. y_smo output will also be provided.  OUTPUTS:  x_maximum :   the   position   of   the   peak ;  hwhm :   the   half - width   at   half - maximum   of   the   peak ;  if   y_smo_out   is   set   to   true ,   then   another   output   is   provided :  y_smo :   the   smoothed   y   signal .   source", 
            "title": "Peak measurement"
        }, 
        {
            "location": "/GeneralFunctions/#integration", 
            "text": "Spectra.jl provides functions that allow one to integrate the area under a region of a spectrum, or to calculate the area under Gaussian, Lorentzian or other bands.  #  Spectra.trapz     Method .  trapz{Tx :Number, Ty :Number}(x::Vector{Tx}, y::Vector{Ty})  Trapezoidal integration.  INPUTS:  x :   Vector { Float64 }   containing   the   x   values ;  y :   Vector { Float64 }   containing   the   y   values .   OUTPUTS:   area :   Vector { Float64 },   the   trapezoidal   integration   value .   This function is particularly helpful to calculate the area under a portion of a spectrum, and can be used for various purposes (normalisation, area comparison, etc.).  source  #  Spectra.bandarea     Method .  bandarea ( Amplitude :: Array { Float64 } , HWHM :: Array { Float64 } ;   peak_shape   =   Gaussian ,   error_switch   =   no ,   eseAmplitude :: Array { Float64 }   =   [ 0.0 ] ,   eseHWHM :: Array { Float64 }   =   [ 0.0 ] )   This function replaces the function gaussianarea in the version  0.1.9 of Spectra.jl. It allows to calculate the area under a specific band, with different shapes. For now, only Gaussian bands are supported, but other band shapes will be added soon. (This explains why gaussianarea is deprecated in favor of a more generic function)  gaussianarea allows to calculate the area under a gaussian peak from its half-width at half maximum (hwhm) and its amplitude, with the possibility of calculating the error based on the inputs of the errors on hwhm and amplitude. Call it as:  area, esearea = band(Amplitude,HWHM; peak_shape =  Gaussian , error_switch =  no , eseAmplitude = [0.0], eseHWHM = [0.0])  INPUTS:  Amplitude :   Array { Float64 },   contains   the   amplitudes   ( intensity )   of   the   band ( s );  HWHM :   Array { Float64 },   contains   the   half   width   at   half   maximum   of   the   peaks ;   OPTIONS  peak_shape :   String ,   indicates   the   shape   of   the   component .   Only   Gaussian   is   supported   for   now ;  error_switch :   String ,   should   be   yes   or   no .   If   yes ,   the   arrays   containing   the   errors   affecting   the   band   amplitude   and   widhts   should   be   provided   in   eseAmplitude   and   eseHWHM   ( see   below );  eseAmplitude :   Array { Float64 },   an   array   that   contains   the   errors   affecting   Amplitude ;  eseHWHM :   Array { Float64 },   an   array   that   contains   the   errors   affecting   HWHM ;   OUTPUTS:   area :   Array { Float64 },   an   array   that   contains   the   areas ;  if   error_switch   is   set   to   yes ,   then   a   second   output   is   provided :  esearea :   Array { Float64 },   an   array   that   contains   the   propagated   errors   affecting   the   areas   calculations .   source", 
            "title": "Integration"
        }, 
        {
            "location": "/GeneralFunctions/#polynomials", 
            "text": "#  Spectra.poly     Method .  poly(p::Vector{Float64},x::Array{Float64})  This function just allows to build a polynomial curve.  INPUTS:  p :   Vector { Float64 },   containing   the   polynomial   parameters .   For   a   linear   curve ,   p   =   [ 1.0 , 1.0 ],   for   a   second   order   polynomial ,   p   =   [ 1.0 , 1.0 , 1.0 ],   etc .;  x :   Array { Float64 },   containing   the   x   values   for   calculation .   Output:  y :   Array { Float64 },   containing   the   result   of   calculation .   source  #  Spectra.polyfit     Method .  polyfit(x::Array{Float64}, y::Array{Float64}, n::Int64)  Fit a polynom of degree n to x-y data. Code from https://rosettacode.org/wiki/Polynomial_regression#Julia  INPUTS:  x :   Array { Float64 },   the   x   values ;  y :   Array { Float64 },   the   y   values ;  n :   Int64 ,   the   polynomial   degree :   0   for   a   constant   up   to   as   high   as   wanted .   OUTPUTS:  coefs :   Array { Float64 },   containing   the   polynomial   coefficients .   source", 
            "title": "Polynomials"
        }, 
        {
            "location": "/GeneralFunctions/#splines", 
            "text": "Not all the splines packages provide the same performances for data smoothing and interpolation. By experience, the Dierckx spline package (\"Dspline\" option in the baseline() function) provides a good starting point, but is not as usefull as other spline packages.  The csaps function of Matlab uses the SMOOTH Fortran library, and provides better smoothing capabilities for noisy data. Similarly, the GCVSPL Fortran package from Woltring (1986) also provides a very robust way to smooth and interpolate noisy data.  This GCVSPL spline package is called directly by Julia (through a ccall()) in the baseline function, with the options of a cubic spline with least-square data fitting. The smoothing is done with scaling the variances of the data points (VAR variable in the GCVSPL.f package) that is provided to the GCVSPL.f program.  Now, while baseline() should be well suited for most users needs, it uses cubic splines that are not always the best answers to some problems. For instance, quadratic splines may be more robust in some cases. You can change that by providing the spline order to baseline() as SplOrder = 2 for instance.  In case you want to have even more control on GCVSPL.f, and use its internal tricks and tweeks, the following lines will provide you the documentation of the two functions allowing you to calculate the spline coefficients and to evaluate the spline values at specific x entries.  #  Spectra.gcvspl_julia     Method .  gcvspl_julia(x,y,ese,SmoothSpline;SplineOrder = Int32(2),SplineMode = Int32(3))  This function allows you to calculate the spline coefficients. It calls gcvspline subroutine of the program GCVSPL.f.  INPUTS:  x :   Array { Float64 },   the   independent   variables ;  y :   Array { Float64 },   the   observations   ( we   assume   here   that   you   want   to   use   this   spline   only   on   1   dataset ...   see   gcvspl . f   if   not );  ese :   Array { Float64 },   the   errors   on   y ;  SplineSmooth :   Float64 ,   the   smoothing   factor ;  SplineOrder   ( M   parameter   in   gcvspl . f ):   Int32 ,   the   half   order   of   the   required   B - splines .   default :   splorder   =   2   ( cubic ).   SplineOrder   =   1 , 2 , 3 , 4   correspond   to   linear ,   cubic ,   quintic ,   and   heptic   splines ,   respectively .   SplineMode   ( Int32 ,   MD   parameter   in   gcvspl . f )   is   the   Optimization   mode   switch : \n     default :     SplineMode   =   2   ( General   Cross   Validated ) \n\n                SplineMode   =   1 :   Prior   given   value   for   p   in   VAL \n                          ( VAL . ge . ZERO ).   This   is   the   fastest \n                          use   of   GCVSPL ,   since   no   iteration \n                          is   performed   in   p . \n\n                SplineMode   =   2 :   Generalized   cross   validation . \n\n                SplineMode   =   3 :   True   predicted   mean - squared   error , \n                          with   prior   given   variance   in   VAL . \n\n                SplineMode   =   4 :   Prior   given   number   of   degrees   of \n                          freedom   in   VAL   ( ZERO . le . VAL . le . N - M ). \n\n                SplineMode      0 :   It   is   assumed   that   the   contents   of \n                          X ,   W ,   M ,   N ,   and   WK   have   not   been \n                          modified   since   the   previous   invoca - \n                          tion   of   GCVSPL .   If   MD     - 1 ,   WK ( 4 ) \n                          is   used   as   an   initial   estimate   for \n                          the   smoothing   parameter   p .    At   the \n                          first   call   to   GCVSPL ,   MD   must   be     0 . \n\n                Other   values   for   SplineMode ,   and   inappropriate   values \n                for   VAL   will   result   in   an   error   condition ,   or \n                cause   a   default   value   for   VAL   to   be   selected . \n                After   return   from   MD . ne . 1 ,   the   same   number   of \n                degrees   of   freedom   can   be   obtained ,   for   identical \n                weight   factors   and   knot   positions ,   by   selecting \n                SplineMode = 1 ,   and   by   copying   the   value   of   p   from   WK ( 4 ) \n                into   VAL .   In   this   way ,   no   iterative   optimization \n                is   required   when   processing   other   data   in   Y .   OUPUTS:  c :   Array { Float64 },   the   spline   coefficients ;  WK :   Array { Float64 },   working   vector ,   see   gcvspl . f ;  IER :   error   parameter \n\n     IER   =   0 :   Normal   exit  \n\n     IER   =   1 :   M . le . 0   . or .   N . lt . 2 * M \n\n     IER   =   2 :   Knot   sequence   is   not   strictly   increasing ,   or   some   weight   factor   is   not   positive . \n\n     IER   =   3 :   Wrong   mode   parameter   or   value .   SEE GCVSPL.f and Woltring (1986) for even more information.  source  #  Spectra.splderivative_julia     Method .  splderivative_julia ( xfull :: Array { Float64 } , xparse :: Array { Float64 } , cparse :: Array { Float64 } ; SplineOrder :: Int32   =   Int32 ( 2 ),   L :: Int32   =   Int32 ( 1 ),   IDER :: Int32   =   Int32 ( 0 ))   Wrapper to the SPLDER function of gcvspl.f, for interpolation purpose  INPUTS:  xfull :   Float64   Array ,   contains   the   entire   x   range   where   the   spline   has   to   be   evaluated  xparse :   Float64   Array ,   contains   the   x   values   of   interpolation   regions     WARNING !!!   =   xparse [ 0 ]   =   xfull [ 0 ]   =   xparse [ n ]   cparse :   Float64   Array ,   is   the   evaluated   spline   coefficients   returned   by   gcvspl   for   xparse   OPTIONS:      splineorder   ( integer ):   is   the   spline   order ,   default :   splineorder   =   2   ( cubic );  L   ( integer ):   see   gcvspl . f   for   details ,   default :   L   =   1 ;  IDER :   the   Derivative   order   required ,   with   0 . le . IDER   and   IDER . le . 2 * M .   If   IDER . eq . 0 ,   the   function   value   is   returned ;   otherwise ,   the   IDER-th   derivative   of   the   spline   is   returned .   SEE gcvspl.f FOR MORE INFORMATION  source", 
            "title": "Splines"
        }, 
        {
            "location": "/Rameau/", 
            "text": "RamEau\n\n\n\n\nIntroductory notes\n\n\nThis is the Julia version of the RamEau software. It allows quantification of the water content of glasses following the internal and external protocols described in:\n\n\nThomas, R. 2000. \u201cDetermination of Water Contents of Granite Melt Inclusions by Confocal Laser Raman Microprobe Spectroscopy.\u201d American Mineralogist 85 (5-6): 868\u201372.\n\n\nBehrens, Harald, Jacques Roux, Daniel R. Neuville, and Michael Siemann. 2006. \u201cQuantification of Dissolved H2O in Silicate Glasses Using Confocal microRaman Spectroscopy.\u201d Chemical Geology 229 (1-3): 96\u2013112. doi:10.1016/j.chemgeo.2006.01.014.\n\n\nLe Losq, Neuville, Moretti, Roux, 2012. Determination of water content in silicate glasses using Raman spectrometry: Implications for the study of explosive volcanism. American Mineralogist 97, 779-790.\n\n\nThe Rameau Pascal/fortran initial software is available through the american mineralogist website. This version goes much beyond the previous version. It allows using various modes for internal calibration, and further allows using external calibrations too.\n\n\nInternal calibration mode refers to the technic of using the silicate peaks to scale the water peak, before relating this ratio to the sample water concentration. External calibrations directly refer the integrated intensity of peak height of the O-H stretching band to the water content, through the use of a standard glass for which this relationship is well constrained. It assumes a linear relationship between the water peak height and the glass water content. See the references listed above for more details.\n\n\nPlease read carefully the following description, and after that jump into the examples section of Spectra.jl to see Spectra.rameau in action on a fraction of the dataset published in 2012. For the full dataset, please consult the American Mineralogist website. To conclude, any bug report, contributions on Github and suggestions will help improving this software and Spectra.jl in general. So you're very welcome to provide any feedback!\n\n\nNOTE ON ABREVIATIONS: Rws in the following refers to the ratio between the area of the water peak and that of the silicate bands.\n\n\n\n\nFunction rameau\n\n\n#\n\n\nSpectra.rameau\n \n \nMethod\n.\n\n\nrameau\n(\npaths\n::\nTuple\n,\nswitches\n::\nTuple\n;\ninput_properties\n=(\n \n,\n0\n),\nprediction_coef\n=\n[\n0.0059\n;\n0.0005\n]\n,\ntemperature\n=\n23\n.\n0\n,\nlaser\n=\n532\n.\n0\n,\nlb_break\n=\n1600\n.,\nhb_start\n=\n2600\n.,\nroi_hf_external\n \n=\n \n[\n3000\n.\n \n3100\n.\n;\n \n3800\n.\n \n3900\n.\n]\n,\nbasetype\n=\ngcvspline\n,\nmmap_switch\n=\ntrue\n)\n\n\n\n\n\n\nINPUTS:\n\n\npaths\n:\n \nTuple\n{\nStrings\n},\n \nit\n \ncontains\n \nthe\n \nfollowing\n \nstrings\n:\n\n\n    \nin_liste\n:\n \nthe\n \nrelative\n \npath\n \nof\n \nyour\n \nliste\n \nof\n \nspectra\n \n(\nsee\n \nthe\n \ndescription\n \nof\n \nthis\n \nliste\n \nbelow\n),\n \ne\n.\ng\n.\n \n./liste_2012.csv\n\n\n    \nin_path\n \n=\n \nthe\n \nrelative\n \npath\n \nof\n \nthe\n \nrepertory\n \nwhere\n \nyour\n \nraw\n \nspectra\n \nare\n \nstored\n,\n \ne\n.\ng\n.\n \n./raw/\n\n\n    \nout_path\n \n=\n \nthe\n \nrelative\n \npath\n \nof\n \nthe\n \nrepertory\n \nwhere\n \nyou\n \nwant\n \nto\n \noutput\n \nthe\n \ncorrected\n \nspectra\n,\n \ne\n.\ng\n.\n \n./treated/\n \n(\nTHIS\n \nFOLDER\n \nMUST\n \nEXIST\n \nPRIOR\n \nTO\n \nRUN\n)\n\n\n    \nfig_path\n=\n \nthe\n \nrelative\n \npath\n \nof\n \nthe\n \nrepertory\n \nfor\n \nsaving\n \nthe\n \nfigures\n,\n \ne\n.\ng\n.\n \n./figures/\n\n\n    \nrws_save_file\n \n=\n \nthe\n \nrelative\n \npath\n \nof\n \nthe\n \ncsv\n \nfile\n \nwhere\n \nthe\n \nresults\n \nwill\n \nbe\n \nstored\n,\n \ne\n.\ng\n.\n \nrws_calculated.csv\n.\n \nIf\n \ncalibration\n \nis\n \nset\n \nto\n \nyes\n,\n \nit\n \noutputs\n \nan\n \narray\n \ncontaining\n \nthe\n \nRws\n,\n \nthe\n \nprovided\n \nwater\n \ncontent\n \nand\n \nthe\n \ncalculated\n \nwater\n \ncontent\n \nin\n \ncolumns\n \n1\n,\n \n2\n \nand\n \n3\n,\n \nrespectively\n.\n \nIf\n \ncalibration\n \nis\n \nset\n \nto\n \nanything\n \nelse\n,\n \nit\n \noutputs\n \nthe\n \nrws\n \nand\n \nthe\n \nwater\n \ncontent\n \npredicted\n \nwith\n \nthe\n \nprovided\n \nprediction_coef\n\n\n    \nrws_save_fig\n \n=\n \nthe\n \nrelative\n \npath\n \nof\n \nthe\n \nfigure\n \nfor\n \nthe\n \ncalibration\n,\n \ne\n.\ng\n.\n \nrws_calculated.jpg\n.\n \nNote\n:\n \nIt\n \nonly\n \nworks\n \nwhen\n \ncalibration\n \nis\n \non\n \nyes\n,\n \nand\n \nType_of_calibration\n \nis\n \nset\n \non\n \ninternal\n.\n \nJust\n \nset\n \nit\n \nto\n \ntrash.jpg\n \nif\n \nyou\n \nare\n \nnot\n \ngoing\n \nto\n \nuse\n \nit\n.\n\n\n\ninput_properties\n:\n \nTuple\n,\n \nit\n \ncontains\n \nthe\n \ndelimiter\n \nof\n \nthe\n \ncolumns\n \nin\n \nyour\n \nspectra\n \nfiles\n,\n \nand\n \nthe\n \nnumber\n \nof\n \nstarting\n \nlines\n \nto\n \nskip\n.\n \nFor\n \ninstance\n,\n \nuse\n \n(\n \n,\n1\n)\n \nif\n \nyour\n \nfiles\n \nhave\n \none\n \nheader\n \nline\n \nand\n \nthe\n \ncolumns\n \nare\n \nseparated\n  \nby\n \ntabulations\n,\n \nor\n \n(\n,\n,\n0\n)\n \nif\n \nyou\n \nuse\n \nCSV\n \nfiles\n \nwithout\n \nheader\n.\n\n\n\nswitches\n:\n \nTuple\n,\n \nit\n \ncontains\n \nthe\n \ndifferent\n \nswitches\n \nas\n \n(\nType_of_calibration\n,\n \ncalibration\n?,\n \nexperimental\n?,\n \ntemperature_laser_correction\n?).\n\n\n    \nType_of_calibration\n:\n \nshould\n \nbe\n \nset\n \nto\n \ninternal\n \nor\n \nexternal\n.\n \nThe\n \nexternal\n \nmode\n \nrequires\n \nstandards\n,\n \nas\n \ndescribed\n \nin\n \nBehrens\n \net\n \nal\n.\n \n(\n2006\n)\n \nand\n \nThomas\n \net\n \nal\n.\n \n(\n2008\n).\n \nIf\n \nyou\n \nuse\n \nthe\n \nexternal\n \nmode\n,\n \nyou\n \ncan\n \nleave\n \nblanks\n \nfor\n \nthe\n \nother\n \nswitches\n.\n \nFor\n \ninstance\n,\n \nenter\n \n(\nexternal\n,\n,\n,\n).\n\n\n    \ncalibration\n?\n \n:\n  \nuse\n \nonly\n \nwith\n \nthe\n \ninternal\n \nmode\n,\n \nthis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nEnter\n \nyes\n \nif\n \nyou\n \nare\n \nsetting\n \nup\n \na\n \nnew\n \ncalibration\n,\n \nor\n \nno\n \nif\n \nyou\n \nwant\n \nto\n \nuse\n \na\n \npreviously\n \ndetermined\n \ncalibration\n \ncoefficient\n \nwith\n \nproviding\n \nthe\n \nlater\n \nin\n \nthe\n \nprediction_coef\n \nvariable\n \n(\nsee\n \noptions\n).\n\n\n    \nexperimental\n?\n \n:\n \nuse\n \nonly\n \nwith\n \nthe\n \ninternal\n \nmode\n,\n \nthis\n \nis\n \nan\n \nexperimental\n \ncode\n.\n \nFor\n \nnow\n,\n \nonly\n \nthe\n \ndouble\n \nfeature\n \nis\n \nadvised\n.\n \nIt\n \nallows\n \nusing\n \ndifferent\n \nsmoothing\n \nspline\n \ncoefficients\n \nfor\n \nthe\n \nwater\n \nand\n \nsilicate\n \nbands\n,\n \ndelimited\n \nby\n \nthe\n \nlb_break\n \nand\n \nhb_start\n \nvariables\n \n(\nsee\n \nbelow\n).\n\n\n    \ntemperature_laser_correction\n?\n \n:\n \nuse\n \nonly\n \nwith\n \nthe\n \ninternal\n \nmode\n,\n \nthis\n \nshould\n \nbe\n \nequal\n \nto\n \nyes\n \nor\n \nno\n.\n \nThis\n \nasks\n \nif\n \nyou\n \nwant\n \nto\n \nuse\n \nthe\n \ntemperature\n-\nlaser\n \nwavelength\n \ncorrection\n \nas\n \ndone\n \nin\n \nLe\n \nLosq\n \net\n \nal\n.\n \n(\n2012\n).\n \nIf\n \nyou\n \nuse\n \nthe\n \ndouble\n \nbaseline\n \nmode\n,\n \nthis\n \ncorrection\n \nis\n \napplied\n \nafter\n \nremoving\n \nthe\n \nbackground\n \nunder\n \nthe\n \nwater\n \npeak\n.\n\n\n\n\n\n\nOPTIONS:\n\n\nprediction_coef\n:\n \nArray\n{\nFloat64\n},\n \nthis\n \narray\n \ncontains\n \nthe\n \ncalibration\n \ncoefficient\n \nwith\n \nits\n \nerror\n \nbar\n.\n \nThose\n \nvalues\n \nwill\n \nbe\n \nused\n \nin\n \nthe\n \npredictions\n,\n \nif\n \nyou\n \nuse\n \nthe\n \npredictive\n \nmode\n \n(\ni\n.\ng\n.,\n \ncalibration\n \nswitch\n \nis\n \nnot\n \nset\n \nto\n \nyes\n).\n \nDefault\n \n=\n \n[\n0.0059\n;\n0.0005\n].\n\n\n\ntemperature\n:\n \nFloat64\n,\n \nthe\n \ntemperature\n \nfor\n \nthe\n \ntemperature\n-\nlaser\n \nwavelength\n \ncorrection\n \nin\n \nCelsius\n.\n \nDefault\n \n=\n \n23.0\n.\n\n\n\nlaser\n:\n \nFloat64\n,\n \nthe\n \nlaser\n \nwavelength\n \nin\n \nnm\n \nfor\n \nthe\n \ntemperature\n-\nlaser\n \nwavelength\n \ncorrection\n.\n \nDefault\n \n=\n \n532.0\n.\n\n\n\nlb_break\n:\n \nFloat64\n,\n \nfor\n \ndouble\n \nbaseline\n \ncorrection\n,\n \nthe\n \nbreaking\n \npoint\n \nbefore\n \nwhich\n \nthe\n \nsoftware\n \nwill\n \nconsider\n \nthe\n \nBIRs\n \nin\n \nthe\n \nlow\n \nfrequency\n \nregion\n.\n \nDefault\n \n=\n \n2010.0\n.\n\n\n\nhb_start\n:\n \nFloat64\n,\n \nfor\n \ndouble\n \nbaseline\n \ncorrection\n,\n \nthe\n \nbreaking\n \npoint\n \nafter\n \nwhich\n \nthe\n \nsoftware\n \nwill\n \nconsider\n \nthe\n \nBIRs\n \nin\n \nthe\n \nhigh\n \nfrequency\n \nregion\n.\n \nDefault\n \n=\n \n1000.0\n.\n\n\n\n\n\n\nroi_hf_external: Array{Float64}, the roi for fitting the linear baseline in the external calibration mode. Default = [3000. 3100.; 3800. 3900.].\n\n\nbasetype\n:\n \nString\n,\n \nthe\n \ntype\n \nof\n \nbaseline\n \nyou\n \nwant\n \nto\n \nfit\n.\n \nCorresponds\n \nto\n \nthe\n \nbasetype\n \nparameter\n \nof\n \nthe\n \nbaseline\n \nfunction\n.\n  \nDefault\n \n=\n \ngcvspline\n.\n\n\n\n\n\n\nmmap_switch: false or true, this allows to switch on or off the memory mapping in the \nreadcsv\n/\nreaddlm\n functions that \nrameau\n uses. Default = \"true\".\n\n\nOUTPUTS:\n\n\nRameau does not provide any outputs directly in Julia, but saves everything in the folders you indicate in the variable \npaths\n.\n\n\n\n\n\nsource\n\n\n\n\nQuick examples\n\n\nIn this example, the Julia code and the csv liste (myliste.csv) of spectra are in the working folder, the data are in ./raw/, and we want to output the corrected spectra and the figures in the ./treated/ and ./figures/ folders. So we set things like:\n\n\nin_liste: \n./myliste.csv\n\n\nin_path = \n./raw/\n\n\nout_path = \n./treated/\n\n\nfig_path= \n./figures/\n\n\nrws_save_file = \n./treated/\n\n\nrws_save_fig = \n./figures/mycalibration.pdf\n\n\npaths = (in_liste,in_path,out_path,fig_path,rws_save_file,rws_save_fig)\n\n\n\n\n\nNow, for performing an internal calibration as explained in Le Losq et al. (2012), enter:\n\n\nswitches = (\ninternal\n,\nyes\n,\nno\n,\nyes\n)\n\n\n\n\n\nand call Rameau:\n\n\nrameau(paths,switches,input_properties = (\n\\t\n,0))\n\n\n\n\n\nThis will allow you to get your prediction coefficient prediction_coef With this knowledge, you can predict values from the spectra of new glasses with the names in \"myliste_newglasses.csv\" with using the commands:\n\n\nin_liste = \nmyliste_newglasses.csv\n\n\nswitches = (\ninternal\n,\nno\n,\nno\n,\nyes\n)\n\nrameau(paths,switches,prediction_coef = 0.0059, input_properties = (\n\\t\n,0))\n\n\n\n\n\nFor an external calibration, you need a standard glass with known water concentration. You also need the knowledge of the densities of the standard and sample glasses. Then, the following commands allow you to calculate the water content of your sample with using the protocol described in Thomas et al. (2008; see also references cited therein):\n\n\nin_liste: \n./myliste.csv\n\n\nin_path = \n./raw/\n\n\nout_path = \n./treated/\n\n\nfig_path= \n./figures/\n\n\nrws_save_file = \nwater_contents_external_calibration.csv\n # this will save the output values\n\nrws_save_fig = \n # not used in the external mode\n\npaths = (in_liste,in_path,out_path,fig_path,rws_save_file,rws_save_fig)\n\nswitches = (\nexternal\n,\nno\n,\nno\n,\nno\n)\n\nrameau(paths,switches,input_properties = (\n\\t\n,0))\n\n\n\n\n\n\n\nInput file liste\n\n\nThe great news about RamEau in Julia is that you can work your file liste in Excel, as it is now a CSV file. It makes it much more pleasant to use, and readable.\n\n\nIf using the \"internal\" mode, this file liste MUST contain:\n\n\ncolumn\n \n1\n:\n \nthe\n \nfile\n \nname\n \nand\n \nextensions\n,\n \ne\n.\ng\n.\n \nmyspectrum\n.\ntxt\n;\n\n\n\ncolumn\n \n2\n:\n \nthe\n \nname\n \nof\n \nyour\n \nproduct\n;\n\n\n\ncolumn\n \n3\n:\n \nthe\n \nwater\n \ncontent\n,\n \nif\n \nknown\n.\n \nIf\n \nunknow\n,\n \nput\n \n0\n.\n0\n;\n\n\n\ncolumn\n \n4\n:\n \nthe\n \nspline\n \ncoefficient\n \nfor\n \nthe\n \nsilicate\n \npart\n.\n \nNote\n:\n \nthis\n \nvalue\n \nis\n \nused\n \nin\n \nthe\n \nsingle\n \nbaseline\n \nprocedure\n \nfor\n \nthe\n \nwhole\n \nspectrum\n;\n\n\n\ncolumn\n \n5\n:\n \nthe\n \nspline\n \ncoefficient\n \nfor\n \nthe\n \nwater\n \npart\n,\n \nin\n \ncase\n \nyou\n \nuse\n \nthe\n \nexperimental\n \nmode\n \nwith\n \nthe\n \ndouble\n \nbaseline\n \nfitting\n \nprocedure\n \n(\nexperimental\n?\n \n=\n \nyes\n \n+\n \ntemperature_laser_correction\n?\n \n=\n \nyes\n);\n\n\n\ncolumns\n \n6\n \nto\n \nend\n:\n \nthe\n \nbeginning\n \nand\n \nends\n \nof\n \nthe\n \nBIRs\n,\n \npaired\n.\n \nPlease\n \nkeep\n \nthe\n \nsame\n \nnumber\n \nof\n \nBIRs\n \nfor\n \nall\n \nthe\n \nspectra\n \nin\n \none\n \nbatch\n.\n\n\n\n\n\n\nIf using the \"external\" mode, this file liste MUST contain:\n\n\ncolumn\n \n1\n:\n \nthe\n \nfile\n \nname\n \nand\n \nextensions\n \nof\n \nthe\n \nreferences\n,\n \ne\n.\ng\n.\n \nmyreference\n.\ntxt\n;\n\n\n\ncolumn\n \n2\n:\n \nthe\n \nname\n \nof\n \nyour\n \nreferences\n;\n\n\n\ncolumn\n \n3\n:\n \nthe\n \nwater\n \ncontent\n \nof\n \nthe\n \nreferences\n,\n \nin\n \nwt\n%;\n\n\n\ncolumn\n \n4\n:\n \nthe\n \ndensity\n \nof\n \nthe\n \nreferences\n,\n \nin\n \nkg\n \nm-3\n;\n\n\n\ncolumn\n \n5\n:\n \nthe\n \nfile\n \nname\n \nand\n \nextensions\n \nof\n \nthe\n \nsamples\n,\n \ne\n.\ng\n.\n \nmysample\n.\ntxt\n;\n\n\n\ncolumn\n \n6\n:\n \nthe\n \nname\n \nof\n \nyour\n \nsamples\n;\n\n\n\ncolumn\n \n7\n:\n \nthe\n \nestimated\n \ndensity\n \nof\n \nyour\n \nsamples\n,\n \nin\n \nkg\n \nm-3\n.\n\n\n\n\n\n\nWARNING: BE SURE THAT THE NUMBER YOU PROVIDE ARE FLOAT NUMBER!\n\n\n\n\nTemperature and excitation line effects corrections\n\n\nThe \"internal\" mode uses the \"long\" mode of the tlcorrection function, whereas the \"external\" mode uses the \"hehlen\", which takes into account the sample density (see tlcorrection function documentation). This allows to intrisically correct the intensity from density effects.\n\n\n\n\nExperimental mode\n\n\nThe experimental mode contains code for solutions that are currently under development. You may prefer not using it.\n\n\nHowever, an interesting feature is provided there, the \"double\" mode:\n\n\nWhen setting the switch experimental? to \"double\" and combining it with the switch tlcorrection \"yes\", it allows you to use different smoothing coefficients for the silicate and water signals. In order to use it, you must set the wavenumber of the first ROI for the water band above 2500 cm-1, and the last fo the silicate band below 1600 cm-1 (see the example file for instance). The two different smoothing coefficients are indicated in the dataliste csv file.\n\n\n\n\nKRregression baseline fitting vs GCV splines\n\n\nThis is to be used with the internal calibration mode.\n\n\nBack in 2012 we mostly used the Generalized Cross-Validated splines for fitting the spectral background. However, recent developments show that KRregression or SVMregression may provid better results with less headache for the user (not need to tune the spline coefficient parameter). From experience, using a spline carefully adjusted provides better result. However, using KRregression may provide good results without headache to adjust any parameter. For now this is an experimental feature.\n\n\nUpdates Spetember 2016: A well-adjusted gcvspline usually outperforms the KRregression mode. I advise sticking with the gcvspline for now.", 
            "title": "Rameau"
        }, 
        {
            "location": "/Rameau/#rameau", 
            "text": "", 
            "title": "RamEau"
        }, 
        {
            "location": "/Rameau/#introductory-notes", 
            "text": "This is the Julia version of the RamEau software. It allows quantification of the water content of glasses following the internal and external protocols described in:  Thomas, R. 2000. \u201cDetermination of Water Contents of Granite Melt Inclusions by Confocal Laser Raman Microprobe Spectroscopy.\u201d American Mineralogist 85 (5-6): 868\u201372.  Behrens, Harald, Jacques Roux, Daniel R. Neuville, and Michael Siemann. 2006. \u201cQuantification of Dissolved H2O in Silicate Glasses Using Confocal microRaman Spectroscopy.\u201d Chemical Geology 229 (1-3): 96\u2013112. doi:10.1016/j.chemgeo.2006.01.014.  Le Losq, Neuville, Moretti, Roux, 2012. Determination of water content in silicate glasses using Raman spectrometry: Implications for the study of explosive volcanism. American Mineralogist 97, 779-790.  The Rameau Pascal/fortran initial software is available through the american mineralogist website. This version goes much beyond the previous version. It allows using various modes for internal calibration, and further allows using external calibrations too.  Internal calibration mode refers to the technic of using the silicate peaks to scale the water peak, before relating this ratio to the sample water concentration. External calibrations directly refer the integrated intensity of peak height of the O-H stretching band to the water content, through the use of a standard glass for which this relationship is well constrained. It assumes a linear relationship between the water peak height and the glass water content. See the references listed above for more details.  Please read carefully the following description, and after that jump into the examples section of Spectra.jl to see Spectra.rameau in action on a fraction of the dataset published in 2012. For the full dataset, please consult the American Mineralogist website. To conclude, any bug report, contributions on Github and suggestions will help improving this software and Spectra.jl in general. So you're very welcome to provide any feedback!  NOTE ON ABREVIATIONS: Rws in the following refers to the ratio between the area of the water peak and that of the silicate bands.", 
            "title": "Introductory notes"
        }, 
        {
            "location": "/Rameau/#function-rameau", 
            "text": "#  Spectra.rameau     Method .  rameau ( paths :: Tuple , switches :: Tuple ; input_properties =(   , 0 ), prediction_coef = [ 0.0059 ; 0.0005 ] , temperature = 23 . 0 , laser = 532 . 0 , lb_break = 1600 ., hb_start = 2600 ., roi_hf_external   =   [ 3000 .   3100 . ;   3800 .   3900 . ] , basetype = gcvspline , mmap_switch = true )   INPUTS:  paths :   Tuple { Strings },   it   contains   the   following   strings : \n\n     in_liste :   the   relative   path   of   your   liste   of   spectra   ( see   the   description   of   this   liste   below ),   e . g .   ./liste_2012.csv \n\n     in_path   =   the   relative   path   of   the   repertory   where   your   raw   spectra   are   stored ,   e . g .   ./raw/ \n\n     out_path   =   the   relative   path   of   the   repertory   where   you   want   to   output   the   corrected   spectra ,   e . g .   ./treated/   ( THIS   FOLDER   MUST   EXIST   PRIOR   TO   RUN ) \n\n     fig_path =   the   relative   path   of   the   repertory   for   saving   the   figures ,   e . g .   ./figures/ \n\n     rws_save_file   =   the   relative   path   of   the   csv   file   where   the   results   will   be   stored ,   e . g .   rws_calculated.csv .   If   calibration   is   set   to   yes ,   it   outputs   an   array   containing   the   Rws ,   the   provided   water   content   and   the   calculated   water   content   in   columns   1 ,   2   and   3 ,   respectively .   If   calibration   is   set   to   anything   else ,   it   outputs   the   rws   and   the   water   content   predicted   with   the   provided   prediction_coef \n\n     rws_save_fig   =   the   relative   path   of   the   figure   for   the   calibration ,   e . g .   rws_calculated.jpg .   Note :   It   only   works   when   calibration   is   on   yes ,   and   Type_of_calibration   is   set   on   internal .   Just   set   it   to   trash.jpg   if   you   are   not   going   to   use   it .  input_properties :   Tuple ,   it   contains   the   delimiter   of   the   columns   in   your   spectra   files ,   and   the   number   of   starting   lines   to   skip .   For   instance ,   use   (   , 1 )   if   your   files   have   one   header   line   and   the   columns   are   separated    by   tabulations ,   or   ( , , 0 )   if   you   use   CSV   files   without   header .  switches :   Tuple ,   it   contains   the   different   switches   as   ( Type_of_calibration ,   calibration ?,   experimental ?,   temperature_laser_correction ?). \n\n     Type_of_calibration :   should   be   set   to   internal   or   external .   The   external   mode   requires   standards ,   as   described   in   Behrens   et   al .   ( 2006 )   and   Thomas   et   al .   ( 2008 ).   If   you   use   the   external   mode ,   you   can   leave   blanks   for   the   other   switches .   For   instance ,   enter   ( external , , , ). \n\n     calibration ?   :    use   only   with   the   internal   mode ,   this   should   be   equal   to   yes   or   no .   Enter   yes   if   you   are   setting   up   a   new   calibration ,   or   no   if   you   want   to   use   a   previously   determined   calibration   coefficient   with   providing   the   later   in   the   prediction_coef   variable   ( see   options ). \n\n     experimental ?   :   use   only   with   the   internal   mode ,   this   is   an   experimental   code .   For   now ,   only   the   double   feature   is   advised .   It   allows   using   different   smoothing   spline   coefficients   for   the   water   and   silicate   bands ,   delimited   by   the   lb_break   and   hb_start   variables   ( see   below ). \n\n     temperature_laser_correction ?   :   use   only   with   the   internal   mode ,   this   should   be   equal   to   yes   or   no .   This   asks   if   you   want   to   use   the   temperature - laser   wavelength   correction   as   done   in   Le   Losq   et   al .   ( 2012 ).   If   you   use   the   double   baseline   mode ,   this   correction   is   applied   after   removing   the   background   under   the   water   peak .   OPTIONS:  prediction_coef :   Array { Float64 },   this   array   contains   the   calibration   coefficient   with   its   error   bar .   Those   values   will   be   used   in   the   predictions ,   if   you   use   the   predictive   mode   ( i . g .,   calibration   switch   is   not   set   to   yes ).   Default   =   [ 0.0059 ; 0.0005 ].  temperature :   Float64 ,   the   temperature   for   the   temperature - laser   wavelength   correction   in   Celsius .   Default   =   23.0 .  laser :   Float64 ,   the   laser   wavelength   in   nm   for   the   temperature - laser   wavelength   correction .   Default   =   532.0 .  lb_break :   Float64 ,   for   double   baseline   correction ,   the   breaking   point   before   which   the   software   will   consider   the   BIRs   in   the   low   frequency   region .   Default   =   2010.0 .  hb_start :   Float64 ,   for   double   baseline   correction ,   the   breaking   point   after   which   the   software   will   consider   the   BIRs   in   the   high   frequency   region .   Default   =   1000.0 .   roi_hf_external: Array{Float64}, the roi for fitting the linear baseline in the external calibration mode. Default = [3000. 3100.; 3800. 3900.].  basetype :   String ,   the   type   of   baseline   you   want   to   fit .   Corresponds   to   the   basetype   parameter   of   the   baseline   function .    Default   =   gcvspline .   mmap_switch: false or true, this allows to switch on or off the memory mapping in the  readcsv / readdlm  functions that  rameau  uses. Default = \"true\".  OUTPUTS:  Rameau does not provide any outputs directly in Julia, but saves everything in the folders you indicate in the variable  paths .  source", 
            "title": "Function rameau"
        }, 
        {
            "location": "/Rameau/#quick-examples", 
            "text": "In this example, the Julia code and the csv liste (myliste.csv) of spectra are in the working folder, the data are in ./raw/, and we want to output the corrected spectra and the figures in the ./treated/ and ./figures/ folders. So we set things like:  in_liste:  ./myliste.csv \n\nin_path =  ./raw/ \n\nout_path =  ./treated/ \n\nfig_path=  ./figures/ \n\nrws_save_file =  ./treated/ \n\nrws_save_fig =  ./figures/mycalibration.pdf \n\npaths = (in_liste,in_path,out_path,fig_path,rws_save_file,rws_save_fig)  Now, for performing an internal calibration as explained in Le Losq et al. (2012), enter:  switches = ( internal , yes , no , yes )  and call Rameau:  rameau(paths,switches,input_properties = ( \\t ,0))  This will allow you to get your prediction coefficient prediction_coef With this knowledge, you can predict values from the spectra of new glasses with the names in \"myliste_newglasses.csv\" with using the commands:  in_liste =  myliste_newglasses.csv \n\nswitches = ( internal , no , no , yes )\n\nrameau(paths,switches,prediction_coef = 0.0059, input_properties = ( \\t ,0))  For an external calibration, you need a standard glass with known water concentration. You also need the knowledge of the densities of the standard and sample glasses. Then, the following commands allow you to calculate the water content of your sample with using the protocol described in Thomas et al. (2008; see also references cited therein):  in_liste:  ./myliste.csv \n\nin_path =  ./raw/ \n\nout_path =  ./treated/ \n\nfig_path=  ./figures/ \n\nrws_save_file =  water_contents_external_calibration.csv  # this will save the output values\n\nrws_save_fig =   # not used in the external mode\n\npaths = (in_liste,in_path,out_path,fig_path,rws_save_file,rws_save_fig)\n\nswitches = ( external , no , no , no )\n\nrameau(paths,switches,input_properties = ( \\t ,0))", 
            "title": "Quick examples"
        }, 
        {
            "location": "/Rameau/#input-file-liste", 
            "text": "The great news about RamEau in Julia is that you can work your file liste in Excel, as it is now a CSV file. It makes it much more pleasant to use, and readable.  If using the \"internal\" mode, this file liste MUST contain:  column   1 :   the   file   name   and   extensions ,   e . g .   myspectrum . txt ;  column   2 :   the   name   of   your   product ;  column   3 :   the   water   content ,   if   known .   If   unknow ,   put   0 . 0 ;  column   4 :   the   spline   coefficient   for   the   silicate   part .   Note :   this   value   is   used   in   the   single   baseline   procedure   for   the   whole   spectrum ;  column   5 :   the   spline   coefficient   for   the   water   part ,   in   case   you   use   the   experimental   mode   with   the   double   baseline   fitting   procedure   ( experimental ?   =   yes   +   temperature_laser_correction ?   =   yes );  columns   6   to   end :   the   beginning   and   ends   of   the   BIRs ,   paired .   Please   keep   the   same   number   of   BIRs   for   all   the   spectra   in   one   batch .   If using the \"external\" mode, this file liste MUST contain:  column   1 :   the   file   name   and   extensions   of   the   references ,   e . g .   myreference . txt ;  column   2 :   the   name   of   your   references ;  column   3 :   the   water   content   of   the   references ,   in   wt %;  column   4 :   the   density   of   the   references ,   in   kg   m-3 ;  column   5 :   the   file   name   and   extensions   of   the   samples ,   e . g .   mysample . txt ;  column   6 :   the   name   of   your   samples ;  column   7 :   the   estimated   density   of   your   samples ,   in   kg   m-3 .   WARNING: BE SURE THAT THE NUMBER YOU PROVIDE ARE FLOAT NUMBER!", 
            "title": "Input file liste"
        }, 
        {
            "location": "/Rameau/#temperature-and-excitation-line-effects-corrections", 
            "text": "The \"internal\" mode uses the \"long\" mode of the tlcorrection function, whereas the \"external\" mode uses the \"hehlen\", which takes into account the sample density (see tlcorrection function documentation). This allows to intrisically correct the intensity from density effects.", 
            "title": "Temperature and excitation line effects corrections"
        }, 
        {
            "location": "/Rameau/#experimental-mode", 
            "text": "The experimental mode contains code for solutions that are currently under development. You may prefer not using it.  However, an interesting feature is provided there, the \"double\" mode:  When setting the switch experimental? to \"double\" and combining it with the switch tlcorrection \"yes\", it allows you to use different smoothing coefficients for the silicate and water signals. In order to use it, you must set the wavenumber of the first ROI for the water band above 2500 cm-1, and the last fo the silicate band below 1600 cm-1 (see the example file for instance). The two different smoothing coefficients are indicated in the dataliste csv file.", 
            "title": "Experimental mode"
        }, 
        {
            "location": "/Rameau/#krregression-baseline-fitting-vs-gcv-splines", 
            "text": "This is to be used with the internal calibration mode.  Back in 2012 we mostly used the Generalized Cross-Validated splines for fitting the spectral background. However, recent developments show that KRregression or SVMregression may provid better results with less headache for the user (not need to tune the spline coefficient parameter). From experience, using a spline carefully adjusted provides better result. However, using KRregression may provide good results without headache to adjust any parameter. For now this is an experimental feature.  Updates Spetember 2016: A well-adjusted gcvspline usually outperforms the KRregression mode. I advise sticking with the gcvspline for now.", 
            "title": "KRregression baseline fitting vs GCV splines"
        }, 
        {
            "location": "/MLregressor/", 
            "text": "Machine Learning Regression\n\n\nSpectra offers a basic access to some machine learning algorithms from the SciKit Learn python library. In addition to using them for baseline fitting, you can also use them to predict an output. For instance, if you have several spectra that you pre-processed with Spectra, you can organise them with each spectra as a row of a large array. Each column will be a channel, or also called a feature, that the machine learning algorithms will look at. From this, Spectra allows you to call\n\n\n\n\nthe Support Vector or Kernel Ridge regression algorithms from SciKit Learn;\n\n\n\n\n- the Linear Regression algorithm from SciKit Learn.\n\n\n\n\n\nWith those algorithm, you can predict a y value (for instance, the concentration of a component that seems to affect the spectral shape) that is related to changes in your spectra. This is done with the mlregressor function. A more extensive use of the SciKit Learn algorithms can be done directly with calling SciKit Learn using a PyCall instance.\n\n\n#\n\n\nSpectra.mlregressor\n \n \nMethod\n.\n\n\nfunction\n \nmlregressor\n(\nx\n::\nArray\n{\nFloat64\n},\ny\n::\nArray\n{\nFloat64\n},\nalgorithm\n::\nAbstractString\n;\nX_test\n::\nArray\n{\nFloat64\n}\n=\n[\n0.0\n],\ny_test\n::\nArray\n{\nFloat64\n}\n=\n[\n0.0\n],\ntest_sz\n=\n0.3\n,\nscaler\n=\nMinMaxScaler\n,\nrand_state\n=\n42\n,\nparam_grid_kr\n \n=\n \nDict\n(\nalpha\n=\n \n[\n1\ne1\n,\n \n1\ne0\n,\n \n0.5\n,\n \n0.1\n,\n \n5\ne\n-\n2\n,\n \n1\ne\n-\n2\n,\n \n5\ne\n-\n3\n,\n \n1\ne\n-\n3\n],\ngamma\n=\n \nlogspace\n(\n-\n4\n,\n \n4\n,\n \n9\n)),\nparam_grid_svm\n=\nDict\n(\nC\n=\n \n[\n1\ne0\n,\n \n2\ne0\n,\n \n5\ne0\n,\n \n1\ne1\n,\n \n5\ne1\n,\n \n1\ne2\n,\n \n5\ne2\n,\n \n1\ne3\n,\n \n5\ne3\n,\n \n1\ne4\n,\n \n5\ne4\n,\n \n1\ne5\n],\ngamma\n=\n \nlogspace\n(\n-\n4\n,\n \n4\n,\n \n9\n)),\nuser_kernel\n=\nrbf\n)\n\n\n\n\n\n\nWorking on that, please be careful when using it.   \n\n\nINPUTS\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nspectra\n \norganised\n \nin\n \nrows\n \n(\n1\n \nrow\n \n=\n \none\n \nspectrum\n).\n \nThe\n \nspectra\n \nshould\n \nshare\n \na\n \ncommon\n \nX\n \naxis\n;\n\n\n\ny\n::\nArray\n{\nFloat64\n},\n \nthe\n \ntarget\n.\n \nOnly\n \na\n \nsigle\n \ntarget\n \nis\n \npossible\n \nfor\n \nnow\n.\n\n\n\nalgorithm\n:\n \nAbstractString\n,\n \nKernelRidge\n \nor\n \nSVM\n \nor\n \nLinearRegression\n\n\n\n\n\n\nOPTIONS\n\n\nX_test\n:\n \nArray\n{\nFloat64\n},\n \nspectra\n \norganised\n \nin\n \nrows\n \n(\n1\n \nrow\n \n=\n \none\n \nspectrum\n)\n \nthat\n \nyou\n \nwant\n \nto\n \nuse\n \nas\n \na\n \ntesting\n \ndataset\n.\n \nTHose\n \nspectra\n \nshould\n \nnot\n \nbe\n \npresent\n \nin\n \nthe\n \nx\n \n(\ntraining\n)\n \ndataset\n.\n \nThe\n \nspectra\n \nshould\n \nshare\n \na\n \ncommon\n \nX\n \naxis\n;\n\n\n\ny_test\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \ntarget\n \nthat\n \nyou\n \nwant\n \nto\n \nuse\n \nas\n \na\n \ntesting\n \ndataset\n.\n \nThose\n \ntargets\n \nshould\n \nnot\n \nbe\n \npresent\n \nin\n \nthe\n \ny\n \n(\ntraining\n)\n \ndataset\n;\n\n\n\nscaler\n:\n \nString\n,\n \nthe\n \ntype\n \nof\n \nscaling\n \nperformed\n.\n \nChoose\n \nbetween\n \nMinMaxScaler\n \nor\n \nStandardScaler\n,\n \nsee\n \nhttp\n://\nscikit\n-\nlearn\n.\norg\n/stable/modules/\npreprocessing\n.\nhtml\n \nfor\n \ndetails\n.\n \nDefault\n \n=\n \nMinMaxScaler\n;\n\n\n\nrand_state\n:\n \nFloat64\n,\n \nthe\n \nrandom\n \nseed\n \nthat\n \nis\n \nused\n \nfor\n \nreproductibility\n \nof\n \nthe\n \nresults\n.\n \nDefault\n \n=\n \n42\n;\n\n\n\nparam_grid_kr\n:\n \nDictionary\n,\n \ncontaing\n \nthe\n \nvalues\n \nof\n \nthe\n \nhyperparameters\n \nthat\n \nshould\n \nbe\n \nchecked\n \nby\n \ngridsearch\n \nfor\n \nthe\n \nKernel\n \nRidge\n \nregression\n \nalgorithm\n;\n\n\n\nparam_grid_svm\n:\n \nDictionary\n,\n \ncontaing\n \nthe\n \nvalues\n \nof\n \nthe\n \nhyperparameters\n \nthat\n \nshould\n \nbe\n \nchecked\n \nby\n \ngridsearch\n \nfor\n \nthe\n \nSupport\n \nVector\n \nregression\n \nalgorithm\n.\n\n\n\n\n\n\nFor the last two parameters, the user is refered to the documentation of SciKit Learn. See the pages:\n\n\nhttp://scikit-learn.org/stable/modules/kernel_ridge.html\n\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n\n\nOUTPUTS\n\n\nprediction_train\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \npredicted\n \ntarget\n \nvalues\n \nfor\n \nthe\n \ntraining\n \ny\n \ndataset\n;\n\n\n\nprediction_test\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \npredicted\n \ntarget\n \nvalues\n \nfor\n \nthe\n \ntesting\n \ny_test\n \ndataset\n;\n\n\n\nmodel\n:\n \nA\n \nScikit\n \nLearn\n \nobject\n \nmodel\n,\n \nsee\n \nthe\n \nabove\n \nlink\n \nfor\n \ndetails\n;\n\n\n\nX_scaler\n:\n \nA\n \nScikit\n \nLearn\n \nscaler\n \nobject\n \nfor\n \nthe\n \nx\n \nvalues\n;\n\n\n\nY_scaler\n:\n \nA\n \nScikit\n \nLearn\n \nscaler\n \nobject\n \nfor\n \nthe\n \ny\n \nvalues\n;\n\n\n\n\n\n\nNOTES \n\n\nFor Support Vector and Kernel Ridge regressions, mlregressor performs a cross_validation search with using 5 KFold cross validators. \n\nIf the results are poor with Support Vector and Kernel Ridge regressions, you will have to tune the param_grid_kr or param_grid_svm dictionnary that records the hyperparameter space to investigate during the cross validation.\n\n\n\n\n\nsource", 
            "title": "Machine Learning Regression"
        }, 
        {
            "location": "/MLregressor/#machine-learning-regression", 
            "text": "Spectra offers a basic access to some machine learning algorithms from the SciKit Learn python library. In addition to using them for baseline fitting, you can also use them to predict an output. For instance, if you have several spectra that you pre-processed with Spectra, you can organise them with each spectra as a row of a large array. Each column will be a channel, or also called a feature, that the machine learning algorithms will look at. From this, Spectra allows you to call   the Support Vector or Kernel Ridge regression algorithms from SciKit Learn;   - the Linear Regression algorithm from SciKit Learn.  With those algorithm, you can predict a y value (for instance, the concentration of a component that seems to affect the spectral shape) that is related to changes in your spectra. This is done with the mlregressor function. A more extensive use of the SciKit Learn algorithms can be done directly with calling SciKit Learn using a PyCall instance.  #  Spectra.mlregressor     Method .  function   mlregressor ( x :: Array { Float64 }, y :: Array { Float64 }, algorithm :: AbstractString ; X_test :: Array { Float64 } = [ 0.0 ], y_test :: Array { Float64 } = [ 0.0 ], test_sz = 0.3 , scaler = MinMaxScaler , rand_state = 42 , param_grid_kr   =   Dict ( alpha =   [ 1 e1 ,   1 e0 ,   0.5 ,   0.1 ,   5 e - 2 ,   1 e - 2 ,   5 e - 3 ,   1 e - 3 ], gamma =   logspace ( - 4 ,   4 ,   9 )), param_grid_svm = Dict ( C =   [ 1 e0 ,   2 e0 ,   5 e0 ,   1 e1 ,   5 e1 ,   1 e2 ,   5 e2 ,   1 e3 ,   5 e3 ,   1 e4 ,   5 e4 ,   1 e5 ], gamma =   logspace ( - 4 ,   4 ,   9 )), user_kernel = rbf )   Working on that, please be careful when using it.     INPUTS  x :   Array { Float64 },   the   spectra   organised   in   rows   ( 1   row   =   one   spectrum ).   The   spectra   should   share   a   common   X   axis ;  y :: Array { Float64 },   the   target .   Only   a   sigle   target   is   possible   for   now .  algorithm :   AbstractString ,   KernelRidge   or   SVM   or   LinearRegression   OPTIONS  X_test :   Array { Float64 },   spectra   organised   in   rows   ( 1   row   =   one   spectrum )   that   you   want   to   use   as   a   testing   dataset .   THose   spectra   should   not   be   present   in   the   x   ( training )   dataset .   The   spectra   should   share   a   common   X   axis ;  y_test :   Array { Float64 },   the   target   that   you   want   to   use   as   a   testing   dataset .   Those   targets   should   not   be   present   in   the   y   ( training )   dataset ;  scaler :   String ,   the   type   of   scaling   performed .   Choose   between   MinMaxScaler   or   StandardScaler ,   see   http :// scikit - learn . org /stable/modules/ preprocessing . html   for   details .   Default   =   MinMaxScaler ;  rand_state :   Float64 ,   the   random   seed   that   is   used   for   reproductibility   of   the   results .   Default   =   42 ;  param_grid_kr :   Dictionary ,   containg   the   values   of   the   hyperparameters   that   should   be   checked   by   gridsearch   for   the   Kernel   Ridge   regression   algorithm ;  param_grid_svm :   Dictionary ,   containg   the   values   of   the   hyperparameters   that   should   be   checked   by   gridsearch   for   the   Support   Vector   regression   algorithm .   For the last two parameters, the user is refered to the documentation of SciKit Learn. See the pages:  http://scikit-learn.org/stable/modules/kernel_ridge.html  http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html  OUTPUTS  prediction_train :   Array { Float64 },   the   predicted   target   values   for   the   training   y   dataset ;  prediction_test :   Array { Float64 },   the   predicted   target   values   for   the   testing   y_test   dataset ;  model :   A   Scikit   Learn   object   model ,   see   the   above   link   for   details ;  X_scaler :   A   Scikit   Learn   scaler   object   for   the   x   values ;  Y_scaler :   A   Scikit   Learn   scaler   object   for   the   y   values ;   NOTES   For Support Vector and Kernel Ridge regressions, mlregressor performs a cross_validation search with using 5 KFold cross validators. \n\nIf the results are poor with Support Vector and Kernel Ridge regressions, you will have to tune the param_grid_kr or param_grid_svm dictionnary that records the hyperparameter space to investigate during the cross validation.  source", 
            "title": "Machine Learning Regression"
        }, 
        {
            "location": "/PeakFitting/", 
            "text": "Peak fitting\n\n\n\n\nModel adjustment\n\n\nPeak fitting is done with the JuMP framework (https://jump.readthedocs.org/en/latest/). Spectra.jl actually does not provide any peak fitting capacities by itself, but the combination of its functionality with JuMP helps making fitting procedure quite easy. An example is visible in the example section of Spectra.jl. \n\n\nOne goal of Spectra is to promote the use of global optimisation models, where peak parameters are actually calculated from variation in other parameters (chemistry, temperature, etc.), or are shared between several spectra. I will provide very soon an example of such an approach. It can be implemented in a few lines of code with combining Spectra and JuMP, and has the advantage of greatly reducing the errors of the fits.\n\n\n\n\nerror calculation with bootstrapping\n\n\nError calculation can be done with using bootstrapping. Spectra provides a function that allows generating K new datasetes, by resampling the existing dataset in a non-parametric or parametric way. \n\n\n#\n\n\nSpectra.bootsample\n \n \nMethod\n.\n\n\nbootsample\n(\nx\n::\nArray\n{\nFloat64\n}\n,\n \ny\n::\nArray\n{\nFloat64\n}\n;\n \nboottype\n::\nString\n \n=\n \nnp\n,\n \nese\n::\nArray\n{\nFloat64\n}\n \n=\n \n[\n0.0\n]\n)\n\n\n\n\n\n\nINPUTS\n\n\nx\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nx\n \naxis\n.\n \nIt\n \ncan\n \nhave\n \nmultiple\n \ncolumns\n.\n\n\n\ny\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \ny\n \naxis\n.\n \nIt\n \ncan\n \nhave\n \nmultiple\n \ncolumns\n.\n\n\n\n\n\n\nOPTIONS\n\n\nboottype\n:\n \nASCIIString\n,\n \neither\n \nnp\n \nor\n \np\n,\n \nthis\n \nis\n \nthe\n \ntype\n \nof\n \nbootstrapping\n \nperformed\n.\n \nnp\n \nperformes\n \na\n \nnon\n-\nparametric\n \nresampling\n \nfo\n \nthe\n \ndataset\n \nwith\n \nreplacement\n.\n \np\n \nperforms\n \na\n \nparametric\n \nresampling\n.\n \nThe\n \ndata\n \nare\n \nresample\n \nfrom\n \na\n \ngaussian\n \ndistribution\n \ncentered\n \non\n \nthe\n \ny\n \nvalues\n \nwith\n \nerrors\n \nthat\n \nshould\n \nbe\n \nprovided\n \nin\n \nthe\n \nese\n \nvariable\n.\n\n\n\nese\n:\n \nArray\n{\nFloat64\n},\n \ncontaining\n \nthe\n \nerrors\n \naffecting\n \nthe\n \ny\n \nvalues\n \nthat\n \nare\n \nused\n \nduring\n \nparametric\n \nbootstrapping\n.\n\n\n\n\n\n\nOUTPUTS\n\n\nb_x_f\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nbootstrapped\n \nx\n \nvalues\n\n\n\nb_y_f\n:\n \nArray\n{\nFloat64\n},\n \nthe\n \nbootstrapped\n \ny\n \nvalues\n\n\n\n\n\n\nThe bootstrap function can be embedded in a for loop, and will each time produce a different dataset. Performing K times the bootstrapping and fitting each time the model will allow to estimate the error distribution on the peak parameters. This technic has the advantage of making no prior assumption on the probability distribution functions of parameters errors. However, it is  much more time consuming that using the covariance matrix.\n\n\nsource\n\n\n#\n\n\nSpectra.bootperf\n \n \nMethod\n.\n\n\nbootperf\n(\nparams_boot\n::\nArray\n{\nFloat64\n}\n;\n \nplotting\n::\nString\n \n=\n \nTrue\n,\n \nparameter\n::\nInt64\n \n=\n \n1\n,\n \nfeature\n::\nInt64\n \n=\n \n1\n,\n \nhistogram_step\n::\nInt64\n \n=\n \n100\n,\n \nsavefigures\n::\nString\n \n=\n \nFalse\n,\n \nsave_bootrecord\n::\nString\n \n=\n \nBoot_record.pdf\n,\n \nsave_histogram\n::\nString\n \n=\n \nBoot_histogram.pdf\n)\n\n\n\n\n\n\nparams_boot[i,j] or [i,j,k]: array with i the bootstrrap experiment, j the parameter and k the feature being calculated (e.g., a peak during peak fitting)\n\n\nplotting: switch to plotting mode (\"True\") or not (\"False\"). If true, parameter and feature must be provided, otherwise an error message is returned. \n\n\nhistogram_step is an integer value to control the histogram X axis division.\n\n\nsavefigures: \"True\" or \"False\", explicit, save in the current working directory.\n\n\nsave_bootrecord: Name for the graphic showing the bootstrap mean and std evolutions, with extension.\n\n\nsave_histogram: Name for the graphic showing the histogram for the parameter and feature of interest, with extension.\n\n\nRETURN: std_record, mean_record, the arrays recording how the standard deviation and mean of the parameters as a function of the bootstrap advance. \n\n\nsource\n\n\nFor further details, see the following references\n\n\nEfron, B. 1979. \u201cBootstrap Methods: Another Look at the Jackknife.\u201d The Annals of Statistics 7 (1): 1\u201326.\n\n\nEfron, Bradley. 1981. \u201cNonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.\u201d Biometrika 68 (3): 589\u201399. doi:10.1093/biomet/68.3.589.\n\n\nEfron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.", 
            "title": "Peak Fitting"
        }, 
        {
            "location": "/PeakFitting/#peak-fitting", 
            "text": "", 
            "title": "Peak fitting"
        }, 
        {
            "location": "/PeakFitting/#model-adjustment", 
            "text": "Peak fitting is done with the JuMP framework (https://jump.readthedocs.org/en/latest/). Spectra.jl actually does not provide any peak fitting capacities by itself, but the combination of its functionality with JuMP helps making fitting procedure quite easy. An example is visible in the example section of Spectra.jl.   One goal of Spectra is to promote the use of global optimisation models, where peak parameters are actually calculated from variation in other parameters (chemistry, temperature, etc.), or are shared between several spectra. I will provide very soon an example of such an approach. It can be implemented in a few lines of code with combining Spectra and JuMP, and has the advantage of greatly reducing the errors of the fits.", 
            "title": "Model adjustment"
        }, 
        {
            "location": "/PeakFitting/#error-calculation-with-bootstrapping", 
            "text": "Error calculation can be done with using bootstrapping. Spectra provides a function that allows generating K new datasetes, by resampling the existing dataset in a non-parametric or parametric way.   #  Spectra.bootsample     Method .  bootsample ( x :: Array { Float64 } ,   y :: Array { Float64 } ;   boottype :: String   =   np ,   ese :: Array { Float64 }   =   [ 0.0 ] )   INPUTS  x :   Array { Float64 },   the   x   axis .   It   can   have   multiple   columns .  y :   Array { Float64 },   the   y   axis .   It   can   have   multiple   columns .   OPTIONS  boottype :   ASCIIString ,   either   np   or   p ,   this   is   the   type   of   bootstrapping   performed .   np   performes   a   non - parametric   resampling   fo   the   dataset   with   replacement .   p   performs   a   parametric   resampling .   The   data   are   resample   from   a   gaussian   distribution   centered   on   the   y   values   with   errors   that   should   be   provided   in   the   ese   variable .  ese :   Array { Float64 },   containing   the   errors   affecting   the   y   values   that   are   used   during   parametric   bootstrapping .   OUTPUTS  b_x_f :   Array { Float64 },   the   bootstrapped   x   values  b_y_f :   Array { Float64 },   the   bootstrapped   y   values   The bootstrap function can be embedded in a for loop, and will each time produce a different dataset. Performing K times the bootstrapping and fitting each time the model will allow to estimate the error distribution on the peak parameters. This technic has the advantage of making no prior assumption on the probability distribution functions of parameters errors. However, it is  much more time consuming that using the covariance matrix.  source  #  Spectra.bootperf     Method .  bootperf ( params_boot :: Array { Float64 } ;   plotting :: String   =   True ,   parameter :: Int64   =   1 ,   feature :: Int64   =   1 ,   histogram_step :: Int64   =   100 ,   savefigures :: String   =   False ,   save_bootrecord :: String   =   Boot_record.pdf ,   save_histogram :: String   =   Boot_histogram.pdf )   params_boot[i,j] or [i,j,k]: array with i the bootstrrap experiment, j the parameter and k the feature being calculated (e.g., a peak during peak fitting)  plotting: switch to plotting mode (\"True\") or not (\"False\"). If true, parameter and feature must be provided, otherwise an error message is returned.   histogram_step is an integer value to control the histogram X axis division.  savefigures: \"True\" or \"False\", explicit, save in the current working directory.  save_bootrecord: Name for the graphic showing the bootstrap mean and std evolutions, with extension.  save_histogram: Name for the graphic showing the histogram for the parameter and feature of interest, with extension.  RETURN: std_record, mean_record, the arrays recording how the standard deviation and mean of the parameters as a function of the bootstrap advance.   source  For further details, see the following references  Efron, B. 1979. \u201cBootstrap Methods: Another Look at the Jackknife.\u201d The Annals of Statistics 7 (1): 1\u201326.  Efron, Bradley. 1981. \u201cNonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.\u201d Biometrika 68 (3): 589\u201399. doi:10.1093/biomet/68.3.589.  Efron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.", 
            "title": "error calculation with bootstrapping"
        }, 
        {
            "location": "/Tutorial/", 
            "text": "Tutorial\n\n\nTutorials are available in the examples folder of Spectra.jl (https://github.com/charlesll/Spectra.jl/tree/master/examples) and include notebooks showing how to fit peaks in a Raman spectrum of a glass after subtraction of a baseline. Another example shows how to use Spectra.jl to peak-fit Infrared spectra taken along a diffusion profile in a crystal. Further examples will be added in a very soon future!", 
            "title": "Tutorial"
        }, 
        {
            "location": "/Tutorial/#tutorial", 
            "text": "Tutorials are available in the examples folder of Spectra.jl (https://github.com/charlesll/Spectra.jl/tree/master/examples) and include notebooks showing how to fit peaks in a Raman spectrum of a glass after subtraction of a baseline. Another example shows how to use Spectra.jl to peak-fit Infrared spectra taken along a diffusion profile in a crystal. Further examples will be added in a very soon future!", 
            "title": "Tutorial"
        }, 
        {
            "location": "/Tips/", 
            "text": "Tips\n\n\nIn this section are listed various tips for the use of Julia and Spectra:\n\n\n\n\nInstallation\n\n\n\n\nYou need the gfortran, gcc and g++ compilers. ifort also works. Check that you have them on your system. Even Ubuntu does not necessary come with those compilers out of the box. If you don't know anything about installing them, ask Google: \"Installing gcc/gfortran/g++ on my mac/linux/windows\"\n\n\nWindows users probably need to manually compile the gcvspl.f library if they want to use the GCV spline function. This compilation is automatic on Max OSX and Linux. Please report any problem with that. I actually recommand to either use JuliaBox or to install a Linux distribution in a virtual box to smoothly run Julia and Spectra.\n\n\nIf you see errors messages linked to PyCall, you may have a problem with your environment variable. To solve it, tyope the following commands in the Julia prompt:\n\n\n\n\nENV[\nPYTHON\n]=\n\nPkg.build(\nPyCall\n)\n\n\n\n\n\nAt this point it should work. If yes, you now can enter:\n\n\nPkg.add(\nSpectra\n)\n\n\n\n\n\n\n\nMaintenance\n\n\n\n\nThe Julia package ecosystem is constantly evolving, with daily changes. Because of that, it is strongly recommanded to run in the starting Julia prompt a\n\n\n\n\nPkg.update()\n\n\n\n\n\ncommand every day, at the beginning of your session.\n\n\n\n\nTime to time, after running the Pkg.update() command for instance and trying to directly work with the same Julia session, you may get Warning/Error messages during the packages pre-compilation indicating a problem with Compat. To solve that, just quit the current session (exit the notebooks AND close the terminals), and open a new Julia terminal. Most of the time, this solves the problem.\n\n\n\n\n\n\nRunning Spectra\n\n\n\n\nSpectra is changing every week, if not every day in some case. Do not forget to Pkg.update() quite often, and check the website.\n\n\nAlways be careful to enter float and integer numbers as required by the functions! They will return an error message if you do not do that.\n\n\nFor the spline, do not hesitate to test a broad range in term of order of magnitudes for the smoothing parameter.\n\n\nSVMregression and KRregression will take more time as several models are tried over a broad range of hyperparameters. Therefore, it is normal that those technics require more time, up to ten to twenty minutes for treating 50 to 100 spectra.\n\n\n\n\n\n\nPotential problems\n\n\n\n\nUsing Julia on a Fedora Linux installed in a VirtualBox virtual machine, I encountered the issue of memory mapping not working when trying to read with \nreaddlm\n/\nreadcsv\n some files that where in a VirtualBox shared folder:\n\n\n\n\nLoadError\n:\n \nSystemError\n:\n \nmemory\n \nmapping\n \nfailed\n:\n \nInvalid\n \nargument\n\n\n\n\n\n\nThis issue is solved by setting the optinal argument use_mmap = false in the readcsv/readdlm call. There is an option \nmmap_switch\n (false/true) in \nrameau\n that allows also to set use_mmap, in case you encouter this problem when calling \nrameau\n in a virtual environment.", 
            "title": "Tips"
        }, 
        {
            "location": "/Tips/#tips", 
            "text": "In this section are listed various tips for the use of Julia and Spectra:", 
            "title": "Tips"
        }, 
        {
            "location": "/Tips/#installation", 
            "text": "You need the gfortran, gcc and g++ compilers. ifort also works. Check that you have them on your system. Even Ubuntu does not necessary come with those compilers out of the box. If you don't know anything about installing them, ask Google: \"Installing gcc/gfortran/g++ on my mac/linux/windows\"  Windows users probably need to manually compile the gcvspl.f library if they want to use the GCV spline function. This compilation is automatic on Max OSX and Linux. Please report any problem with that. I actually recommand to either use JuliaBox or to install a Linux distribution in a virtual box to smoothly run Julia and Spectra.  If you see errors messages linked to PyCall, you may have a problem with your environment variable. To solve it, tyope the following commands in the Julia prompt:   ENV[ PYTHON ]= \nPkg.build( PyCall )  At this point it should work. If yes, you now can enter:  Pkg.add( Spectra )", 
            "title": "Installation"
        }, 
        {
            "location": "/Tips/#maintenance", 
            "text": "The Julia package ecosystem is constantly evolving, with daily changes. Because of that, it is strongly recommanded to run in the starting Julia prompt a   Pkg.update()  command every day, at the beginning of your session.   Time to time, after running the Pkg.update() command for instance and trying to directly work with the same Julia session, you may get Warning/Error messages during the packages pre-compilation indicating a problem with Compat. To solve that, just quit the current session (exit the notebooks AND close the terminals), and open a new Julia terminal. Most of the time, this solves the problem.", 
            "title": "Maintenance"
        }, 
        {
            "location": "/Tips/#running-spectra", 
            "text": "Spectra is changing every week, if not every day in some case. Do not forget to Pkg.update() quite often, and check the website.  Always be careful to enter float and integer numbers as required by the functions! They will return an error message if you do not do that.  For the spline, do not hesitate to test a broad range in term of order of magnitudes for the smoothing parameter.  SVMregression and KRregression will take more time as several models are tried over a broad range of hyperparameters. Therefore, it is normal that those technics require more time, up to ten to twenty minutes for treating 50 to 100 spectra.", 
            "title": "Running Spectra"
        }, 
        {
            "location": "/Tips/#potential-problems", 
            "text": "Using Julia on a Fedora Linux installed in a VirtualBox virtual machine, I encountered the issue of memory mapping not working when trying to read with  readdlm / readcsv  some files that where in a VirtualBox shared folder:   LoadError :   SystemError :   memory   mapping   failed :   Invalid   argument   This issue is solved by setting the optinal argument use_mmap = false in the readcsv/readdlm call. There is an option  mmap_switch  (false/true) in  rameau  that allows also to set use_mmap, in case you encouter this problem when calling  rameau  in a virtual environment.", 
            "title": "Potential problems"
        }, 
        {
            "location": "/ToDo/", 
            "text": "To Do\n\n\n\n\nPre-Processing\n\n\n\n\nAdding access to the SMOOTH spline library, used by the csaps Matlab function.\n\n\n\n\n\n\nIntegration\n\n\n\n\ngaussianarea will change in peakarea, with the option to choose between the shape of the peak (gaussian, lorentzian, etc.) ??\n\n\nShould we think to add Simpson's rule integration also?\n\n\nMoving Average smoothing ?", 
            "title": "Todo"
        }, 
        {
            "location": "/ToDo/#to-do", 
            "text": "", 
            "title": "To Do"
        }, 
        {
            "location": "/ToDo/#pre-processing", 
            "text": "Adding access to the SMOOTH spline library, used by the csaps Matlab function.", 
            "title": "Pre-Processing"
        }, 
        {
            "location": "/ToDo/#integration", 
            "text": "gaussianarea will change in peakarea, with the option to choose between the shape of the peak (gaussian, lorentzian, etc.) ??  Should we think to add Simpson's rule integration also?  Moving Average smoothing ?", 
            "title": "Integration"
        }, 
        {
            "location": "/References/", 
            "text": "References\n\n\nBehrens, Harald, Jacques Roux, Daniel R. Neuville, and Michael Siemann. 2006. \u201cQuantification of Dissolved H2O in Silicate Glasses Using Confocal microRaman Spectroscopy.\u201d Chemical Geology 229 (1-3): 96\u2013112. doi:10.1016/j.chemgeo.2006.01.014.\n\n\nBrooker et al. 1988 Assessment of correction procedures for reduction of Raman spectra. Journal of Raman Spectroscopy 19(2), 71-78.\n\n\nEfron, B. 1979. \u201cBootstrap Methods: Another Look at the Jackknife.\u201d The Annals of Statistics 7 (1): 1\u201326.\n\n\nEfron, Bradley. 1981. \u201cNonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.\u201d Biometrika 68 (3): 589\u201399. doi:10.1093/biomet/68.3.589.\n\n\nEfron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.\n\n\nGaleener, F. L., and Sen, P. N. 1978. \u201cTheory of the First-Order Vibrational Spectra of Disordered Solids.\u201d Physical Review B 17 (4): 1928\u201333.\n\n\nHehlen, B. 2010. \u201cInter-Tetrahedra Bond Angle of Permanently Densified Silicas Extracted from Their Raman Spectra.\u201d Journal of Physics: Condensed Matter 22 (2): 025401.\n\n\nLe Losq, C., D. R. Neuville, R. Moretti, and J. Roux. 2012. Determination of Water Content in Silicate Glasses Using Raman Spectrometry: Implications for the Study of Explosive Volcanism. American Mineralogist 97 (5-6): 779\u201390. doi:10.2138/am.2012.3831.\n\n\nLe Losq C., Neuville D. R., Florian P., Henderson G. S. and Massiot D., 2014, The role of Al3+ on rheology and structural changes in sodium silicate and aluminosilicate glasses and melts. Geochimica et Cosmochimica Acta 126, 495-517.\n\n\nNeuville, D. R., and B. O. Mysen. 1996. \u201cRole of Aluminium in the Silicate Network: In Situ, High-Temperature Study of Glasses and Melts on the Join SiO\u2082-NaAl0\u2082.\u201d Geochimica et Cosmochimica Acta 60: 1727\u201337.\n\n\nMysen, B. O., L. W. Finger, D. Virgo, and F. A. Seifert. 1982. \u201cCurve-Fitting of Raman Spectra of Silicate Glasses.\u201d American Mineralogist 67: 686\u201395.\n\n\nShuker, Reuben, and Robert Gammon. 1970. \u201cRaman-Scattering Selection-Rule Breaking and the Density of States in Amorphous Materials.\u201d Physical Review Letters 25 (4): 222\u201325.\n\n\nThomas, R. 2000. \u201cDetermination of Water Contents of Granite Melt Inclusions by Confocal Laser Raman Microprobe Spectroscopy.\u201d American Mineralogist 85 (5-6): 868\u201372.\n\n\nWoltring, 1986, A FORTRAN package for generalized, cross-validatory spline smoothing and differentiation. Adv. Eng. Softw. 8, 104-113.", 
            "title": "References"
        }, 
        {
            "location": "/References/#references", 
            "text": "Behrens, Harald, Jacques Roux, Daniel R. Neuville, and Michael Siemann. 2006. \u201cQuantification of Dissolved H2O in Silicate Glasses Using Confocal microRaman Spectroscopy.\u201d Chemical Geology 229 (1-3): 96\u2013112. doi:10.1016/j.chemgeo.2006.01.014.  Brooker et al. 1988 Assessment of correction procedures for reduction of Raman spectra. Journal of Raman Spectroscopy 19(2), 71-78.  Efron, B. 1979. \u201cBootstrap Methods: Another Look at the Jackknife.\u201d The Annals of Statistics 7 (1): 1\u201326.  Efron, Bradley. 1981. \u201cNonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.\u201d Biometrika 68 (3): 589\u201399. doi:10.1093/biomet/68.3.589.  Efron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.  Galeener, F. L., and Sen, P. N. 1978. \u201cTheory of the First-Order Vibrational Spectra of Disordered Solids.\u201d Physical Review B 17 (4): 1928\u201333.  Hehlen, B. 2010. \u201cInter-Tetrahedra Bond Angle of Permanently Densified Silicas Extracted from Their Raman Spectra.\u201d Journal of Physics: Condensed Matter 22 (2): 025401.  Le Losq, C., D. R. Neuville, R. Moretti, and J. Roux. 2012. Determination of Water Content in Silicate Glasses Using Raman Spectrometry: Implications for the Study of Explosive Volcanism. American Mineralogist 97 (5-6): 779\u201390. doi:10.2138/am.2012.3831.  Le Losq C., Neuville D. R., Florian P., Henderson G. S. and Massiot D., 2014, The role of Al3+ on rheology and structural changes in sodium silicate and aluminosilicate glasses and melts. Geochimica et Cosmochimica Acta 126, 495-517.  Neuville, D. R., and B. O. Mysen. 1996. \u201cRole of Aluminium in the Silicate Network: In Situ, High-Temperature Study of Glasses and Melts on the Join SiO\u2082-NaAl0\u2082.\u201d Geochimica et Cosmochimica Acta 60: 1727\u201337.  Mysen, B. O., L. W. Finger, D. Virgo, and F. A. Seifert. 1982. \u201cCurve-Fitting of Raman Spectra of Silicate Glasses.\u201d American Mineralogist 67: 686\u201395.  Shuker, Reuben, and Robert Gammon. 1970. \u201cRaman-Scattering Selection-Rule Breaking and the Density of States in Amorphous Materials.\u201d Physical Review Letters 25 (4): 222\u201325.  Thomas, R. 2000. \u201cDetermination of Water Contents of Granite Melt Inclusions by Confocal Laser Raman Microprobe Spectroscopy.\u201d American Mineralogist 85 (5-6): 868\u201372.  Woltring, 1986, A FORTRAN package for generalized, cross-validatory spline smoothing and differentiation. Adv. Eng. Softw. 8, 104-113.", 
            "title": "References"
        }
    ]
}